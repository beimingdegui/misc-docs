<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.23">
<title>计算机体系结构</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child{border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active,#footnotes .footnote a:first-of-type:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
</head>
<body class="article">
<div id="header">
<h1>计算机体系结构</h1>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>李龙斌 - <a href="mailto:202432466@mail.sdu.edu.cn">202432466@mail.sdu.edu.cn</a></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_计算机概论与设计分析基础"><a class="link" href="#_计算机概论与设计分析基础">1. 计算机概论与设计分析基础</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_引言"><a class="link" href="#_引言">1.1. 引言</a></h3>

</div>
<div class="sect2">
<h3 id="_计算机的分类"><a class="link" href="#_计算机的分类">1.2. 计算机的分类</a></h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>物联网/嵌入式计算机</p>
<div class="literalblock">
<div class="content">
<pre>物联网/嵌入式计算机是一种专门为特定功能设计的计算机系统，通常嵌入到更大的设备或系统中，以实现专用的任务。这类计算机通常具备低功耗、小体积和高可靠性的特点。它们硬件资源有限，通常运行轻量级的实时操作系统或者无操作系统，专注于单一或少量功能的高效执行。嵌入式计算机广泛应用于智能家居设备（如智能音箱、恒温器）、工业控制系统（如PLC）、汽车电子（如自动驾驶辅助系统）、医疗设备（如便携式医疗监测设备）等场景中。树莓派、ESP32、Arduino等设备是这一领域的典型代表。</pre>
</div>
</div>
</li>
<li>
<p>个人移动设备</p>
<div class="literalblock">
<div class="content">
<pre>个人移动设备是为便携性设计的小型计算设备，如智能手机、平板电脑和智能手表。它们集成了触控屏幕、摄像头、麦克风等多种输入输出设备，通常运行移动操作系统（如Android或iOS），支持多任务处理。个人移动设备的特点是设计轻薄便携，具有无线连接能力（如Wi-Fi、蜂窝网络）以及较长的电池续航时间。这类设备已经成为现代人生活的核心工具，广泛用于通信（如电话、视频通话）、娱乐（如游戏、音乐、视频）、工作（如电子邮件、文档处理）和导航等场景。智能手机是最常见的个人移动设备，平板电脑和智能手表则进一步扩展了其使用范围。</pre>
</div>
</div>
</li>
<li>
<p>桌面计算机</p>
<div class="literalblock">
<div class="content">
<pre>桌面计算机是一种固定式个人计算机，通常由主机、显示器、键盘和鼠标组成，适合放置在工作台上。其特点是性能强大、散热能力优越，可扩展性强，硬件组件（如内存、存储、显卡等）可以根据需要进行更换和升级。桌面计算机主要用于高性能任务，如办公应用（文档处理、数据分析）、高性能游戏、内容创作（视频剪辑、图形设计）、编程开发等。相比于笔记本电脑，桌面计算机更适合需要长期使用或性能要求较高的场景。常见的品牌台式机如戴尔OptiPlex，DIY装机则提供了更大的灵活</pre>
</div>
</div>
</li>
<li>
<p>服务器</p>
<div class="literalblock">
<div class="content">
<pre>服务器是一种专门为提供服务设计的高性能计算机，通常位于数据中心，为其他计算机或用户提供计算、存储和网络服务。服务器的特点是性能强劲、稳定可靠，支持多线程、多任务处理，并具备冗余设计（如双电源、ECC内存）以确保高可用性。它们通过专用的硬件和软件（如虚拟化技术）来实现远程管理和资源共享。服务器被广泛应用于托管网站（Web服务器）、运行数据库（数据库服务器）、支持网络通信（邮件服务器、DNS服务器）以及提供云计算服务等场景。典型的服务器设备包括刀片式服务器（如Dell PowerEdge）和机架式服务器（如HPE ProLiant）。</pre>
</div>
</div>
</li>
<li>
<p>分布式集群（计算机）</p>
<div class="literalblock">
<div class="content">
<pre>分布式集群是一种由多台计算机通过网络连接组成的计算系统，这些计算机协同工作，共同完成复杂任务。它的特点是高可扩展性，可以通过增加计算节点提升系统性能，同时具备高容错性，部分节点故障不会影响整体运行。分布式集群通常采用资源共享的方式，将任务分配到各个节点进行并行处理。它广泛应用于高性能计算（如科学模拟、基因分析）、大数据处理（如Hadoop和Spark平台）、云服务（如AWS和Google Cloud）以及分布式存储（如Ceph和HDFS）。超级计算机（如Fugaku）和云计算集群（如Kubernetes）是分布式集群的重要代表。</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_计算机的组成"><a class="link" href="#_计算机的组成">1.3. 计算机的组成</a></h3>
<div class="sect3">
<h4 id="_硬件组成部分"><a class="link" href="#_硬件组成部分">1.3.1. 硬件组成部分</a></h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>输入设备</p>
<div class="literalblock">
<div class="content">
<pre>输入设备是计算机硬件的重要组成部分，用于将外部信息转换为计算机能够识别和处理的电子信号。这些设备通常负责捕捉用户的指令或环境中的数据，以便计算机能够执行相应的操作。常见的输入设备包括键盘、鼠标、触摸屏、麦克风、摄像头以及传感器等。它们的主要特点是多样化和精确性，例如键盘适合精确输入文本和命令，而麦克风可以捕捉声音信号以供语音识别和通信使用。输入设备广泛应用于各类场景，从办公和游戏到自动化监控和虚拟现实体验，为计算机与用户之间的交互提供了多种可能性。</pre>
</div>
</div>
</li>
<li>
<p>输出设备</p>
<div class="literalblock">
<div class="content">
<pre>输出设备是计算机将处理结果以用户可感知形式输出的硬件部分。它们的主要作用是将计算机内部的数字信息转换为可视、可听或其他形式的表现，以便用户理解和利用。常见的输出设备包括显示器、打印机、扬声器、耳机以及触觉反馈设备等。输出设备的特点在于提供高质量的表现形式，例如高分辨率显示器可以展现清晰的图像和视频，扬声器可以播放高保真的音频内容。这些设备在日常生活、专业工作和娱乐中应用广泛，例如在设计领域显示高分辨率的图像，在教育领域播放多媒体内容，以及在虚拟现实中提供多感官的沉浸式体验。</pre>
</div>
</div>
</li>
<li>
<p>储存器</p>
<div class="literalblock">
<div class="content">
<pre>储存器是计算机用于保存数据和程序的硬件部件，分为不同层次以满足性能与容量需求的平衡。层次化存储的结构通常包括高速缓存（Cache）、主存（RAM）和外存（如硬盘、固态硬盘）。高速缓存存储常用数据，具有低延迟、高速度的特点；主存作为计算机的工作内存，支持快速读写；外存则负责长期保存大量数据。储存器的层次化设计通过不同级别的速度和容量优化了计算机系统的性能与成本。储存器的广泛应用包括在游戏中提供快速加载、在数据中心存储海量信息，以及在嵌入式设备中保存操作程序和运行时数据。</pre>
</div>
</div>
</li>
<li>
<p>运算器</p>
<div class="literalblock">
<div class="content">
<pre>运算器是计算机执行算术和逻辑运算的核心部件，通常由加法器、逻辑单元和寄存器等组成。其主要功能是处理指令中的计算任务，包括整数运算、浮点运算和逻辑判断等。运算器的特点在于速度和精确性，它能够在短时间内完成复杂的数学运算，并为其他硬件提供支持。现代运算器通常集成在处理器中，通过并行计算技术进一步提升性能。运算器广泛应用于科学计算、图形渲染、加密解密以及人工智能模型训练等领域，是计算机完成复杂任务的基础硬件。</pre>
</div>
</div>
</li>
<li>
<p>控制器</p>
<div class="literalblock">
<div class="content">
<pre>控制器是计算机的指挥中心，用于解析并执行指令，协调其他硬件部件的工作。控制器通过时钟信号驱动整个系统，并负责管理指令的获取、解码和执行过程。现代控制器与运算器一起构成了处理器（CPU），具备更高的集成度和性能。控制器支持多种并行技术，包括指令级并行（同时执行多条指令）、数据级并行（对大规模数据并行操作）以及线程级并行（同时运行多个任务）。这些特点使控制器能够处理多样化和复杂的任务。控制器的应用涵盖了从日常计算到高性能计算领域，如图像处理、多线程编程以及虚拟化平台支持，是现代计算系统的核心。</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_软件组成部分"><a class="link" href="#_软件组成部分">1.3.2. 软件组成部分</a></h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>应用软件</p>
<div class="literalblock">
<div class="content">
<pre>应用软件是专门为用户完成特定任务而开发的软件，直接服务于用户的需求。它的定义涵盖了从单一功能工具到综合型解决方案的广泛范围，例如文字处理软件、图形设计工具、会计软件、社交媒体应用等。应用软件的特点是面向用户需求设计，界面友好，功能明确，并能够在各种设备和平台上运行，如桌面计算机、移动设备和云平台。应用软件在日常生活和工作中应用广泛，例如在办公场景中使用Microsoft Office进行文档处理，在娱乐领域通过媒体播放器观看电影，在专业领域利用AutoCAD进行工程设计，以及在电子商务平台上进行购物和交易。应用软件的种类和功能随着用户需求的变化而不断丰富。</pre>
</div>
</div>
</li>
<li>
<p>系统软件</p>
<div class="literalblock">
<div class="content">
<pre>系统软件是计算机运行的基础，主要负责管理硬件资源并为应用软件提供支持和运行环境。它包括操作系统（如Windows、Linux、macOS）、驱动程序、系统工具和基础库等。系统软件的特点是抽象复杂硬件操作，提供标准化接口，确保硬件资源的高效分配和安全管理。它通常以后台运行的方式为用户和应用软件提供服务。操作系统是系统软件的核心部分，负责内存管理、文件系统、进程调度和设备管理等功能。此外，系统软件的可靠性和性能对整个计算机系统的稳定性至关重要。它广泛应用于个人电脑、服务器、移动设备以及嵌入式系统中，为用户的高效使用提供保障，同时也为应用软件开发者提供了统一的平台。</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_计算机体系结构"><a class="link" href="#_计算机体系结构">1.4. 计算机体系结构</a></h3>
<div class="paragraph">
<p>计算机体系结构包含计算机的物理实现及其逻辑设计（硬件）、各个部件之间的互连（组成，也称为微体系结构）。</p>
</div>
<div class="sect3">
<h4 id="_七个伟大思想"><a class="link" href="#_七个伟大思想">1.4.1. 七个伟大思想</a></h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">思想</th>
<th class="tableblock halign-left valign-top">概括</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">使用抽象简化设计</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">通过隐藏底层细节，专注于高层设计逻辑，从而简化复杂系统的开发。这一思想类似于函数的使用：函数封装了具体的实现逻辑，对外提供统一的接口，使得开发者可以专注于高层结构设计，而无需了解底层实现细节。应用场景包括模块化编程、操作系统的虚拟内存管理以及软件工程中的面向对象设计。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">加速经常性事件</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">针对系统中常见的操作进行优化，使其运行得更快、更高效。这一思想基于“常见情形出现得更频繁”这一观察，例如处理器优化分支预测的命中路径或缓存对热点数据的快速访问。这种方法使得系统能将资源优先分配给高频事件，从而整体提升性能。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">通过并行提高性能</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">通过指令级并行（如流水线技术）、数据级并行（如向量体系结构和GPU）、线程级并行（如多核处理器）来提高系统性能。并行化是现代计算机设计中的核心理念之一，其目的是充分利用硬件资源，在多个层次上同时处理数据和指令。例如，GPU擅长数据级并行，在图形处理和深度学习中具有极高效率。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">通过流水线提高性能</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">流水线技术是一种指令级并行实现方式，它将指令分解为多个阶段，各阶段可以同时处理不同的指令部分，从而提高吞吐量。这种方法类似于工业生产线，将复杂任务分解为多个子任务，各个子任务可以并行执行。应用于处理器设计中，流水线技术显著提升了指令执行的效率。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">通过预测提高性能</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">分支预测是一种提高性能的技术，通过提前执行可能的分支路径来减少因条件分支而造成的停顿。当预测结果正确时，性能显著提升；如果预测错误，系统则会撤回无效的操作。这一技术广泛用于现代处理器中，以减少分支指令对流水线的干扰。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">储存层次</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">存储层次结构是通过缓存机制和虚拟存储来优化数据访问速度的一种设计思想。系统将经常使用的数据存储在较快的存储层（如缓存）中，而将较少访问的数据存储在容量较大的层（如磁盘）中。这种机制通过权衡存取速度和存储容量，提升了整体性能。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">通过冗余提高可靠性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">冗余设计在系统中增加了额外的组件或信息，用于在发生故障时代替失效部分，从而保持系统的正常运行。例如，RAID存储技术通过冗余磁盘阵列来保护数据安全，冗余电源设计确保即使单个电源失效，系统仍能正常运行。这种方法提升了系统的容错性和可靠性。</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_计算机的性能"><a class="link" href="#_计算机的性能">1.5. 计算机的性能</a></h3>
<div class="paragraph">
<p>计算机处于不同场景下对于性能的关注点不一样，如个人用户更关注计算机的响应时间，而服务器更关心它的吞吐量与带宽。对于性能好坏的评价在不同场景下需要使用不同的标准。</p>
</div>
<div class="sect3">
<h4 id="_性能的定义与度量"><a class="link" href="#_性能的定义与度量">1.5.1. 性能的定义与度量</a></h4>
<div class="paragraph">
<p>时间是计算机性能的衡量标准</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">时间的定义</th>
<th class="tableblock halign-left valign-top">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">响应时间</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">响应时间指的是完成某项任务所需的总时间，包括所有相关开销。这不仅仅是CPU执行任务的时间，还包含等待I/O操作的时间、内存访问时间以及操作系统调度时间等。响应时间通常用于衡量系统的整体性能，特别是在实时系统或交互式应用中。例如，当用户点击一个网页链接，响应时间指从点击开始到页面完全加载并呈现的总时间。优化响应时间可以提升用户体验，其关键策略包括优化I/O性能、减少系统开销以及提升任务调度的效率。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CPU执行时间</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">CPU执行时间是指程序在CPU上实际执行指令所花费的时间，通常细分为用户CPU时间和系统CPU时间。用户CPU时间是程序运行其自身代码所用的时间，而系统CPU时间则是操作系统为该程序提供服务所用的时间（如处理系统调用）。CPU执行时间通常被用来评估程序的计算效率，与响应时间不同，它忽略了外部因素的干扰（如I/O等待）。程序员可以通过优化算法、减少上下文切换以及充分利用硬件资源（如向量化和多线程）来减少CPU执行时间。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">时钟周期数</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">时钟周期数是衡量计算机硬件完成基本功能速度的指标，它表示某项操作所需的时钟周期总数。每个时钟周期由处理器的时钟频率定义，例如一个1 GHz的处理器的时钟周期为1纳秒。时钟周期数反映了指令执行的效率，是评估硬件性能的重要指标。通过减少每条指令所需的时钟周期数（CPI，Cycles Per Instruction）或提高处理器的时钟频率，可以提升计算性能。此外，现代处理器通过流水线和并行计算技术进一步优化时钟周期的利用率。</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_cpu性能及其度量因素"><a class="link" href="#_cpu性能及其度量因素">1.5.2. CPU性能及其度量因素</a></h4>
<div class="stemblock">
<div class="content">
\[程序的CPU执行时间 = 程序的CPU时钟数 \times 时钟周期时间\]
</div>
</div>
<div class="paragraph">
<p>由于时钟频率和时钟周期长度互为倒数，故另一种表达形式为：</p>
</div>
<div class="stemblock">
<div class="content">
\[程序的CPU执行时间 = \frac{程序的CPU时钟数}{时钟频率}\]
</div>
</div>
<div class="paragraph">
<p>这个公式表明，硬件设计者减少程序执行所需的CPU时钟周期数或缩短时钟周期长度。就能改进性能。</p>
</div>
</div>
<div class="sect3">
<h4 id="_指令性能"><a class="link" href="#_指令性能">1.5.3. 指令性能</a></h4>
<div class="stemblock">
<div class="content">
\[CPU时钟周期数 = 程序的指令数 \times 指令平均时钟周期数（CPI）\]
</div>
</div>
<div class="paragraph">
<p>CPI（Cycles Per Instruction）是指处理器平均执行一条指令所需的时钟周期数。它是衡量计算机处理器性能的重要指标之一，用于描述指令执行效率。公式如下：</p>
</div>
<div class="stemblock">
<div class="content">
\[CPI = \frac{总时钟周期数}{指令总数}\]
</div>
</div>
<div class="paragraph">
<p>CPI的大小反映了处理器执行指令的效率。较低的CPI表示处理器能够在更少的时钟周期内完成指令执行，而较高的CPI则意味着指令执行效率较低。CPI受多种因素影响，包括指令集架构、处理器的设计（如流水线深度、并行执行能力）以及指令的性质（简单指令和复杂指令的CPI可能差异较大）。CPI提供了一种相同指令系统在不同实现下比较性能的方法，因为在指令系统不变的情况下，一个程序执行的指令数是不变的。</p>
</div>
</div>
<div class="sect3">
<h4 id="_经典cpu性能公式"><a class="link" href="#_经典cpu性能公式">1.5.4. 经典CPU性能公式</a></h4>
<div class="stemblock">
<div class="content">
\[CPU时间 = 指令数 \times 指令平均时钟周期数（CPI）\times 时钟周期时间\]
</div>
</div>
<div class="paragraph">
<p>或：</p>
</div>
<div class="stemblock">
<div class="content">
\[CPU时间 = \frac{指令数 \times 指令平均时钟周期数（CPI）}{时钟周期时间}\]
</div>
</div>
</div>
<div class="sect3">
<h4 id="_性能的测量报告和汇总"><a class="link" href="#_性能的测量报告和汇总">1.5.5. 性能的测量、报告和汇总</a></h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">基准测试</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">桌面基准测试</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">处理器密集型测试、图形密集型测试</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">服务器基准测试</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">事务处理基准测试</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">性能测试结果</p></td>
<td class="tableblock halign-left valign-top" colspan="2"><div class="content"><div class="stemblock">
<div class="content">
\[SPECRatio = \frac{基准计算机上的执行时间}{待评估计算机上的执行时间}\]
</div>
</div></div></td>
</tr>
</tbody>
</table>
<div class="ulist">
<ul>
<li>
<p>处理器密集型测试</p>
<div class="literalblock">
<div class="content">
<pre>主要关注处理器在执行大量计算任务时的效率。这种测试通常以数学运算、科学计算或加密算法为核心，测量处理器执行这些高计算强度任务的速度。它能够反映处理器的算术运算能力、指令执行效率以及寄存器操作的性能。处理器密集型测试广泛应用于高性能计算领域、科学研究以及对处理器进行性能对比分析。例如，使用基准工具如SPEC CPU基准套件来测试处理器在处理密集型任务时的表现，从而为用户或开发者选择硬件提供数据支持。</pre>
</div>
</div>
</li>
<li>
<p>图形密集型测试</p>
<div class="literalblock">
<div class="content">
<pre>主要用于评估系统在处理复杂图形任务时的能力，特别是显卡（GPU）的性能。这种测试通常通过渲染复杂的三维场景、光影效果和纹理操作，测量系统的帧率（FPS）、延迟和抗锯齿效果等指标。图形密集型测试反映了系统在游戏、视频渲染以及虚拟现实等场景中的性能表现。这类测试通常采用专业工具，例如3DMark、Unigine Heaven等，以模拟高负载图形任务的场景，从而判断显卡与驱动程序的综合性能。图形密集型测试对于游戏开发者、图形设计师和硬件厂商具有重要意义，能够帮助他们优化软件与硬件的兼容性和性能。</pre>
</div>
</div>
</li>
<li>
<p>事务处理基准测试</p>
<div class="literalblock">
<div class="content">
<pre>事务处理通常涉及大量的数据库操作，如插入、更新、查询以及删除数据，同时要求系统具备较高的并发处理能力和数据一致性。事务处理基准测试通常使用标准化的工作负载模型，如TPC-C（在线事务处理基准）或TPC-H（决策支持系统基准），来测量系统在多用户环境下的吞吐量、响应时间和扩展能力。这类测试广泛应用于企业信息管理、电子商务和金融服务领域，用以评估数据库管理系统、服务器和存储设备的性能，并为系统优化和扩展提供数据支持。</pre>
</div>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_计算机的发展方向"><a class="link" href="#_计算机的发展方向">1.6. 计算机的发展方向</a></h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>技术上，由于摩尔定律的失效，缩小晶体管的尺寸与增加晶体管的数量越来越困难，需要从新材料新架构中寻求突破。另外，由于网络速度的加快，远程计算机、云服务将越来越实用与流行。</p>
</li>
<li>
<p>能耗上，在移动设备与嵌入式设备（物联网）中，在低功耗的情况下实现高性能仍然是突破点</p>
</li>
<li>
<p>芯片制造中，随着制程工艺的减少，芯片生产难度加大。改良制造工艺提高良率能有效降低成本</p>
</li>
</ol>
</div>
<div class="sect3">
<h4 id="_技术趋势"><a class="link" href="#_技术趋势">1.6.1. 技术趋势</a></h4>
<div class="ulist">
<ul>
<li>
<p>性能趋势：带宽胜过延迟</p>
<div class="literalblock">
<div class="content">
<pre>带宽和吞吐量是指在给定时间内完成的总工作量，比如在进行磁盘读写时每秒传输的兆字节数。与之相对，延迟或响应时间是指一个事件从开始到完成所经过的时间，比如一次磁盘访问需要的毫秒数。下图绘制了微处理器、存储器、网络和磁盘等各项技术在出现里程碑式进步时，带宽与延迟的相对改进曲线。在目前技术的发展过程中，带宽的改进速度超过延迟，而且这一趋势很可能持续下去。一个简单的经验法则是：带宽的增加速度至少是延迟改进速度的平方。</pre>
</div>
</div>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/1.6.png" alt="1.6">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>晶体管性能与连线的发展</p>
<div class="literalblock">
<div class="content">
<pre>集成电路的制造工艺是用特征尺寸（feature size）来衡量的，所谓特征尺寸就是一个品体管或一条连线在x轴方向或y轴方向的最小尺寸。待征尺寸已经从1971年的10微米减小到2017年的0.016微米。事实上，单位已经变了，2011年的特征尺寸被称为“16纳米”（16nm）.7纳米的芯片正在研发之中。由于每平方毫米硅片上的晶体管数目是由单个晶体管的表面积决定的，所以当特征尺寸线性减小时，晶体管密度将呈二次方增长。
不过，晶体管性能的提升更加复杂。当特征尺寸缩小时，器件在水平方向的缩小服从平方律，在垂直方向上也会缩小。在垂直方向上缩小时，需要降低工作电压，以保持晶体管的正常工作和可靠性。缩放因子的这种组合效果使晶体管性能和工艺特征尺寸之间产生了复杂的关系。大致来说，晶体管性能的提高与特征尺寸的减小呈线性关系。
当特征尺寸减小时，晶体管性能线性提升，而晶体管数目却呈二次方增加，这既是挑战，也是机遇，计算机架构师正是解决此类问题的！在微处理器发展的早期，借助晶体管密度的这种快速增长，微处理器迅速从4位发展到8位、16位、32位乃至64位。最近几年，密度的增长已经足以支持在一个芯片上引入多个处理器，支持更宽的SIMD单元、推测执行和缓存中的许多创新，第2、3、4、5章将会讨论这些内容。
尽管晶体管的性能通常会随着特征尺寸的减小而提升，但集成电路中的连线却不会如此。具体来说，一段连线的信号延迟与其电阻和电容的乘积成正比。当然，当特征尺寸减小时，连线会变短，但单位长度的电阻和电容都会变差。这种关系很复杂，这是因为电阻和电容都依赖于工艺的具体细节、连线的几何形状、连线的负载，甚至与其他结构的邻近程度。偶尔也会有工艺方面的改进，比如铜的引入，这些改进会一次性地缩短连线延迟。
一般来说，与晶体管性能相比，连线延迟方面的改进小得可怜，这增大了设计人员面临的挑战。在过去几年里，除了功耗限制之外，连线延迟已经成为大型集成电路的主要设计障碍，而且往往比晶体管开关延迟还要关键。信号在连线上的传播延迟消耗了越来越多的时钟周期，而功耗对时钟周期的影响大于连线延迟。</pre>
</div>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_集成电路中的功耗和能耗趋势"><a class="link" href="#_集成电路中的功耗和能耗趋势">1.6.2. 集成电路中的功耗和能耗趋势</a></h4>
<div class="paragraph">
<p>今天，对于几乎所有类型的计算机来说，能耗都是计算机设计人员面对的最大挑战。第一，必须将电源引人芯片，并进行分配，而现代微处理器仅仅为供电和接地就使用了数百个管脚和多个互连层。第二，功耗以热的形式耗散，必须降低。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>功耗与能耗：系统视角</p>
<div class="literalblock">
<div class="content">
<pre>系统架构师或用户应当如何考虑性能、功耗和能耗呢?从系统架构师的角度来看，共有3个主要关注事项。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>第一，处理器需要的最大功耗是多少?
满足功耗要求对于确保操作正确非常重要。例如。如果处理器的预期功耗大于电源系统能够提供的功耗(也就是试图汲取的电流大于电源系统能够提供的电流），通常会导致电压下降，而电压下降可能会导致器件无法正常工作。现代处理器在峰值电流时的功耗变化范围很大，因此提供了电压指数方法，让处理器能够减缓速度，在惠大幅度内调整电压。显然，这样会降低性能。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>第二，持续功耗是多少？
这个指标通常称为热设计功耗（thermal design power,TDP)因为它是对系统散热提出的要求。TDP既不是峰值功耗（峰值功耗通常要高1.5倍），也不是在给定计算期间的（可能更低的）实际平均功耗。在为一个系统适配电源时，其功耗通常要大于TDP，而冷却系统的散热通常也不小于TDP。如果散热能力不足，处理器中的结点温度可能会超出最大值，导致器件故障，甚至水久损坏。由于最大功耗可能超出TDP指定的长期平均值（从而使热量和温度上升），所以现代处理器提供了两项功能来帮助管理热量——当温度接近结点温度上限时，电路降低时钟频率，从而减小功耗；如果这个动作不管用，则启用热过载保护装置强制芯片断电。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>第三,能耗和能效是多少？
回想一下，功耗就是单位时间的能耗1瓦=1焦/秒。哪个指标更适合用来对比处理器：能耗还是功耗？一般来说，能耗更好一些，因为它与特定任务以及该项任务所需要的时间相关联。具体来说，执行一项工作负载的能耗等子平均功耗乘以此项工作负载的执行时间。</pre>
</div>
</div>
</li>
<li>
<p>微处理器内部的能耗与功耗</p>
<div class="literalblock">
<div class="content">
<pre>配电、散热和防热点的难度日益增加。能耗是现在使用晶体管的主要限制因素。因此，现代微处理器提供了许多技术，试图在时钟频率和电源电压保持不变的情况下，提高能效。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>（1）以逸待劳
今天的大多数微处理器会关闭非活动模块的时钟，以降低能耗和动态功耗。例如，如果当前没有执行浮点指令，浮点单元的时钟将被禁用。如果一些核处于空闲状态，它们的时钟也会被停止。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>（2)动态电压一频率调整(dynamic voltage-frequency scaling,DVFS）
第二种技术直接来自上述公式。PMD、笔记本计算机，甚至服务器都会有一些活跃程度较低的时期，在此期间不需要以最高时钟频率和电压运转。现代微处理器通常提供几种能够降低功耗和能耗的工作时钟频率和工作电压。图l-5绘制了当工作负载降低时，服务器通过DVFS可能节省的功耗，3种时钟频率为2.4GHz、1.8GHz和1GHz。在这两个步骤中的每一步，服务器可以节省大约10%-15%的总功耗。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>（3）针对典型情景的设计
由于PMD和笔记本计算机经常空闲，所以内外存储器都提供了低功耗模式，以减少能耗，例如，DRAM具有一系列功耗逐渐降低的低功耗模式，用于延长PMD和笔记本计算机的电池寿命；同时，针对磁盘也提出了一些建议，即在空闲时使其采用低转速模式，以省电，遗憾的是，在这些模式下，你不能访问DRAM和磁盘，无论访问速度有多低，你都必须返回全速工作模式才能进行读写。前面曾经提到，PC微处理器的设计考虑了一种更典型的情景：在高工作温度下密集使用。这种设计依靠片上温度传感器检测应当在什么时候自动减少活动，以避免过热。这种“紧急减速”使制造商能够针对更典型的情景进行设计，如果所运行程序的耗电量远远超出典型情况，则可以依靠这种安全机制来保证安全。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>（4）超频
Intel在2008年开始提供Turbo模式，在这种模式中，芯片可以判定在少数几个核上以较高时钟频率短时运行是安全的，直到温度开始上升为止。例如，3.3GHzCore i7可以在很短的时间内以3.6GHz的频率运行。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>尽管通常认为动态功耗是CMOS中功耗的主要来源，但由于即使晶体管处于关闭状态也存在泄漏电流，所以静态功耗也逐渐成为一个重要问题：</pre>
</div>
</div>
<div class="stemblock">
<div class="content">
\[功耗_{静态} \propto 电流_{静态} \times 电压\]
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>也就是说，静态功耗与器件数目成正比。因此，如果增加晶体管的数目，即使它们处于空闲状态也会增加功耗，并且当品体管的尺寸较小时，处理器中的泄漏电流会增大。所以，功耗极低的系统甚至会关闭非活动模块的电源（电源门控，power gating），以控制由泄漏电流导致的损失</pre>
</div>
</div>
</li>
<li>
<p>计算机体系结构因为能耗限制而发生变化</p>
<div class="literalblock">
<div class="content">
<pre>随着晶体管发展速度的减缓，计算机架构师必须寻求其他提高能效的方法。事实上，在给定能耗预算的情况下，今天很容易设计出一种微处理器，其拥有的晶体管数多到不能同时全部开启。这种现象称为暗硅（dark silicon），这是因为在任意时刻，由于热限制，一个芯片的大部分都不能使用（“暗”）。这一观测结果使架构师们重新研究了处理器设计的基本原理，以寻求更高的能效。</pre>
</div>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_成本趋势"><a class="link" href="#_成本趋势">1.6.3. 成本趋势</a></h4>
<div class="literalblock">
<div class="content">
<pre>成本趋势是推动计算机技术发展的另一大因素。随着技术的进步和生产规模的扩大，计算机系统的成本逐渐降低。时间、产量和大众化成本的降低使得高性能计算逐步进入更多消费者的日常生活。特别是在过去几十年中，摩尔定律的推动使得计算机硬件的价格不断下降，处理能力不断提升，这为个人计算机的普及奠定了基础。随着市场需求的扩大和技术成熟，计算机设备不仅在性能上得到了提高，成本方面也得到了显著优化，推动了计算机的民主化，使得各种计算设备更加普及。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>集成电路的成本随着生产工艺的进步而不断降低。随着半导体制造技术的不断发展，集成电路的生产成本逐渐下降。规模化生产、精密制造和先进工艺的引入使得每个晶体管的成本大幅降低，从而降低了整体集成电路的价格。这种成本降低不仅使得更为复杂的电路能够得到实现，还推动了消费电子产品的普及，例如智能手机、平板电脑等。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>制造成本与运营成本的变化也对计算机的发展起到了重要作用。随着新型制造工艺和自动化生产线的引入，集成电路的制造成本不断降低。然而，运营成本，尤其是在大规模数据中心和云计算环境中的能源消耗和维护费用，仍然是计算机技术发展中的一大挑战。为了降低运营成本，越来越多的企业开始采用高效能硬件、绿色数据中心和智能管理系统，这不仅能降低能源消耗，还能延长设备的使用寿命，最终为企业节省成本。</pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_指令系统"><a class="link" href="#_指令系统">2. 指令系统</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_汇编语言及其操作数"><a class="link" href="#_汇编语言及其操作数">2.1. 汇编语言及其操作数</a></h3>
<div class="paragraph">
<p>汇编语言是一种介于机器语言和高级语言之间的低级编程语言，它以符号化的助记符代替机器语言中的二进制操作码和内存地址，帮助程序员更容易地与硬件交互。汇编语言的作用主要体现在直接控制硬件、优化程序性能和深入理解计算机系统等方面。在操作系统开发、驱动程序编写和嵌入式系统设计中，汇编语言因其对硬件资源的精确控制而被广泛应用。此外，汇编语言还常用于程序性能优化，通过手动调整指令和资源分配，可以实现更高效的代码执行。</p>
</div>
<div class="paragraph">
<p>汇编语言具有与硬件高度相关、符号化表示低级操作、高效率但复杂性高等特点。由于其紧密依赖于特定的处理器架构，每种汇编语言的指令集和功能都与相应的硬件设计息息相关，导致它在不同平台之间无法直接移植。相比于高级语言，汇编语言的可读性和可维护性较差，但在运行效率上更具优势。其符号化的表示方式虽然简化了机器语言的复杂性，但仍需要程序员对底层硬件有深入的理解和掌控。</p>
</div>
<div class="paragraph">
<p>汇编语言与高级语言处于不同的抽象层次，两者既有显著区别又具有密切联系。高级语言通过抽象屏蔽底层硬件细节，使程序设计更接近自然语言，极大地提高了开发效率和可移植性。然而，高级语言编写的程序需要经过编译器翻译成汇编代码，最终再由汇编器转为机器码，这使得高级语言程序的执行效率通常不如汇编语言。在实际开发中，高级语言和汇编语言往往结合使用。当程序对性能和硬件操作有极高要求时，开发者可以选择用汇编语言编写关键模块，将其嵌入到高级语言中，以兼顾系统性能与开发效率。汇编语言在优化代码性能和深入理解系统底层运作方面仍具有不可替代的价值，与高级语言共同构成了完整的编程工具体系。</p>
</div>
<div class="paragraph">
<p>汇编语言的操作数种类多样，通常包括立即数、寄存器和内存地址三种形式。立即数是直接嵌入指令中的具体值，表示常量数据，使用时无需额外的存储访问，因此处理速度快但灵活性较低。寄存器操作数指存储在处理器内部寄存器中的数据，由于寄存器是处理器中访问速度最快的存储单元，寄存器操作数的使用能够显著提高运算效率。然而，由于寄存器数量有限，寄存器操作数的应用通常需要精心规划和优化。内存地址操作数则指向存储在主存中的数据，虽然存储空间更大，但访问内存操作数需要额外的存储访问时间，可能影响指令执行的速度。</p>
</div>
<div class="paragraph">
<p>汇编语言的操作数具有低级性和直接性的特点，完全依赖于底层硬件的体系结构。每种处理器架构定义了支持的操作数类型、数量以及操作数的位置规则。例如，一些架构允许指令同时包含多个操作数，而另一些架构则限制为单一操作数或特定的寻址模式。这种对硬件特性的依赖使得汇编语言的操作数灵活性受到一定限制，同时导致其代码在不同硬件平台之间的可移植性较差。</p>
</div>
<div class="paragraph">
<p>操作数的寻址方式是汇编语言的另一个显著特点。处理器支持多种寻址模式，用于确定操作数的具体位置，包括直接寻址、间接寻址、寄存器寻址、偏移寻址等。不同的寻址方式为程序提供了多样化的操作数访问手段，使开发者可以根据具体需求优化代码性能和存储使用。例如，在循环操作中，偏移寻址可以简化数组元素的访问，而寄存器寻址则能最大限度地提高运算效率。</p>
</div>
<div class="sect3">
<h4 id="_存储器操作数"><a class="link" href="#_存储器操作数">2.1.1. 存储器操作数</a></h4>
<div class="paragraph">
<p>处理器只能在寄存器中保存少量数据，但是计算机内存可以存储数十亿数据元素。因此数据结构（数组和结构体）可以保存在内存中。由于RISC-V指令中的算术运算只作用于寄存器，因此，RISC-V必须包含在内存和寄存器之间传输数据的指令。这些指令称为数据传输指令。要访问内存中的字，指令必须提供内存地址。内存只是一个大型一维数组，其地址作为该数组的下标，从0开始。将数据从内存复制到寄存器的数据传输指令通常称为载入指令（load）。载入指令的格式是操作名称后面紧跟数据待取的寄存器，然后是寄存器和用于访问内存的常量。指令的常量部分和第二个寄存器中的内容相加组成内存地址。实际的RISC-V指令名称是lw，表示取字。</p>
</div>
<div class="paragraph">
<p>加载字和存储字是在RISC-V体系结构中存储器和寄存器之间传输字的指令。许多程序有着比计算机中寄存器数量更多的变量。所以，编译器会尽量把最常用的变量存放在寄存器中，剩下的存放在内存中，使用load和store在寄存器和内存之间传输变量。将不常用的变量（或稍后才使用的变量）存放到内存的过程称为寄存器换出。关于大小和速度的硬件设计原则表明内存一定比寄存器慢，因为寄存器更少。事实确实如此，如果数据在寄存器而不是内存中，数据访问速度会更快。而且，数据在寄存器中更有用。RISC-V算术指令可以读取两个寄存器，对它们进行操作并写入结果。RISC-V数据传输指令只读取一个操作数或写入一个操作数，并不对其进行操作。因此，与内存相比，寄存器的访问时间更短，吞吐率更高。这使得寄存器中的数据访问速度更快，使用更简单。与访问内存相比，访问寄存器所需的能耗也少得多。要获得最高的性能并节约能耗，指令系统体系结构必须有足够多的寄存器，并且编译器必须有效使用寄存器。</p>
</div>
</div>
<div class="sect3">
<h4 id="_常数或立即数操作数"><a class="link" href="#_常数或立即数操作数">2.1.2. 常数或立即数操作数</a></h4>
<div class="paragraph">
<p>通过把常数作为算术指令操作数，和从存储器中取出常数相比，操作速度更快，能耗更低。</p>
</div>
<div class="paragraph">
<p>常数0有另一个作用，通过有效使用它可以简化指令系统体系结构。例如可以使用常数0寄存器求原数的相反数。因此，RISC-V专用寄存器x0硬连线到常数0.根据使用频率来确定要定义的常数，这是第一章中重要思想加速经常性事件的实例。</p>
</div>
</div>
<div class="sect3">
<h4 id="_有符号数与无符号数"><a class="link" href="#_有符号数与无符号数">2.1.3. 有符号数与无符号数</a></h4>
<div class="paragraph">
<p>在计算机内部，有符号数（正负数）和无符号数的表示依赖于二进制编码方式。计算机使用固定长度的二进制位来表示数据，如何区分正数、负数或单纯的无符号数取决于所选的编码规则。</p>
</div>
<div class="paragraph">
<p>有符号数需要区分正数和负数，因此通常使用最高位（即最左侧的位）作为符号位，剩余的位表示数值。符号位为0表示正数，为1表示负数。以下是常用的有符号数表示方法：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>原码</p>
<div class="literalblock">
<div class="content">
<pre>原码是一种直接的表示方式，符号位加上数值的绝对值。例如，8位二进制中，+5表示为00000101，-5表示为10000101。虽然原码表示简单，但在进行运算时，符号位需要单独处理，运算逻辑较为复杂，因此不常用于计算机实际运算。</pre>
</div>
</div>
</li>
<li>
<p>反码</p>
<div class="literalblock">
<div class="content">
<pre>反码的符号位与原码相同，但负数的数值部分通过对原码取反（0变1，1变0）得到。例如，+5的反码是00000101，而-5的反码是11111010。反码在加减运算中简化了一部分逻辑，但依然存在问题，如表示零时会有+0和-0两种形式。</pre>
</div>
</div>
</li>
<li>
<p>补码</p>
<div class="literalblock">
<div class="content">
<pre>补码是计算机中最常用的有符号数表示方法。正数的补码与其原码相同，而负数的补码通过对原码取反后加1得到。例如，+5的补码为00000101，而-5的补码为11111011。补码的优点是可以将减法统一为加法运算，且解决了零的双重表示问题（补码中只有一种形式的零）。由于这些特性，补码成为现代计算机处理有符号数的标准。</pre>
</div>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>无符号数的表示</p>
</div>
<div class="paragraph">
<p>无符号数只表示非负整数，因此所有二进制位都用于表示数值，不包含符号位。例如，在8位二进制中，00000000表示0，11111111表示255。无符号数的范围为\((0, 2^n - 1)\),其中\(n\)是二进制位数。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_计算机中的指令表示"><a class="link" href="#_计算机中的指令表示">2.2. 计算机中的指令表示</a></h3>
<div class="imageblock">
<div class="content">
<img src="./src/pic/2.2.png" alt="2.2">
</div>
</div>
<div class="paragraph">
<p>RISC-V 的指令根据功能不同分为多种格式，例如 R 型、I 型、S 型、B 型、U 型和 J 型。这些格式共享某些字段，但也有独特部分。32 位指令的通用结构包括以下字段：</p>
</div>
<div class="paragraph">
<p>Opcode（操作码，7 位）</p>
</div>
<div class="literalblock">
<div class="content">
<pre>位置：第 0-6 位（从右向左编号，最右侧为第 0 位）。
含义：指定指令的基本操作类型，如算术运算、内存访问、控制流指令等。
作用：操作码决定指令的功能类别，结合其他字段进一步解析具体操作。</pre>
</div>
</div>
<div class="paragraph">
<p>rd（目标寄存器，5 位）</p>
</div>
<div class="literalblock">
<div class="content">
<pre>位置：第 7-11 位。
含义：指定操作结果的目标寄存器编号（0-31，对应 32 个寄存器）。
作用：表示操作结果将存储到的寄存器。</pre>
</div>
</div>
<div class="paragraph">
<p>funct3（功能码，3 位）</p>
</div>
<div class="literalblock">
<div class="content">
<pre>位置：第 12-14 位。
含义：提供次级操作分类，与操作码配合，用于进一步区分指令功能，例如加法与减法。
作用：在同一操作码下区分具体操作类型。</pre>
</div>
</div>
<div class="paragraph">
<p>rs1（源寄存器 1，5 位）</p>
</div>
<div class="literalblock">
<div class="content">
<pre>位置：第 15-19 位。
含义：指定第一个源操作数的寄存器编号。
作用：表示操作中需要读取的第一个操作数。</pre>
</div>
</div>
<div class="paragraph">
<p>rs2（源寄存器 2，5 位）</p>
</div>
<div class="literalblock">
<div class="content">
<pre>位置：第 20-24 位。
含义：指定第二个源操作数的寄存器编号。
作用：表示操作中需要读取的第二个操作数（仅适用于部分指令类型，如 R 型指令）。</pre>
</div>
</div>
<div class="paragraph">
<p>funct7（功能码扩展，7 位）</p>
</div>
<div class="literalblock">
<div class="content">
<pre>位置：第 25-31 位。
含义：提供进一步的操作区分信息，与 funct3 和操作码结合，确定特定指令行为（如区分加法和减法）。
作用：用于增强功能分类，扩展指令集。</pre>
</div>
</div>
<div class="paragraph">
<p>立即数字段（不同格式中的位置和长度可变）</p>
</div>
<div class="literalblock">
<div class="content">
<pre>含义：表示常量值，用于偏移量、地址或立即操作数等用途。
作用：立即数在不同指令格式中位置不同，但均用于表示直接参与操作的固定值。</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_逻辑操作指令"><a class="link" href="#_逻辑操作指令">2.3. 逻辑操作指令</a></h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">逻辑操作类型</th>
<th class="tableblock halign-left valign-top">C操作符</th>
<th class="tableblock halign-left valign-top">Java操作符</th>
<th class="tableblock halign-left valign-top">对应的RISC-V指令</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">左移 (Shift Left)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">&lt;&lt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">&lt;&lt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLL 指令：<code>sll rd, rs1, rs2</code> 或 <code>slli rd, rs1, imm</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">逻辑右移 (Shift Right Logical)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">&gt;&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">&gt;&gt;&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">SRL 指令：<code>srl rd, rs1, rs2</code> 或 <code>srli rd, rs1, imm</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">算术右移 (Shift Right Arithmetic)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">&gt;&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">&gt;&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">SRA 指令：<code>sra rd, rs1, rs2</code> 或 <code>srai rd, rs1, imm</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">按位与 (Bitwise AND)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">&amp;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">&amp;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">AND 指令：<code>and rd, rs1, rs2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">按位或 (Bitwise OR)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">|</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">|</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">OR 指令：<code>or rd, rs1, rs2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">按位异或 (Bitwise XOR)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">^</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">^</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">XOR 指令：<code>xor rd, rs1, rs2</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">按位非 (Bitwise NOT)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">~</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">~</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">取反指令：<code>xori rd, rs1, -1</code></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_决策指令"><a class="link" href="#_决策指令">2.4. 决策指令</a></h3>
<div class="paragraph">
<p>使用条件分支指令（beq、bne等）进行回跳（循环）或前跳（if）。</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">指令</th>
<th class="tableblock halign-left valign-top">含义</th>
<th class="tableblock halign-left valign-top">功能描述</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>beq rs1, rs2, offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Branch if Equal</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">如果`rs1`等于`rs2`，跳转到`PC + offset`指定的地址</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>bne rs1, rs2, offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Branch if Not Equal</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">如果`rs1`不等于`rs2`，跳转到`PC + offset`指定的地址</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>blt rs1, rs2, offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Branch if Less Than (Signed)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">如果`rs1`小于`rs2`（有符号比较），跳转到`PC + offset`指定的地址</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>bge rs1, rs2, offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Branch if Greater Than or Equal (Signed)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">如果`rs1`大于或等于`rs2`（有符号比较），跳转到`PC + offset`指定的地址</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>bltu rs1, rs2, offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Branch if Less Than (Unsigned)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">如果`rs1`小于`rs2`（无符号比较），跳转到`PC + offset`指定的地址</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>bgeu rs1, rs2, offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Branch if Greater Than or Equal (Unsigned)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">如果`rs1`大于或等于`rs2`（无符号比较），跳转到`PC + offset`指定的地址</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>jal rd, offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Jump and Link</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">跳转到`PC + offset`指定的地址，并将返回地址（<code>PC + 4</code>）保存到寄存器`rd`</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>jalr rd, rs1, offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Jump and Link Register</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">跳转到寄存器`rs1 + offset`的地址，并将返回地址（<code>PC + 4</code>）保存到寄存器`rd`</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>虽然常量通常很短并且适合12位字段，但有时它们也会更大。</p>
</div>
<div class="paragraph">
<p>RISC-V指令系统包括指令load upper immediate(取立即数高位，lui)，用于将20位常数加载到寄存器的第31位到第12位。最右边的12位全部用0填充。例如，这条指令允许使用两条指令创建32位常量。lui使用新的指令格式——U型，因为其他格式不能支持如此大的常量。</p>
</div>
<div class="sect3">
<h4 id="_risc_v寻址模式总结"><a class="link" href="#_risc_v寻址模式总结">2.4.1. RISC-V寻址模式总结</a></h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">寻址模式</th>
<th class="tableblock halign-left valign-top">定义</th>
<th class="tableblock halign-left valign-top">应用与特点</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">立即数寻址</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">操作数直接嵌入指令中，作为常量值。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">常用于加法、减法等运算，或加载、存储指令中的常量。
  示例：<code>addi rd, rs1, imm</code>，将`rs1`与立即数`imm`相加，并存储到`rd`寄存器。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">寄存器寻址</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">操作数位于寄存器中，指令通过寄存器指定操作数的位置。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">常用于寄存器之间的数据传输与算术运算。非常快速。
  示例：<code>add rd, rs1, rs2</code>，将`rs1`与`rs2`相加并将结果存储在`rd`中。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">基址寻址</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">操作数地址通过基地址寄存器和立即数偏移量计算得出。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">常用于内存访问，基址寄存器用于存储数据结构起始地址，偏移量指定数据位置。
  示例：<code>lw rd, offset(rs1)</code>，将内存地址`rs1 + offset`处的数据加载到`rd`。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PC相对寻址</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">操作数的地址是相对于当前PC值的偏移量计算得出。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">用于条件跳转与程序控制，确保程序在不同内存位置加载时的正确性。
  示例：<code>beq rs1, rs2, offset</code>，若`rs1`和`rs2`相等，跳转到`PC + offset`。
  示例：<code>jal rd, offset</code>，跳转到`PC + offset`并保存返回地址到`rd`寄存器。</p></td>
</tr>
</tbody>
</table>
<div class="imageblock">
<div class="content">
<img src="./src/pic/2.4.1.png" alt="2.4.1">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_条件分支指令"><a class="link" href="#_条件分支指令">2.4.2. 条件分支指令</a></h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-asm" data-lang="asm"># 如果rs1中的值与rs2中的值相等，那么PC跳转到标签L1处
beq rs1, rs2, L1

# 如果rs1中的值与rs2中的值不相等，那么PC跳转到标签了L2处
bne rs1, rs2, L2</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_循环"><a class="link" href="#_循环">2.4.3. 循环</a></h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-asm" data-lang="asm"># rs1持续加一，直到rs1等于10则退出循环
addi rs1, rs0, 1
addi rs2, rsr0, 10
Loop:
addi rs1, rs1 ,1
beq rs1, rs2, Exit
j Loop
Exit:
# 退出循环</code></pre>
</div>
</div>
<div class="paragraph">
<p>对相等或不相等的判断可能是最常见的判断，但也有很多其他两个数之间的关系。例如，for循环可能需要判断下标变量是否小于0。完整的相互关系有小于（&lt;）、小于等于（≤）、大于（&gt;）、大于等于（≥）、相等（=）、不等于（\(\neq\)）。</p>
</div>
<div class="paragraph">
<p>位模式的比较还必须处理有符号和无符号数之间的差别。有时候，最高有效位是1代表一个负数，当然，它小于任何正数（最高有效位是0）。另一方面，对于无符号整数，最高有效位是1表示大于任何最高有效位是0的数。（我们很快将利用最高有效位的这种双重含义来降低数组边界检查的成本。）RISC-V提供了指令来处理这两种情况。这些指令与beq和bne具有相同的形式，但是执行不同的比较。小于则分支指令（b1t）比较寄存器rsl和rs2中的值（采用二进制补码表示），如果rsl中的值较小则跳转。大于等于分支（bge）指令是相反情况，也就是说，如果rsl中的值至少不小于rs2中的值则跳转。无符号的小于则分支指令（b1tu）意味着，如果二者是无符号数，那么rsl中的值小于rs2中的值则跳转。最后，无符号数的大于等于则分支指令（bgeu)在相反的情况下跳转。</p>
</div>
<div class="paragraph">
<p>另一种提供这些额外分支指令的方法是根据比较结果设置寄存器，然后使用beq或bne指令根据该临时寄存器中的值来进行分支判断。这种由MIPS指令系统使用的方法可以使处理器数据通路稍微简单一些，但它需要更多指令来表达程序。</p>
</div>
<div class="paragraph">
<p>ARM指令系统使用的另一种方法是，保留额外的位来记录指令执行期间发生的情况。这些额外的位称为条件代码或标志位，用于表明例如算术运算的结果是否为负数或零，或溢出。条件分支利用这些条件代码的组合来执行期望的判断。条件代码的一个缺点是，如果许多指令总是设置它们，则会生成让流水线执行困难的依赖关系（参见第4章）。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>边界检查的简便方法</p>
<div class="literalblock">
<div class="content">
<pre>将有符号数当作无符号数处理，给我们提供了一种低成本的方式检查是否0≤x&lt;y，常用于检测数组下标是否越界。关键在于二进制补码表示中的负整数看起来像无符号表示中很大的数；因为最高有效位在有符号数中表示符号位，但在无符号数中表示数的很大一部分。因此，无符号比较x&lt;y在检测x是否小于y的同时，也检测了x是否为负数。</pre>
</div>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_caseswitch语句"><a class="link" href="#_caseswitch语句">2.4.4. case/switch语句</a></h4>
<div class="paragraph">
<p>两种方法：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>将case/switch语句转换为if-then-else语句</p>
</li>
<li>
<p>使用分支地址表。程序索引到地址表中，然后跳转到对应的地址。</p>
<div class="literalblock">
<div class="content">
<pre>编码形成指令序列的地址表，称为分支地址表或分支表，程序只需要索引到表中，然后跳转到合适的指令序列。因此，分支表只是一个字数组，其中包含与代码中的标签对应的地址，该程序将分支表中的相应条目加载到寄存器中。然后需要使用寄存器中的地址进行跳转。为了支持这种情况，RISC-V这类指令系统包含一个间接跳转指令，该指令对寄存器中指定的地址执行无条件跳转。在RISC-V中，跳转-链接指令（jalr）用于此目的。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>分支地址表：也称作分支表，一种包含了不同指令序到地经的表。</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_计算机硬件对函数的支持"><a class="link" href="#_计算机硬件对函数的支持">2.5. 计算机硬件对函数的支持</a></h3>
<div class="paragraph">
<p>过程(procedure)或函数是编程人员用于结构化编程的一种工具，两者均有助于提高程序的可理解性和代码的可重用性。过程允许程序员一次只专注于任务的一部分；参数可以传递数值并返回结果，因此用以充当过程和其余程序与数据之间的接口。</p>
</div>
<div class="paragraph">
<p>过程是用软件实现抽象的一种方式。可以把过程想象成一个携带秘密计划离开的侦探，他获取资源，执行任务，掩盖踪迹，然后带着预期结果返回原点。一旦任务完成，则再无任何干扰。更重要的是，侦探只在“需要知道”的基础上运作，因此侦探不能对雇主同样，在执行过程时，程序必须遵循以下六个步骤：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>将参数放在过程可以访问的位置</p>
</li>
<li>
<p>将控制转交给过程（函数）</p>
</li>
<li>
<p>获得过程所需的储存资源</p>
</li>
<li>
<p>执行任务</p>
</li>
<li>
<p>将结果放在调用程序可以访问的位置</p>
</li>
<li>
<p>将控制返回初始点</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>过程:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>一个根据给定参教执行特定任务的已存储的子程序。</pre>
</div>
</div>
<div class="paragraph">
<p>跳转一链接指令:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>政转到某个地址的同时得下一条指今的地址保存在寄存器（在RISC-V中还常是x1）中的指令。</pre>
</div>
</div>
<div class="sect3">
<h4 id="_使用更多的寄存器"><a class="link" href="#_使用更多的寄存器">2.5.1. 使用更多的寄存器</a></h4>
<div class="paragraph">
<p>假设对于一个过程，编译器需要比8个参数寄存器更多的寄存器。由于在任务完成后必须掩盖踪迹，调用者所需的所有寄存器都必须恢复到调用该过程之前所存储的值。换出寄存器的理想数据结构是栈（stack）——一种后进先出的队列。栈需要一个指向栈中最新分配地址的指针，以指示下一个过程应该放置换出寄存器的位置或寄存器旧值的存放位置。在RISC-V中，栈指针(stack pointer)是寄存器x2.也称为sp。栈指针按照每个被保存或恢复的寄存器按字进行调整。栈应用非常广泛，因而传送数据到栈或从栈传输数据都具有专业术语：将数据放人栈中称为压栈，从栈中移除数据称为弹栈。</p>
</div>
<div class="paragraph">
<p>按照历史惯例，栈按照从高到低的地址顺序“增长”。这就意味着可以通过减栈指针将值压栈；通过增加栈指针缩小栈，从而弹出栈中的值。</p>
</div>
<div class="paragraph">
<p>在运行过程（函数）时，在栈中存储局部变量，在堆中存储常量和静态变量</p>
</div>
<div class="paragraph">
<p>栈:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>一种被组织成后进先出队列并用于寄存器换出的数据结构。</pre>
</div>
</div>
<div class="paragraph">
<p>栈指针：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>指示栈中最新分配的地址的值，用于指示应该被换出的寄存器的位置，或寄存艺旧值的存放位置。在RISC-V中为齐存器sp或x2。</pre>
</div>
</div>
<div class="paragraph">
<p>压栈：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>向栈中添加元素。</pre>
</div>
</div>
<div class="paragraph">
<p>弹楼：</p>
</div>
<div class="literalblock">
<div class="content">
<pre>从栈中移除无素。</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_嵌套过程"><a class="link" href="#_嵌套过程">2.5.2. 嵌套过程</a></h4>
<div class="paragraph">
<p>不调用其他过程的过程称为叶子（leaf）过程。如果所有过程都是叶子过程，情况将会变得简单，但事实并非如此。正如一个侦探任务的一部分可能是雇佣其他侦探一样，被雇佣的侦探进而雇佣更多的侦探，过程调用其他过程也是如此。更进一步，递归过程甚至调用的是自身的“克隆”。就像在过程中使用寄存器时需要小心一样，在调用非叶子过程时必须更加注意。</p>
</div>
<div class="paragraph">
<p>一种解决方法是将其他所有必须保存的寄存器压栈，就像保存寄存器压栈一样。调用者将所有调用后还需要的参数寄存器(x10-x17）或临时寄存器(x5-×7和×28-×31)压栈。被调用者将返回地址寄存器x1和被调用者使用的保存寄存器(x8<sub>x9和x18</sub>x27)压栈。调整栈指针sp以计算压栈寄存器的数量。返回时，从存储器中恢复寄存器并重新调整栈指针。</p>
</div>
</div>
<div class="sect3">
<h4 id="_在栈中为新数据分配空间"><a class="link" href="#_在栈中为新数据分配空间">2.5.3. 在栈中为新数据分配空间</a></h4>
<div class="paragraph">
<p>栈也用于存储过程的局部变量，但这些变量不适用于寄存器，例如局部数组或结构体。栈中包含过程所保存的寄存器和局部变量的段称为过程帧或活动记录。图下图展示了过程调用之前、之中和之后栈的状态。一些RISC-V编译器使用帧指针fp或者寄存器x8来指向过程帧的第一个字。栈指针在过程中可能会发生改变，因此对存储器中局部变量的引用可能会有不同的偏移量，具体取决于它们在过程中的位置，从而使过程更难理解。帧指针在过程中为局部变量引用提供一个稳定的基址寄存器。注意，不管是否使用显式的帧指针，栈上都会显示一条活动记录。我们可以通过维护稳定的Sp来减少对fp的使用：在示例中，仅在进入和退出过程时才调整栈。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/2.5.3.png" alt="2.5.3">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_在堆中为新数据分配空间"><a class="link" href="#_在堆中为新数据分配空间">2.5.4. 在堆中为新数据分配空间</a></h4>
<div class="paragraph">
<p>除了动态变量（对于过程局部有效）之外，C程序员还需要为静态变量和动态数据结构分配内存空间。下图展示了运行Linux操作系统时RISC-V分配内存的约定。栈从用户地址空间的高端开始（见第5章）并向下扩展。低端内存的第一部分是保留的，之后是RISC-V机器代码，通常称为代码段(text segment)。在此之上是静态数据段(static data seement).用于存放常量和其他静态变量。虽然数组具有固定长度，且因此可与静态数据段很好地匹配，但像链表等数据结构往往会随生命周期增长和缩短。存放这类数据结构（数组和链表）的段通常称为堆（heap）.它放在内存中。注意，这种分配允许栈和堆相向而长，从而随着这两个段的此消彼长达到内存的高效使用。C语言通过显式函数调用来分配和释放堆上的空间。malloc(）在堆上分配空间并返回困难bug的根源。忘记释放空间会导致“内存泄漏”，最终耗尽大量内存，可能导致操作系指向它的指针，free（）释放指针所指向的堆空间。C程序控制内存分配，这是许多常见和统崩溃。过早释放空间会导致“悬空指针”，这可能导致指针指向程序未曾打算访问的位置。Java主要使用自动内存分配和垃圾回收机制来避免这类错误。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/2.5.4.png" alt="2.5.4">
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_并行性与指令同步"><a class="link" href="#_并行性与指令同步">2.6. 并行性与指令：同步</a></h3>
<div class="paragraph">
<p>当任务之间相互独立时，并行执行更为容易，但通常任务之间需要协作。协作通常意味着一些任务正在写人其他任务必须读取的值。需要知道任务何时完成写人以便其他任务安全地读出，因此任务之间需要同步。如果它们不同步，则存在数据竞争（data race)的危险，那么程序的结果会根据事件发生的次序而改变。</p>
</div>
<div class="paragraph">
<p>在计算中，同步机制通常由用户级的软件例程所构建，而这依赖于硬件提供的同步指令。加锁和解锁可直接用于创建只有单个处理器可以操作的区域，称为互斥(mutual exclusion)区，以及实现更复杂的同步机制。</p>
</div>
<div class="paragraph">
<p>在多处理器中实现同步所需的关键是一组硬件原语，能够提供以原子方式读取和修改内存单元的能力。也就是说，在内存单元的读取和写入之间不能插人其他任何操作。如果没有这样的能力，构建基本同步原语的成本将会很高，并会随着处理器数量的增加而急剧增加。</p>
</div>
<div class="paragraph">
<p>有许多基本硬件原语的实现方案，所有这些都提供了原子读和原子写的能力，以及一些判断读写是不是原子操作的方法。通常，体系结构设计人员不希望用户使用基本的硬件原语，而是期望系统程序员使用原语来构建同步库，这个过程通常复杂且棘手。</p>
</div>
<div class="paragraph">
<p>原子交换(atomic exchange或atomic swap)原语是构建同步机制的一种典型操作，会将寄存器中的值与存储器中的值进行交换。为了了解如何使用它来构建基本同步原语，假设要构建一个简单的锁变量，其中值0用于表示锁变量可用，值1用于表示锁变量已被占用。处理器尝试通过将寄存器中的1与该锁变量对应的内存地址的值进行交换来设置加锁。如果某个其他处理器已声明访问该锁变量则交换指令的返回值为1，表明该锁已被其他处理器占用，否则为0，表示加锁成功。在后一种情况下，锁变量的值变为1，以防止其他处理器也加锁成功。</p>
</div>
<div class="paragraph">
<p>例如，考虑两个处理器尝试同时进行交换操作：这种竞争会被阻止，因为其中一个处理器将首先执行交换，并返回0，而第二个处理器在进行交换时将返回1。使用交换原语实现同步的关键是操作的原子性：交换是不可分割的，硬件将对两个同时发生的交换进行排序。尝试以这种方式设置同步变量的两个处理器都不可能认为它们同时设置了变量。</p>
</div>
<div class="paragraph">
<p>实现单个的原子存储操作为处理器的设计带来了一些挑战，因为它要求在单条不可中断的指令中完成存储器的读和写操作。</p>
</div>
<div class="paragraph">
<p>另一种方法是使用指令对，其中第二条指令返回一个值，该值表示该指令对是否被原子执行。如果任何处理器执行的所有其他操作都发生在该对指令之前或之后，则该指令对实际上是原子的。因此，当指令对实际上是原子操作时，没有其他处理器可以在指令对之间改变值。在RISC-V中，这对指令指的是一个称为保留加载（load-reserved）字（1r.w)的特殊加载指令和一个称为条件存储(store-conditional）字(sc.w）的特殊存储指令。这些指令按序使用：如果保留加载指令指定的内存位置的内容在条件存储指令执行到同一地址之前发生了变化，则条件存储指令失败且不会将值写入内存。条件存储指令定义为将（可能是不同的）寄存器的值存储在内存中，如果成功则将另一个寄存器的值更改为0.如果失败则更改为非零值。因此，SC.w指定了三个寄存器：一个用于保存地址，一个用于指示原子操作失败或成功，还有一个用于如果成功则将值存储在内存中。</p>
</div>
</div>
<div class="sect2">
<h3 id="_翻译并启动程序"><a class="link" href="#_翻译并启动程序">2.7. 翻译并启动程序</a></h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">工具</th>
<th class="tableblock halign-left valign-top">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">编译器 (Compiler)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">将高级语言（如C、C++）源代码转换成中间代码或机器代码。编译器负责语法分析、语义分析、优化和目标代码生成。它生成一个独立的可执行文件，通常为机器语言指令，供计算机直接执行。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">汇编器 (Assembler)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">将汇编语言代码转换成机器代码或目标代码。汇编器负责将汇编语言的每条指令映射为相应的机器指令。它处理符号（如标签和变量）并生成对应的机器代码文件（通常是`.obj`文件）。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">链接器 (Linker)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">将多个目标文件（通常是由编译器或汇编器生成的）和库文件结合在一起，生成一个可执行文件。链接器负责解决符号引用、地址分配和代码重定向，使程序中的函数和变量能够正确地互相引用。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">加载器 (Loader)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">将可执行文件加载到内存中并准备执行。加载器将程序的各个部分（如代码段、数据段）载入内存，并将控制权交给操作系统或程序的入口点，开始执行程序。它还可能进行地址重定位，确保程序在内存中正确运行。</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>编译器、汇编器、链接器和加载器是计算机程序开发过程中密切协作的四个关键工具，它们分别承担不同的角色，并且在程序生成和执行过程中依赖彼此的工作。编译器是程序开发的第一步，它将高级语言（如C语言）源代码转换为汇编语言或中间代码。汇编器接下来会将编译器生成的汇编代码转换为机器代码或目标代码，产生可供计算机理解的低级语言。生成的目标代码通常是一个或多个独立的文件，但这些文件还不能直接执行，因为它们可能包含未解析的符号或地址引用。链接器接管这个任务，它将多个目标文件和库文件合并成一个完整的可执行文件，并解决其中的符号引用，调整内存地址，确保所有函数和数据能够正确链接和引用。</p>
</div>
<div class="paragraph">
<p>当程序准备好并生成了可执行文件之后，加载器的工作就开始了。加载器负责将可执行文件加载到内存中，并将程序控制权交给操作系统或程序的入口点，从而启动程序的执行。在加载过程中，加载器可能还会进行地址重定位，确保程序能够在内存的不同位置运行。总的来说，编译器、汇编器、链接器和加载器共同协作，将开发者编写的高级程序转化为最终可在计算机上运行的可执行文件，并确保程序的各个部分能够正确连接和执行。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/2.7.png" alt="2.7">
</div>
</div>
<div class="sect3">
<h4 id="_动态链接库"><a class="link" href="#_动态链接库">2.7.1. 动态链接库</a></h4>
<div class="paragraph">
<p>动态链接库（Dynamic Link Library，简称DLL）是一种在程序运行时动态加载和链接的库文件。与静态链接库不同，动态链接库在程序编译时并不直接包含进可执行文件，而是在程序运行时根据需要加载到内存中。DLL文件通常包含一组函数、数据或资源，供其他程序或模块在执行过程中调用。这种方式能够实现模块化的编程，多个程序可以共享同一个DLL文件，从而减少内存和磁盘空间的占用。</p>
</div>
<div class="paragraph">
<p>动态链接库的主要作用是提供程序功能的共享和扩展。通过将常用的功能封装在DLL中，开发者可以避免重复编写相同的代码，并且在程序运行时可以灵活地加载和调用这些功能。当多个程序需要相同的功能时，它们可以共享同一个DLL，避免每个程序都包含一份相同的代码，这样不仅节省了资源，还使得程序的更新和维护变得更加简便。通过更新DLL文件中的代码，所有使用该库的程序都能够自动获得更新，而无需重新编译和发布每个程序。</p>
</div>
<div class="paragraph">
<p>此外，动态链接库还提供了运行时的灵活性。程序可以根据需求加载和卸载DLL，使得系统能够更有效地管理内存。它还支持程序的插件式架构，允许在不修改主程序的情况下添加新的功能或模块，从而提升了程序的可扩展性和维护性。</p>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_计算机的算术运算"><a class="link" href="#_计算机的算术运算">3. 计算机的算术运算</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_加法和减法"><a class="link" href="#_加法和减法">3.1. 加法和减法</a></h3>
<div class="paragraph">
<p>加法是数字从右到左逐位相加，并将进位传送到左侧的下一位数字，与手动计算一样。减法也使用加法实现：相应操作数被简单取反后再进行加法操作。</p>
</div>
<div class="sect3">
<h4 id="_加法与减法的溢出判断"><a class="link" href="#_加法与减法的溢出判断">3.1.1. 加法与减法的溢出判断</a></h4>
<div class="paragraph">
<p>由于硬件规模总是有一定限制的，比如字宽为32位，当运算结果超过这个限制时，就会发生溢出。在加法中何时会发生溢出？当不同符号的操作数相加时，不会发生溢出。因为总和一定不会大于其中任意一个操作数。例如，\(-10+4=-6\)。由于操作数可以表示成32位且其总和不大于任一操作数，所以总和也一定能表示成32位。因此，当正负操作数相加时不会发生溢出。在减法中也有类似的不会发生溢出的情况，但原理相反：当操作数的符号相同时，不会发生溢出。为了说明这一点，需要记住\(c-a=c+(-a)\)，这是因为我们通过将第二个操作数取反然后相加来实现减法。因此，当相同符号的操作数相减时，最终会变成相反符号的操作数相加。从上一段落可知，在这种情况下不会发生溢出。知道加法和减法运算在什么时候不会发生溢出固然很好，但如何检测它何时发生呢？显然，加或减两个32位的数字可能产生一个需要33位才能表示的结果。缺少第33位意味着当溢出发生时，符号位被结果的值占用而非结果的正确符号。由于溢出结果只可能多一位，所以只有符号位可能是错误的。因此，当两个正数相加但和为负数时，说明发生了溢出，反之亦然。这个假的和值意味着产生了向符号位的进位。</p>
</div>
<div class="paragraph">
<p>当出现了不合理的运算结果时，意味着发生了溢出。下表展示了溢出发生时的运算、操作数和运算结果。</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">操作</th>
<th class="tableblock halign-left valign-top">操作数A</th>
<th class="tableblock halign-left valign-top">操作数B</th>
<th class="tableblock halign-left valign-top">表明溢出的结果</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(A+B\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(\ge 0\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(\ge 0\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(&lt; 0\)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(A+B\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(&lt; 0\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(&lt; 0\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(\ge 0\)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(A-B\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(\ge 0\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(&lt; 0\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(&lt; 0\)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(A-B\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(&lt; 0\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(\ge 0\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(\ge 0\)</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>无符号整数通常用于表示忽略溢出的内存地址。计算机的有限字长意味着算术运算可能会产生过量而无法用这种固定字长表示的运算结果，即发生溢出。虽然无符号数的溢出容易检测，但无符号数通常使用自然数做地址运算，而程序通常不需要检测地址计算的溢出，所以这些溢出总被忽略。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_乘法"><a class="link" href="#_乘法">3.2. 乘法</a></h3>
<div class="sect3">
<h4 id="_串行版的乘法运算及其硬件实现"><a class="link" href="#_串行版的乘法运算及其硬件实现">3.2.1. 串行版的乘法运算及其硬件实现</a></h4>
<div class="paragraph">
<p>该设计模仿了我们在小学学到的算法，上图展示了该设计的硬件结构。假设乘数位于32位乘法器寄存器中，并且将64位乘积寄存器初始化为0。我们需要在每一步计算中将被乘数左移一位，因为它可能会和之前的中间结果相加。在32步计算之后，32位被乘数会向左移动32位。因此，我们需要一个64位的被乘数寄存器，将其初始化为右半部分的32位被乘数和左半部分的零。然后该寄存器每执行一步便左移1位，将被乘数与64位的乘积寄存器中的中间结果对齐并累加到中间结果。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/3.2.1(1).png" alt="3.2.1(1)">
</div>
</div>
<div class="paragraph">
<p>下图显示了对于操作数的每一位都需要做的三个基本步骤。第一步中的乘数最低位（乘数第0位）决定了是否要把被乘数加到积寄存器当中。第二步中的左移起着将中间操作数左移的作用，就像手工计算做乘法一样。第三步中的右移给出了下次迭代要检测的乘数的下一位。这三个步骤重复32次就会得到最后的积。如果每个步骤花费一个时钟周期，那么该算法计算两个32位数相乘差不多要花费200个时钟周期。像乘法这样的算术运算的重要性随程序的不同而变化，但一般加法和减法出现的次数会是乘法的5到100倍。因此，在许多应用中，乘法花费若干时钟周期并不会显著影响性能。但是，Amdahl定律提醒我们，一个慢速操作如果占据了一定的比例，也会限制程序性能。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/3.2.1(2).png" alt="3.2.1(2)">
</div>
</div>
<div class="paragraph">
<p>这种算法和硬件很容易改进到每步只花费一个时钟周期。加速来源于操作的并行执行：如果乘数位是1.那么对被乘数和乘数进行移位，与此同时，把被乘数加到积上。硬件只需要保证它检测的是乘数的最右位，而且得到的是被乘数移位前的值。注意到寄存器和加法器有未使用的部分后，通常会将加法器和寄存器的位长减半以进一步优化硬件结构。下图展示了修正后的硬件。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/3.2.1(3).png" alt="3.2.1(3)">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_带符号乘法"><a class="link" href="#_带符号乘法">3.2.2. 带符号乘法</a></h4>
<div class="paragraph">
<p>对于如何处理带符号乘法，最简单的方式是先把被乘数和乘数转换为正数，然后记住它们的初始符号。这样，将之前的算法迭代执行31次，符号位不参与计算。正如我们小学学到的那样，只有在乘数和被乘数符号相反时，对积取反。事实证明，如果记住我们正在处理具有无限位长的数，并且只用32位来表示它们，则上面的最后一种算法适用于带符号数。因此，在移位时需要对带符号数的积进行符号扩展。当算法结束时，低位的双字就是32位积。</p>
</div>
</div>
<div class="sect3">
<h4 id="_快速乘法"><a class="link" href="#_快速乘法">3.2.3. 快速乘法</a></h4>
<div class="paragraph">
<p>摩尔定律提供了非常充足的资源，从而使硬件设计人员可以实现更快的乘法硬件。通过在乘法运算开始的时候检查32个乘数位，就可以判定是否要将被乘数加上。快速乘法可以通过为每个乘数位提供一个32位加法器来实现：一个输入是被乘数和一个乘数位相与的结果，另一个输入是上一个加法器的输出。一种简单的方法是将右侧加法器的输出端连接到左侧加法器的输入端，形成一个高64位的加法器栈。另一种方式是将这32个加法器组织成如下图所示的并行树。这样我们就只需要等待\(log_2(32)\)，即5次32位长加法的时间，而不是32次。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/3.2.3.png" alt="3.2.3">
</div>
</div>
<div class="paragraph">
<p>由于使用进位保留加法器，乘法的速度甚至比5次加法还要快，并且因为容易将上述设计流水化，它能够同时支持多个乘法。</p>
</div>
</div>
<div class="sect3">
<h4 id="_risc_v中的乘法"><a class="link" href="#_risc_v中的乘法">3.2.4. RISC-V中的乘法</a></h4>
<div class="paragraph">
<p>为了产生正确带符号或无符号的64位积，RISC-V有四条指令：乘（mul），乘法取高位（mulh)，无符号乘法取高位（mulhu)，有符号/无符号乘法取高位（mulhsu）。要获得整数32位积，应使用mu1指令。要想得到64位积的高32位，如果两个操作数都是有符号的，应使用mulh指令；如果两个操作数都是无符号的，则使用mulhu指令；如果一个操作数是有符号的而另一个是无符号的，则使用mulhsu指令。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_除法"><a class="link" href="#_除法">3.3. 除法</a></h3>
<div class="sect3">
<h4 id="_除法运算及其硬件实现"><a class="link" href="#_除法运算及其硬件实现">3.3.1. 除法运算及其硬件实现</a></h4>
<div class="paragraph">
<p>下图展示了模拟基本除法算法的硬件。在开始时将32位的商寄存器置0.算法的每次迭代都需要将除数右移一位，因此开始需要将除数放置到64位的除数寄存器的左半部分，并且每运算一步并将其右移1位，使之与被除数对齐。余数寄存器初始化为被除数。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/3.3.1(1).png" alt="3.3.1(1)">
</div>
</div>
<div class="paragraph">
<p>下图展示了第一个除法算法的三个步骤。与人不同，计算机没有聪明到能预先知道除数是否小于被除数。它必须先在步骤1中用被除数减去除数，这正是我们实现比较所使用的方式。如果结果是正数或0，则除数小于或等于被除数，所以在商中生成一位1(步骤2a)。如果结果为负，则下一步是通过将除数加回余数来恢复原始值，并在商中生成一位0（步骤2b）。除数右移，然后再次迭代。在迭代完成后，余数和商将存放在其同名的寄存器中。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/3.3.1(2).png" alt="3.3.1(2)">
</div>
</div>
<div class="paragraph">
<p>这个算法及其硬件结构可以被改进得更快且更便宜。通过操作数移位和商与减法同时进行来加速。该细化包括注意哪里有未使用的寄存器和将加法器和寄存器宽度减半。图3-11展示了修改后的硬件。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/3.3.1(3).png" alt="3.3.1(3)">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_有符号除法"><a class="link" href="#_有符号除法">3.3.2. 有符号除法</a></h4>
<div class="paragraph">
<p>计算机中的有符号除法是一种处理带符号整数的除法运算方法，能够正确处理正数和负数之间的除法关系。其核心思想是对符号和数值分别处理，以确保结果的符号正确，并在运算过程中避免符号干扰。以下是处理有符号除法的主要步骤。</p>
</div>
<div class="paragraph">
<p>首先，确定被除数和除数的符号。通过检查两数的符号位（通常是最高有效位），判断它们是否为正数或负数。如果符号相同（两者均为正或均为负），最终的商为正；如果符号不同（一个为正，一个为负），最终的商为负。这一步确定了商的符号，同时便于后续操作只处理数值部分。</p>
</div>
<div class="paragraph">
<p>接着，将被除数和除数的数值部分转换为绝对值进行处理。通过忽略符号位，可以将负数转化为正数，从而将后续的计算简化为无符号除法。随后，计算绝对值的商和余数，这通常是通过硬件或软件实现的无符号整数除法算法完成的。</p>
</div>
<div class="paragraph">
<p>在计算得到商和余数后，需要恢复结果的符号。商的符号按照第一步的判断进行设置，即根据被除数和除数符号是否相同来决定正负号。余数的符号通常与被除数相同，以保持数学意义上的一致性。</p>
</div>
<div class="paragraph">
<p>最后，将符号恢复后的商和余数作为最终结果返回。这个过程确保了除法运算能够正确处理正负数之间的关系，同时保持了计算机中带符号整数的标准表示方式。</p>
</div>
</div>
<div class="sect3">
<h4 id="_快速除法"><a class="link" href="#_快速除法">3.3.3. 快速除法</a></h4>
<div class="paragraph">
<p>摩尔定律适用于除法硬件以及乘法运算，所以希望能够通过其硬件来加速除法。通过使用许多加法器来加速乘法，但不能对除法使用相同的方法。因为在执行下一步运算之前，需要先知道减法结果的符号，而乘法运算可以立即计算32个部分积。有些技术每步可以产生多于一位的商。SRT除法技术试图根据被除数和余数的高位来查找表，以预测每步的多个商的位数。它依靠后续步骤纠正错误预测。今天的典型值是4位。关键在于猜测要减去的值。对于二进制除法，只有一个选择。这些算法使用余数的6位和除数的4位来索引查找表，以确定每个步骤的猜测。</p>
</div>
<div class="paragraph">
<p>这种快速方法的准确性取决于查找表中的值是否合适。3.9节中的谬误展示了如果表不正确将会发生什么情况。</p>
</div>
</div>
<div class="sect3">
<h4 id="_risc_v中的除法"><a class="link" href="#_risc_v中的除法">3.3.4. RISC-V中的除法</a></h4>
<div class="paragraph">
<p>上文中提到的乘法与除法都可以使用相同的顺序执行硬件。唯一需要的是一个可以左右移位的64位寄存器和一个实现加法或减法的32位ALU。</p>
</div>
<div class="paragraph">
<p>为了处理有符号整数和无符号整数，RISC-V有两条除法指令和两条余数指令：除（div），无符号除(divu)，余数（rem），无符号余数（remu）。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_浮点运算"><a class="link" href="#_浮点运算">3.4. 浮点运算</a></h3>
<div class="paragraph">
<p>浮点数的表示基于科学计数法的思想，将数值拆分为三个部分：符号、尾数和指数，从而能够在有限的存储空间内表示非常大的数值范围和较高的精度。浮点数的运算原理涵盖其表示方式、对齐、计算和规范化等多个步骤。</p>
</div>
<div class="paragraph">
<p>浮点数通常采用IEEE 754标准表示。一个浮点数由符号位、指数部分和尾数部分组成。符号位决定数值是正还是负；指数部分采用偏移表示法（通常为偏移值加上实际指数），用来表示浮点数的数量级；尾数部分存储有效数字，并隐含一个固定的基数（如2或10），构成完整的数值表示。</p>
</div>
<div class="paragraph">
<p>在浮点运算中，首先需要对操作数进行对齐。对齐是指通过调整指数，使得两数的指数部分相同，从而保证尾数能够直接参与加法或减法运算。对齐时，较小指数的数值会通过右移尾数来提升指数，可能会丢失部分精度。接下来，计算器会执行尾数的加法、减法、乘法或除法操作，具体过程与整数运算类似，但需要对结果进行额外的处理以符合浮点数的格式。</p>
</div>
<div class="paragraph">
<p>运算完成后，结果可能需要进行规范化和舍入。规范化是指调整尾数和指数，使尾数的最高位为非零，以便最大限度利用存储精度。如果尾数超出浮点数的表示范围，则需要通过调整指数来缩放结果。舍入是为了处理由于尾数截断而导致的误差，常用的舍入方式包括向上取整、向下取整或最近值舍入。</p>
</div>
<div class="paragraph">
<p>浮点运算还需要处理特殊情况，如零、无穷大和非数字（NaN）。这些特殊值由IEEE 754标准定义，用于应对计算中的异常情况。浮点数运算的复杂性主要来自于其需要在保持数值范围和精度之间取得平衡，因此需要硬件和算法的高效支持。浮点运算广泛应用于科学计算、图形处理和工程模拟中，是计算机实现高精度数值计算的重要基础。</p>
</div>
<div class="sect3">
<h4 id="_浮点表示"><a class="link" href="#_浮点表示">3.4.1. 浮点表示</a></h4>
<div class="paragraph">
<p>浮点表示的设计者必须在尾数的位数大小和指数的位数大小之问找到一个平衡，因为固定的字大小意味着若一部分增加一位，则另一部分就得减少一位。即要做精度和范围之间的权衡：增加尾数位数的大小可以提高小数精度，而增加指数位数的大小则可以增加数的表示范围。</p>
</div>
<div class="paragraph">
<p>浮点数通常占用多个字的长度。下图是RISC-V浮点数的表示方法，其中S是浮点数的符号（l表示负数），指数由8位指数字段（包括指数的符号）表示，尾数由23位数表示。正如第2章提过的那样，这种表示称为符号和数值，符号与数值的位是相互分离的。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/3.4.1(1).png" alt="3.4.1(1)">
</div>
</div>
<div class="paragraph">
<p>通常来讲，浮点数可以这样表示：</p>
</div>
<div class="stemblock">
<div class="content">
\[(-1)^S \times F × 2^E\]
</div>
</div>
<div class="paragraph">
<p>F是尾数字段中表示的值，而E是指数字段表示的值。</p>
</div>
<div class="paragraph">
<p>这些指定的指数和尾数位长使RISC-V计算机具有很大的运算范围。小到\(2.0_{10} \times 10^{-38}\)，大到\(2.0_{10} \times 10^{38}\)，计算机都能表示出来。但是它和无穷大不同，所以仍然可能存在数太大而表示不出来的情况。因此，和整点运算一样，浮点运算中也会发生溢出例外。注意这里的溢出表示因指数太大而无法在指数字段中表示出来。</p>
</div>
<div class="paragraph">
<p>浮点运算还会导致出现一种新的例外情况。正如程序员想知道他们什么时候计算了一个难以表示的太大的数一样，他们还想知道他们正在计算的非零小数是否变得小到无法表示，这两个事件都可能导致程序给出不正确的答案。为了和上溢区分开来，我们把这种情况称为下溢。当负指数太大而指数字段无法表示时，就会出现这种情况。</p>
</div>
<div class="paragraph">
<p>减少下溢或上溢发生概率的一种方法是提供另一种具有更大指数范围的格式。在C语言中，这个数据类型称为双精度（double）.基于双精度的运算称为双精度浮点运算，而单精度浮点就是前面介绍的格式。</p>
</div>
<div class="paragraph">
<p>双精度浮点数需要一个RISC-V双字才能表示，如下所示，其中S仍然是数的符号位。指数字段为11位，尾数字段为52位。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/3.4.1(2).png" alt="3.4.1(2)">
</div>
</div>
<div class="paragraph">
<p>RISC-V双精度可以表示的实数范围小到\(2.0_{10} \times 10^{-308}\)，大到\(2.0_{10} \times 10^{308}\)。尽管双精度确实增加了指数字段能表示的范围，但其最主要的优点是由于有更大的尾数位数而具有更高的精度。</p>
</div>
</div>
<div class="sect3">
<h4 id="_例外和中断"><a class="link" href="#_例外和中断">3.4.2. 例外和中断</a></h4>
<div class="paragraph">
<p>在上溢或下溢时应该让计算机发生什么以让用户知道出现了问题?有些计算机会通过引发例外（有时也称作中断）来告知问题的出现。例外或中断在本质上是一种非预期的过程调用。造成溢出的指令的地址保存在寄存器中，并且计算机会跳转到预定义的地址以调用相应的例外处理程序。中断的地址被保存下来，以便在某些情况下可以在执行纠正代码之后继续执行原程序。RISC-V计算机不会在上溢或下溢时引发例外，不过，软件可以读取浮点控制和状态寄存器(fcsr)来检测是否发生上溢或下溢。</p>
</div>
</div>
<div class="sect3">
<h4 id="_ieee754浮点数标准"><a class="link" href="#_ieee754浮点数标准">3.4.3. IEEE754浮点数标准</a></h4>
<div class="paragraph">
<p>IEEE 754 是一种广泛应用于计算机系统的浮点数标准，旨在规范浮点数的表示、运算、舍入和异常处理，使不同计算平台能够一致地处理实数运算。最初的标准于 1985 年发布，后续版本不断改进，支持更广泛的计算需求。以下是该标准的主要内容和特点：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>浮点数的表示</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>IEEE 754 采用类似于科学计数法的形式表示浮点数，通过二进制分解为三个部分：符号位（Sign）、指数部分（Exponent）和尾数部分（Mantissa，又称有效位）。浮点数表示的通用公式为：</p>
</div>
<div class="stemblock">
<div class="content">
\[N = (-1)^S \times F × 2^E\]
</div>
</div>
<div class="paragraph">
<p>其中：</p>
</div>
<div class="paragraph">
<p>S：符号位，表示数值的正负。0 为正数，1 为负数。</p>
</div>
<div class="paragraph">
<p>E：指数部分，使用偏移表示法存储。实际指数通过 E_actual = E_stored - bias 计算，bias 是一个偏移值。</p>
</div>
<div class="paragraph">
<p>M：尾数部分，表示有效数字的二进制小数。标准规定隐含一个整数部分，通常为1。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>特殊值的表示
IEEE 754 设计了特殊值来表示异常或边界情况：</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>零：符号位可以是0或1，指数部分全为0，尾数全为0。</p>
</li>
<li>
<p>无穷大（Infinity）：符号位表示正负，指数部分全为1，尾数全为0。</p>
</li>
<li>
<p>非数字（NaN，Not a Number）：用于表示未定义或无效的结果，如 0/0。指数部分全为1，尾数非零。</p>
</li>
<li>
<p>非规格化数（Denormalized Number）：当指数部分为0且尾数非零时，表示非常接近零的小数。</p>
</li>
</ol>
</div>
</li>
<li>
<p>舍入模式
IEEE 754 提供了多种舍入模式，用于解决尾数截断引发的误差：</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>向最近值舍入（默认）
向零舍入
向正无穷大舍入
向负无穷大舍入</p>
</div>
</div>
<div class="sect3">
<h4 id="_浮点加法"><a class="link" href="#_浮点加法">3.4.4. 浮点加法</a></h4>
<div class="paragraph">
<p>让我们用科学记数法表示的数的手算加法来说明一下浮点数的加法：\(9.999_{10} \times l0^1 + 1.610_{10} \times 10^{-1}\)。假设有效数位中只能保存4位十进制数字，而指数字段只能保存两位十进制数字。</p>
</div>
<div class="paragraph">
<p>第一步：为了能够对这些数做出正确的加法运算，我们必须将指数较小的数的小数点和指数较大的数的小数点对齐。因此，我们需要处理指数较小的数，即\(1.610_{10} \times 10^{-1}\)，让它与具有较大的指数的数的指数相同。我们发现一个非规格化的浮点数可以有多种科学记数法的表示形式，从而可以利用该特性完成指数对齐，即</p>
</div>
<div class="stemblock">
<div class="content">
\[1.610_{10} \times 10^{-1} = 0.1610_{10} \times 10^0 = 0.01610 \times 10^1\]
</div>
</div>
<div class="paragraph">
<p>最右边的数是我们想要的版本，因为它的指数与较大数的指数相等，即\(9.999_{10} \times 10^1\)。因此，第一步将较小数的有效数位进行右移，直到它的指数变得和较大数的指数一样。但是我们只能表示四位十进制数，所以在移位之后的数是：</p>
</div>
<div class="stemblock">
<div class="content">
\[0.016_{10} \times 10^1\]
</div>
</div>
<div class="paragraph">
<p>第二步：将两个数的有效数位相加和为\(10.015_{10}×10^1\)。</p>
</div>
<div class="paragraph">
<p>第三步：这个和没有用规格化的科学记数法表示，因此要调整为：</p>
</div>
<div class="stemblock">
<div class="content">
\[10.015_{10} \times 10^1 = 1.0015_{10} \times 10^2\]
</div>
</div>
<div class="paragraph">
<p>因此，在加法之后，我们必须对和进行移位，适当地调整指数大小，把它变为规格化的形式。这个例子展示了将和右移一位的情况，但是如果一个数是正数而另一个数是负数，那么得到的和可能有许多前导0，这时需要进行左移操作。每当指数增大或减小时，我们都必须检测上溢或下溢，也就是说，必须确保指数大小没有超过指数字段的表示范围。</p>
</div>
<div class="paragraph">
<p>第四步：由于我们假定有效位数可能只有四位（不包括符号位），所以我们必须对最后结果进行舍入。在小学学过的算法中，如果右边多余的数在0和4之间，则直接舍去，如果右边的数在5和9之间，则舍去后前一位加l。前面所得的和为：</p>
</div>
<div class="stemblock">
<div class="content">
\[1.0015_{10} \times 10^2\]
</div>
</div>
<div class="paragraph">
<p>因为小数点右边的第四位数字在5到9之间，所以舍入到四位有效数位的结果是：</p>
</div>
<div class="stemblock">
<div class="content">
\[1.002_{10} \times 10^2\]
</div>
</div>
<div class="paragraph">
<p>请注意，如果我们在舍入的时候运气不好，例如遇到前面各位都是9的情况，那么加上1的和仍不是规格化的，需要再次执行第三步。</p>
</div>
<div class="paragraph">
<p>下图显示了遵循该十进制加法示例的二进制浮点加法的算法。第一步和第二步与刚刚讨论的示例类似：调整指数较小的数的有效数位.让它和另一个较大数的小数点对齐，然后加上两个数的有效数位。第三步对结果进行规格化，并强制检测上溢或下溢。第三步中的上溢和下溢检测取决于操作数的精度。回想一下，指数中全为0的表示被保留并用于0的浮点表示。而且，指数中全为1的表示仅用于标识指定的值和超出正常浮点数范围之外的情况。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_并行性与计算机算术"><a class="link" href="#_并行性与计算机算术">3.5. 并行性与计算机算术</a></h3>
<div class="paragraph">
<p>通过划分进位链，可以同时对多个短向量进行并行操作。即数据级并行</p>
</div>
<div class="paragraph">
<p>由于手机、平板电脑或笔记本电脑中的每个微处理器都有自己的图形显示器，随着晶体管数量的增加，对于图形操作的支持也不可避免地会增加。</p>
</div>
<div class="paragraph">
<p>许多图形系统最初使用8位数据来表示三原色中的一种，外加8位来表示一个像素的位置。在电话会议和视频游戏中添加了扬声器和麦克风对声音进行支持。音频采样需要8位以上的精度，但16位精度就已经足够了。</p>
</div>
<div class="paragraph">
<p>所有微处理器都对字节和半字有特殊支持，使其在存储时占用更少的存储器空间，但在典型的整数程序中对这类大小数据的算术运算非常少，因此几乎不支持除数据传输之外的其他操作。架构师发现，许多图形和音频应用会对这类数据的向量执行相同操作。通过在128位加法器内划分进位链，处理器可以同时对16个8位操作数、8个16位操作数、4个32位操作数或2个64位操作数的短向量进行并行操作。</p>
</div>
<div class="paragraph">
<p>这种分割加法器的开销很小，但带来的加速可能很大。</p>
</div>
<div class="paragraph">
<p>将这种在一个宽字内部进行的并行操作称为子字并行(subword parallelism)。更通用的名称是数据级并行(data level parallelism)。对于单指令多数据，它们也被称为向量或SIMD。多媒体应用程序的逐渐普及促使了支持易于并行计算的窄位宽操作的算术指令的出现。</p>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_处理器"><a class="link" href="#_处理器">4. 处理器</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_单周期处理器实现"><a class="link" href="#_单周期处理器实现">4.1. 单周期处理器实现</a></h3>
<div class="paragraph">
<p>实现一个单周期处理器需要多个关键模块协同工作，以便在一个时钟周期内完成指令的取指、译码、执行、存储访问和写回操作。这些模块包括控制单元、寄存器文件、算术逻辑单元（ALU）、程序计数器（PC）、指令存储器、数据存储器以及各种多路选择器（MUX）和信号通路（Bus）。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>程序计数器（PC）</p>
<div class="literalblock">
<div class="content">
<pre>程序计数器存储当前指令的地址，并在每个时钟周期自动更新以指向下一条指令。PC的输出作为指令存储器的输入地址。对于跳转或分支指令，PC的值可能由控制单元计算并更新。</pre>
</div>
</div>
</li>
<li>
<p>指令存储器</p>
<div class="literalblock">
<div class="content">
<pre>指令存储器根据 PC 提供的地址，输出当前指令的二进制码。指令由操作码（opcode）、寄存器地址（源寄存器、目标寄存器）和立即数等字段组成，这些字段作为后续模块的输入。</pre>
</div>
</div>
</li>
<li>
<p>控制单元</p>
<div class="literalblock">
<div class="content">
<pre>控制单元负责解析指令的操作码，生成控制信号以指导其他模块的行为。例如：
决定 ALU 执行的操作（加、减、逻辑运算等）。
控制数据存储器的读写行为。
控制寄存器文件的数据读写方向。
选择跳转或分支地址。
控制单元的输出信号连接到 ALU、数据存储器、多路选择器和其他模块。</pre>
</div>
</div>
</li>
<li>
<p>寄存器模块</p>
<div class="literalblock">
<div class="content">
<pre>寄存器模块存储处理器的操作数。它包含多个通用寄存器：
根据指令的源寄存器字段，从寄存器文件中读取操作数。
根据目标寄存器字段，将计算结果写回寄存器文件。
寄存器文件的读写操作由控制单元生成的控制信号控制。</pre>
</div>
</div>
</li>
<li>
<p>算术逻辑单元（ALU）</p>
<div class="literalblock">
<div class="content">
<pre>ALU 执行算术和逻辑运算，例如加法、减法、位与、位或等。它的输入操作数来自寄存器模块或立即数，具体取决于指令类型（R 型、I 型等）。ALU 的输出即为运算结果，通常存储回寄存器文件或用于分支条件的判断。</pre>
</div>
</div>
</li>
<li>
<p>数据存储器</p>
<div class="literalblock">
<div class="content">
<pre>数据存储器用于加载或存储数据，支持内存读写操作：
加载指令（如 lw）从数据存储器读取数据，并将其送入寄存器文件。
存储指令（如 sw）将寄存器文件中的数据写入数据存储器。
数据存储器的地址和数据由指令字段和 ALU 的运算结果决定，其读写行为由控制信号控制。</pre>
</div>
</div>
</li>
<li>
<p>多路选择器（MUX）</p>
<div class="literalblock">
<div class="content">
<pre>多路选择器用于在多种可能的输入中选择一个作为输出。主要用途包括：
在立即数和寄存器操作数之间选择 ALU 输入。
在 ALU 输出和数据存储器输出之间选择寄存器写入的数据。
在顺序地址和跳转目标地址之间选择 PC 的下一个值。</pre>
</div>
</div>
</li>
<li>
<p>信号通路和总线</p>
<div class="literalblock">
<div class="content">
<pre>信号通路用于连接各个模块，允许数据和控制信号在模块之间流动。总线是一种共享的通信通道，可用于传递指令、数据或地址。</pre>
</div>
</div>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/4.1.png" alt="4.1">
</div>
</div>
<div class="paragraph">
<p>通过这些模块的紧密配合，单周期处理器能够在一个时钟周期内完成一条指令的全部执行过程。虽然结构简单，但由于所有操作都必须在单个周期内完成，其性能受限于最慢路径的延迟。</p>
</div>
<div class="sect3">
<h4 id="_逻辑设计的基本方法"><a class="link" href="#_逻辑设计的基本方法">4.1.1. 逻辑设计的基本方法</a></h4>
<div class="paragraph">
<p>RISC-V实现中的数据通路包含两种不同类型的逻辑单元：处理数据值的单元和存储状态的单元。处理数据值的单元是组合逻辑，它们的输出仅依赖于当前输人。给定相同的输人，组合逻辑单元总是产生相同的输出。例如，ALU就是一个组合逻辑单元。由于组合逻辑单元没有内部存储功能，当给定一组输人时，它总是产生相同的输出。</p>
</div>
<div class="paragraph">
<p>设计中的其他单元不是组合逻辑，而是包含状态的。如果一个单元有内部存储功能，它就包含状态，称其为状态单元。这是因为关机后重启计算机，通过恢复状态单元的原值，计算机可继续运行，就像没有发生过断电一样。进一步地，这些状态单元可以完整地表征计算机。例如，指令存储器、数据存储器以及寄存器都是状态单元。</p>
</div>
<div class="paragraph">
<p>一个状态单元至少有两个输人和一个输出。必需的输入是要写入状态单元的数据值和决定何时写入数据值的时钟信号。状态单元的输出提供了在前一个时钟周期写入单元的数据值。例如，逻辑上最简单的一种状态单元是D触发器，它有两个输入(一个数据值和一个时钟）和一个输出。除了触发器，RISC-V的实现中还用到了另外两种状态单元：存储器和寄存器。状态单元何时被写入由时钟确定，但是它随时可以被读。</p>
</div>
<div class="paragraph">
<p>包含状态的逻辑部件也被称为时序的，因为其输出取决于输人和内部状态。例如，表示寄存器的功能单元的输出取决于所提供的寄存器号和之前写人寄存器的内容。</p>
</div>
<div class="paragraph">
<p><strong>时钟同步方法</strong></p>
</div>
<div class="paragraph">
<p>时钟同步方法（clocking methodology）规定了信号可以读出和写入的时间。规定信号的读写时间非常重要，因为如果在读信号的同时写信号，那么读到的值可能是该信号的旧值，也可能是新写入的值，甚至可能是二者的混合。计算机设计无法容忍这种不可预测性。时钟同步方法就是为避免这种情况而提出的。</p>
</div>
<div class="paragraph">
<p>为简单起见，假定我们采用边沿触发的时钟(edge-triggered clocking)，即存储在时序逻辑单元中的所有值仅在时钟边沿更新，这是从低电平快速跳变到高电平（反之亦然）的过程。因为只有状态单元能存储数据值，所有组合逻辑单元都必须从状态单元集合接收输入，并将输出写入状态单元集合。其输入是之前某时钟周期写入的值，输出的值可以在后续时钟周期使用。</p>
</div>
</div>
<div class="sect3">
<h4 id="_数据通路"><a class="link" href="#_数据通路">4.1.2. 数据通路</a></h4>
<div class="paragraph">
<p>数据通路是计算机处理器中一个核心的硬件部分，专门用于传输、存储和处理指令和数据。它由寄存器、算术逻辑单元（ALU）、多路选择器（MUX）、数据总线、存储器等模块组成，负责在指令执行过程中完成数据的流动和运算操作。数据通路通过硬件资源的协同工作，将指令的每个步骤具体化，从而实现处理器功能。</p>
</div>
<div class="paragraph">
<p>数据通路的作用是完成指令执行的全部过程，包括指令的取指、译码、执行、存储访问和写回操作。通过程序计数器（PC），数据通路能够确定当前指令的位置并从指令存储器中读取；通过寄存器文件和 ALU，数据通路可以完成算术和逻辑运算；通过多路选择器和数据总线，数据通路能在不同的硬件模块之间高效地传递数据；通过数据存储器，数据通路支持加载和存储操作。它的设计决定了处理器的性能、效率和指令支持能力，是实现计算任务的硬件基础。</p>
</div>
</div>
<div class="sect3">
<h4 id="_为什么现在不使用单周期实现"><a class="link" href="#_为什么现在不使用单周期实现">4.1.3. 为什么现在不使用单周期实现</a></h4>
<div class="paragraph">
<p>尽管单周期设计可以正确工作，但是在现代设计中不采取这种方式，因为它的效率太低。究其原因，是在单周期设计中时钟周期对于每条指令必须等长。这样，处理器中的最长路径决定了时钟周期。这条路径很可能是一条load指令，它连续地使用5个功能单元：指令存储器、寄存器堆、ALU、数据存储器和寄存器堆。虽然CP1为1（见第1章），但由于时钟周期太长，单周期实现的整体性能可能很差。使用单周期设计的代价是显著的，但对于这个小指令集而言，或许是可以接受的。历史上，早期具有简单指令集的计算机确实采用这种实现方式。但是，如果要实现浮点单元或更复杂的指令集，单周期设计根本无法正常工作。由于时钟周期必须满足所有指令中最坏的情况，所以不能使用那些缩短常用指令执行时间而不改变最坏情况的实现技术。因此，单周期实现违反了第1章中加速经常性事件这一设计原则。在4.6节，我们将看到一种称为流水线的实现技术，它使用与单周期相似的数据通路，但吞吐量更高，效率更高。流水线技术通过同时执行多条指令来提高效率。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_多周期实现"><a class="link" href="#_多周期实现">4.2. 多周期实现</a></h3>
<div class="paragraph">
<p>在多周期实现中，执行中的每一步都需要1个时钟周期。多周期实现允许每个指令多次使用同一个功能单元，只要它在不同的时钟周期内使用。这种共享有助于减少所需的硬件数量。允许指令采用不同数量的时钟周期，以及在单条指令的执行中共享功能单元是多周期设计的主要优势。虽然多周期实现可以降低硬件成本，但今天几乎所有的芯片都使用流水线来提高性能。</p>
</div>
<div class="paragraph">
<p>多周期处理器是一种通过将指令执行过程划分为多个阶段、在多个时钟周期内完成的处理器设计。相比单周期处理器，多周期处理器可以在不需要重复硬件资源的情况下完成指令执行，从而实现更高的硬件利用率和更灵活的设计。其主要组成模块包括控制单元、程序计数器（PC）、指令存储器、寄存器文件、算术逻辑单元（ALU）、数据存储器和多路选择器等。</p>
</div>
<div class="paragraph">
<p>多周期处理器的工作流程通过阶段化的方式逐步完成每条指令的执行。首先，程序计数器提供当前指令的地址，指令存储器根据地址取出指令并送入控制单元。控制单元解析指令，生成对应的控制信号，引导寄存器文件从指定寄存器中读取操作数，同时为后续阶段设定路径。接下来，ALU 执行算术或逻辑运算，或者用于计算存储器的访问地址。对于加载或存储指令，ALU 的输出作为地址输入到数据存储器，数据存储器根据指令类型进行读写操作。最后，处理器将运算结果或者从存储器读取的数据写回寄存器文件，完成指令的执行。</p>
</div>
<div class="paragraph">
<p>在多周期处理器中，每个时钟周期只执行一部分工作，例如取指、译码、执行、存储访问或写回。这种设计允许同一硬件资源（如 ALU 或数据存储器）在不同阶段为不同指令使用，因此相较于单周期处理器，硬件资源需求更低。此外，多周期处理器的控制单元采用有限状态机（FSM）设计，根据当前指令的类型和执行阶段生成精确的控制信号，确保每个模块在正确的时间参与操作。</p>
</div>
<div class="paragraph">
<p>多周期处理器通过分阶段执行，平衡了性能与硬件资源之间的关系，使其适合于资源有限的系统设计，同时可以支持复杂指令集。然而，由于指令完成时间不固定，其性能通常低于流水线处理器，但更容易实现且硬件开销较低。</p>
</div>
</div>
<div class="sect2">
<h3 id="_流水线概述"><a class="link" href="#_流水线概述">4.3. 流水线概述</a></h3>
<div class="paragraph">
<p>流水线是一种能使多条指令重叠执行的实现技术。使用流水线来使指令能重叠执行，以提高性能。即指令级并行（ILP）。目前，流水线技术广泛应用。</p>
</div>
<div class="paragraph">
<p>下面使用一个比喻概述流水线的概念及相关问题。</p>
</div>
<div class="paragraph">
<p>任何做洗衣工作的人都不自觉地使用流水线技术。非流水线的洗衣过程包含如下步骤：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>将一批脏衣服放入洗衣机。</p>
</li>
<li>
<p>洗衣机洗完后，将湿衣服取出并放入烘干机</p>
</li>
<li>
<p>烘干机完成后，将干衣服取出，放在桌上并叠起来</p>
</li>
<li>
<p>叠好后，请你的室友帮忙把衣服收好。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>当这一批衣服收好后，再开始洗下一批脏衣服。</p>
</div>
<div class="paragraph">
<p>流水线方法花费的时间少得多。当第一批衣服从洗衣机中取出并放人烘干机后，就可以把第二批脏衣服放入洗衣机。当第一批衣服烘干完成后，就可以把它们放在桌上叠起来，同时把洗衣机中洗好的衣服放入烘干机，再将下一批脏衣服放入洗衣机。接着让你的室友把第一批衣服从桌上收好，你开始叠第二批衣服，烘干机开始烘干第三批衣服，同时可以把第四批衣服放人洗衣机。此时，所有的洗衣步骤（称为流水线阶段）在同时工作。只要每个阶段使用不同的资源，我们就可以用流水线的方法完成任务。</p>
</div>
<div class="paragraph">
<p>流水线的矛盾在于，对于一双脏袜子，从把它放人洗衣机到被烘干、叠好和收起的时间在流水线中并没有缩短；然而对于许多负载来说，流水线更快的原因是所有工作都在并行地执行。所以单位时间能够完成更多工作，流水线提高了洗衣系统的吞吐率（throughput)。因此，流水线不会缩短洗一次衣服的时间，但是当有很多衣物需要洗时，吞吐率的提高减少了完成整个任务的时间。</p>
</div>
<div class="paragraph">
<p>如果每个步骤需要的时间相同，并且要完成的工作足够多，那么由流水线产生的加速比等于流水线中步骤的数目，在这个例子中是4倍：洗涤、烘干、折叠和收起。因此，流水线方式洗衣是非流水线方式洗衣速度的4倍：流水线中20次洗衣需要的时间是一次洗衣的5倍，而20次非流水线洗衣的时间是一次洗衣的20倍。</p>
</div>
<div class="paragraph">
<p>同样的原则也可用于处理器，即采用流水线方式执行指令。RISC-V指令执行通常包含五个步骤：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>从存储器中取出指令。</p>
</li>
<li>
<p>读寄存器并译码指令。</p>
</li>
<li>
<p>执行操作或计算地址。</p>
</li>
<li>
<p>访问数据存储器中的操作数（如有必要）。</p>
</li>
<li>
<p>将结果写入寄存器（如有必要）。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>因此，本章探讨的RISC-V流水线有五个阶段，正如流水线加速洗衣过程一样。</p>
</div>
<div class="sect3">
<h4 id="_面向流水线的指令系统设计"><a class="link" href="#_面向流水线的指令系统设计">4.3.1. 面向流水线的指令系统设计</a></h4>
<div class="paragraph">
<p>尽管上面的例子只是对流水线的简单介绍，但我们也能够通过它了解面向流水线设计的RISC-V指令系统。</p>
</div>
<div class="paragraph">
<p>第一，所有RISC-V指令长度相同。这个限制简化了流水线第一阶段取指令和第二阶段指令译码。在像x86这样的指令系统中，指令长度从1字节到15字节不等，流水线设计更具挑战性。现代x86架构在实现时，将x86指令转换为类似RISC-V指令的简单操作，然后流水化这些简单操作，而不是流水化原始的x86指令。</p>
</div>
<div class="paragraph">
<p>第二，RISC-V只有几种指令格式，源寄存器和目标寄存器字段的位置相同。</p>
</div>
<div class="paragraph">
<p>第三，存储器操作数只出现在RISC-V的load或store指令中。这个限制意味着可以利用执行阶段来计算存储器地址，然后在下一阶段访问存储器。如果可以操作内存中的操作数，就像在x86中一样，那么第三阶段和第四阶段将扩展为地址计算阶段、存储器访问阶段和执行阶段。</p>
</div>
</div>
<div class="sect3">
<h4 id="_流水线数据通路和控制"><a class="link" href="#_流水线数据通路和控制">4.3.2. 流水线数据通路和控制</a></h4>
<div class="paragraph">
<p>下图显示了4.4节中提到的单周期数据通路，并且标识了流水线阶段。将指令划分成五个阶段意味着五级流水线，还意味着在任意单时钟周期里最多执行五条指令。相应的，我们必须将数据通路划分成五个部分，将每个部分用对应的指令执行阶段来命名：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>IF：取指令</p>
</li>
<li>
<p>ID：指令译码和读寄存器堆</p>
</li>
<li>
<p>EX：执行或计算地址</p>
</li>
<li>
<p>MEM：存储器访问</p>
</li>
<li>
<p>WB：写回</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>在下图中，这五个部分与图中数据通路的绘制方式是对应的，指令和数据通常随着执行过程从左到右依次通过这五个阶段。再回到我们的洗衣类比，在通过工作线路时衣服依次被清洁、烘干和整理，同时永远不会逆向移动。然而，在从左到右的指令流动过程中存在两个特殊情况：在写回阶段，它将结果写回位于数据通路中段的寄存器堆中。在选择下一PC值时，在自增PC值与MEM阶段的分支地址之间进行选择。从右到左的数据流向不会对当前的指令造成影响，这种反向的数据流动只会影响流水线中的后续指令。需要注意的是，第一种特殊情况会导致数据冒险，第二种会导致控制冒险。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/4.3.2(1).png" alt="4.3.2(1)">
</div>
</div>
<div class="paragraph">
<p>我们可以通过引入寄存器保存数据的方式，使得部分数据通路可以在指令执行的过程中被共享。</p>
</div>
<div class="paragraph">
<p>举例来说，指令存储器只在指令的五个阶段中的一个阶段被使用，而在其他四个阶段中允许被其他指令共享。为了保留在其他四个阶段中的指令的值，必须把从指令存储器中读取的数据保存在寄存器中。类似的理由适用于每个流水线阶段，所以我们必荣将寄存器放置在上图中每个阶段之间的分隔线上。再回到洗衣例子中，我们会在每两个步骤之间放置一个篮子，用于存放为下一步所准备的衣服。</p>
</div>
<div class="paragraph">
<p>下图显示了流水线数据通路，其中的流水线寄存器被高亮表示。所有指令都会在每一个时钟周期里从一个流水线寄存器前进到下一个寄存器中。寄存器的名称由两个被该寄存器分开的阶段的名称来命名。例如，F和ID阶段之间的流水线寄存器被命名为IF/D。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/4.3.2(2).png" alt="4.3.2(2)">
</div>
</div>
<div class="paragraph">
<p>需要注意的是，在写回阶段的最后没有流水线寄存器。所有的指令都必须更新处理器中的某些状态，如寄存器堆、存储器或PC等、因此、单独的流水线寄存器对于已经被更新的状态来说是多余的。例如，加载指令将它的结果放人32个寄存器中的一个，此后任何需要该数据的指令只需要简单地读取相应的寄存器即可。</p>
</div>
<div class="paragraph">
<p>当然，每条指令都会更新PC，无论是通过自增还是通过将其设置为分支目标地址。PC可以被看作一个流水线寄存器：它给流水线的F阶段提供数据。不同于上图中被标记阴影的流水线寄存器，PC是可见体系结构状态的一部分，在发生例外时，PC中的内容必须被保存，而流水线寄存器中的内容则可以被丢弃。在洗衣的例子中，你可以将PC看作在清步骤之前盛放脏衣服的篮子。</p>
</div>
</div>
<div class="sect3">
<h4 id="_利用指令级并行的基本编译器技术"><a class="link" href="#_利用指令级并行的基本编译器技术">4.3.3. 利用指令级并行的基本编译器技术</a></h4>
<div class="ulist">
<ul>
<li>
<p>找出除维护循环的代码外互不相关的循环迭代，判定循环展开是有用的。</p>
</li>
<li>
<p>使用不同寄存器，以避免由于不同运算使用相同寄存器而造成的非必要约束（比如，名称依赖）。</p>
</li>
<li>
<p>去除多余的测试和分支指令，并调整循环终止与迭代代码。</p>
</li>
<li>
<p>通过观察不同迭代中的载人指令与存储指令互不相关，判定展开后的循环中的载人指令和存储指令可以交换位置。这一变换需要分析存储器地址，确认它们没有引用同一地址。</p>
</li>
<li>
<p>在保留必要的依赖，以得到与原代码相同的结果的前提下，对代码进行调度。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>要进行所有这些变换，关键是要理解指令之间的依赖关系，而且要知道在这些关系下如何改变指令或调整指令的顺序。</p>
</div>
<div class="paragraph">
<p>有3种效果会限制循环展开带来的好处：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>每次展开操作分摊的开销降低；</p>
</li>
<li>
<p>代码规模限制;</p>
</li>
<li>
<p>编译器限制。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>我们首先考虑循环开销问题。将循环展开4次时，它在指令之间产生了足够的并行性，可以在没有停顿周期的情况下调度循环。事实上，在14个时钟周期中，只有2个周期是循环开销：维护索引值的addt和终止循环的bne。如果将循环展开8次，这一开销将从每个元素1/2周期降低到1/4周期。</p>
</div>
<div class="paragraph">
<p>展开的第二个限制是代码规模的增长。对于较大规模的循环，代码规模的增长可能是一个问题，特别是当它会导致指令缓存缺失率上升时。</p>
</div>
<div class="paragraph">
<p>还有一个通常比代码规模更重要的因素，就是由于大量进行展开和调度而造成寄存器数量不足。由于在大段代码中进行指令调度而产生的这一副作用被称为寄存器紧缺（register pressure）。之所以会出现这种情况，是因为调度代码以增加IP时导致存活值的数量增加。在大量进行指令调度之后，可能无法将所有存活值都分配到寄存器中。尽管转换后的代码在理论上运行速度更快，但由于它会造成寄存器紧缺，所以可能会损失部分乃至全部收益。在没有展开循环时，分支就足以限制大量使用调度，所以寄存器紧缺几乎不会成为问题。但是，循环展开与大量调度结合起来却可能导致这一问题。在需要暴露更多独立指令序列的多发射处理器中，这个问题变得尤其具有挑战性，因为这些指令序列的执行可能是重叠的。一般来说，高级、复杂转换的应用导致现代编译器的复杂度大幅增加，而在生成具体代码之前，很难度量这种应用带来的可能提升。</p>
</div>
<div class="paragraph">
<p>循环展开是一种简单但有用的方法，能够增大可以有效调度的直线代码片段的规模。这种转换在各种处理器上都非常有用，从前面研究过的简单流水线，到多发射超标量，再到本章后面要研究的VLIW。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_冒险与竞争"><a class="link" href="#_冒险与竞争">4.4. 冒险与竞争</a></h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">冒险类型</th>
<th class="tableblock halign-left valign-top">原因</th>
<th class="tableblock halign-left valign-top">解决方案</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">结构冒险</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">硬件不支持多条指令在同一时钟周期执行</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">可以在设计流水线时避免</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">数据冒险</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">一个指令必须等待其他指令的结果才能完成导致的停顿为数据冒险</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">采用前递或旁路、动态调度技术优化</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">控制冒险</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在分支判断结果未出现时，无法得知下一条指令是什么，导致停顿</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">采用分支预测技术优化</p></td>
</tr>
</tbody>
</table>
<div class="sect3">
<h4 id="_结构冒险"><a class="link" href="#_结构冒险">4.4.1. 结构冒险</a></h4>
<div class="paragraph">
<p>硬件不支持多条指令在同一时钟周期执行。在洗衣例子中，如果用洗衣烘干一体机而不是分开的洗衣机和烘干机，或者如果你的室友正在做其他事情而不能收好衣服，都会发生结构冒险。这时，我们精心设计的流水线就会受到破坏。如上所述，RISC-V指令系统是面向流水线设计的，这使得设计人员在设计流水线时很容易避免结构冒险。</p>
</div>
</div>
<div class="sect3">
<h4 id="_数据冒险"><a class="link" href="#_数据冒险">4.4.2. 数据冒险</a></h4>
<div class="paragraph">
<p>假设你在叠衣服时发现一只袜子找不到与之匹配的另一只。一种可能的策略是跑到房间，在衣橱中找，看是否能找到另一只。显然，当你在找袜子时，完成烘干准备被折叠的衣服和那些已经洗完准备去烘干的衣服，不得不停顿等待。在计算机流水线中，数据冒险源于一条指令依赖于前面一条尚在流水线中的指令(这种关系在洗衣例子中并不存在)。</p>
</div>
<div class="paragraph">
<p>例如，假设有一条加法指令，它后面紧跟着一条使用加法的和的减法指令(x19)：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-asm" data-lang="asm">add x19, x0, x1

sub x2, x19, ×3</code></pre>
</div>
</div>
<div class="paragraph">
<p>在不做任何干预的情况下，这一数据冒险会严重地阻碍流水线。add指令直到第五个阶段才写结果，这将浪费三个时钟周期。尽管可以尝试通过编译器来消除这些冒险，但结果并不令人满意。这些依赖经常发生，并且导致的延迟太长，所以不可能指望编译器将我们从这个困境中解救出来一种基本的解决方案是基于以下发现：不需要等待指令完成就可以尝试解决数据冒险。对于上面的代码序列，一旦ALU计算出加法的和，就可将其作为减法的输入。向内部资源添加额外的硬件以尽快找到缺少的运算项的方法，称为前递（forwarding）或旁路(bypassing)</p>
</div>
<div class="paragraph">
<p>前递的效果很好，但不能避免所有的流水线停顿。有时候即使使用前递，流水线也不得不停顿一个阶段来处理载入-使用型数据冒险（load-use data hazard）。这引出了流水线的一个重要概念，正式叫法是流水线停顿（pipeline stall），但通常俗称为气泡（bubble）。</p>
</div>
<div class="paragraph">
<p>当一条load指令之后紧跟着一条需要使用其结果的R型指令时，即使使用前递也需要停顿。如果不停顿，从存储器访问阶段的输出到执行阶段的输入这条路径意味着时间倒流，这是不可能的。该图实际是一个示意图，因为直到sub指令被取出并译码后才知道是否需要停顿。</p>
</div>
</div>
<div class="sect3">
<h4 id="_用动态调度克服数据冒险"><a class="link" href="#_用动态调度克服数据冒险">4.4.3. 用动态调度克服数据冒险</a></h4>
<div class="paragraph">
<p>除非是流水线中的已有指令与要读取的指令之间存在数据依赖，而且无法通过旁路或前递来隐藏这一数据依赖，否则，简单的静态调度流水线就会提取一条指令并发射出去。（前递逻辑可以减少实际流水线延迟，所以某些依赖不会导致冒险。）如果存在不能隐藏的数据依赖，那么冒险检测硬件会从使用该结果的指令开始，将流水线置于停顿状态。在清除这一依赖之前，不会提取和发射新的指令。</p>
</div>
<div class="paragraph">
<p>在动态调度中，硬件会重新安排指令的执行顺序以减少停顿，同时保持数据流和异常行为。动态调度有几个优点:</p>
</div>
<div class="paragraph">
<p>第一，它允许针对一种流水线编译的代码在不同类型的流水线上高效执行，不需要多个二进制文件，也无须为不同的微体系结构重新速行编译。如今，大多数软件来自第三方，而且是以二进制文件形式分发的，这种计算环境使上述优势更加明显。</p>
</div>
<div class="paragraph">
<p>第二，它可以应对编译时依赖关系未知的情况；比如，这些依赖可能涉及存储器访问或者与数据有关的分支，或者，它们可能源自使用动态链接或动态分发的现代编程环境。</p>
</div>
<div class="paragraph">
<p>第三，也可能是最重要的一个优点，它允许处理器容忍一些预料之外的延迟，比如缓存缺失，它可以在等待解决缺失问题时执行其他代码。</p>
</div>
<div class="paragraph">
<p>尽管动态调度的处理器不能改变数据流，但它会在存在依赖关系时尽力避免停顿。相反，由编译器调度的静态流水线尽量将停顿时间降至最低，具体方法是隔离相关指令，使它们不会导致骨险。当然，对于那些本来准备在采用动态调度流水线的处理器上运行的代码，也可以使用编译器流水线调度。</p>
</div>
<div class="paragraph">
<p>简单流水线技术的一个主要限制是，它们使用顺序指令发射与执行：指令按程序顺序发射；如果一条指令停顿在流水线中，后续指令都不能执行。因此，如果流水线中两条相距很近的指令存在依赖关系，就会导致冒险和停顿。如果存在多个功能单元，这些单元也可能处于空闲状态。如果指令j依赖于长时间运行的指令i（当前正在流水线中执行），那么j之后的所有指令都必须停顿，直到i完成、j可以执行为止。例如，考虑以下代码：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-asm" data-lang="asm">fdiv.d f0.12.f4

fadd.d f10.f0.r8

fsub.d f12.f8.f14</code></pre>
</div>
</div>
<div class="paragraph">
<p>由于fadd.d对fdiv.d的依赖性会导致流水线停顿，所以fsub.d指令不能执行；但是，fsub.d与流水线中的任何指令都没有数据依赖性。这一冒险会对性能造成限制，如果不需要以程序顺序来执行指令，就可以消除这一限制。</p>
</div>
<div class="paragraph">
<p>在经典的五级流水线中，可在指令译码（ID）期间检查结构冒险和数据冒险：当一个指令可以无冒险执行时，它会从ID发射出去，并确认所有数据冒险都已解决。</p>
</div>
<div class="paragraph">
<p>为了能够开始执行上面例子中的fsub.d，必须将发射过程分为两个部分：检查所有结构胃险和等待数据冒险的消失。因此，我们仍然使用顺序指令发射（即按程序顺序发射指令），但我们希望一条指令能够在其数据操作数可用时立即开始执行。这样的流水线实际是乱序执行(out-of-order execution），这也就意味着乱序完成(out-of-order completion)。</p>
</div>
<div class="paragraph">
<p>乱序执行可能导致WAR冒险和WAW冒险，而这些冒险在这个五级整数流水线及其逻辑扩展中的顺序浮点流水线中是不存在的。考虑以下RISC-V浮点代码序列：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-asm" data-lang="asm">fdiv.d f0.f2.f4

fmul.d f6.f0.f8

fadd.d f0.f10.f14</code></pre>
</div>
</div>
<div class="paragraph">
<p>在fmul.d和fadd.d之间存在反依赖（对于寄存器f0），如果流水线在fmul.d（在等待fdiv.d)之前执行fadd.d，将会违反反依赖性，产生WAR冒险。与此类似，为了避免违反输出依赖，比如由fadd.d在fdiv.d完成之前写入f0，就必须处理WAW冒险。后面将会看到，利用寄存器重命名可以避免这两种冒险。</p>
</div>
<div class="paragraph">
<p>乱序完成还会使异常处理变得复杂。采用乱序完成的动态调度必须保留异常行为，使那些在严格按照程序顺序执行程序时会发生的异常仍然会实际发生，并且不会发生其他异常。动态调度的处理器会通过推迟相关异常的发布来保留异常行为，直到处理器知道该指令就是接下来要完成的指令为止。</p>
</div>
<div class="paragraph">
<p>尽管异常行为必须保留，但动态调度的处理器可能造成非精确异常。如果在发生异常时，处理器的状态与严格按照程序顺序执行指令时的状态不完全一致，就说这一异常是非精确的。非精确异常可以因为以下两种可能性而发生:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>流水线在执行导致异常的指令时，可能已经完成了按照程序顺序排在这一指令之后的指令。</p>
</li>
<li>
<p>流水线在执行导致异常的指令时，可能还没有完成按照程序顺序排在这一指令之前的指令。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>非精确异常增大了在异常之后重新开始执行的难度。我们在这一节不会解决这些问题，而是讨论一种解决方案，这种方案能够在具有推测功能的处理器环境中提供精确异常。</p>
</div>
<div class="paragraph">
<p>为了能够进行乱序执行，我们将五级简单流水线的ID流水级大体分为以下两个阶段:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>发射（issue）——指令译码，检查结构冒险。</p>
</li>
<li>
<p>读取操作数——一直等到没有数据冒险后，然后读取操作数。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>指令读取阶段在发射阶段之前，既可以把指令放到指令寄存器中，也可能放到一个待完成指令队列中，然后从指令寄存器或队列发射这些指令。执行阶段跟在读取操作数阶段之后，这一点和五级流水线中一样。执行过程可能需要多个周期，具体数目取决于所执行的操作。</p>
</div>
<div class="paragraph">
<p>我们区分一个指令开始执行和完成执行的时刻，在这两个时刻之间，指令处于执行过程中。我们的流水线允许同时执行多条指令，如果没有这一功能，就会失去动态调度的主要优势。要同时执行多条指令，需要有多个功能单元或流水化功能单元，或者两者兼有。由于这两种功能（流水化功能单元和多个功能单元）在流水线控制方面大体相当，所以我们假定处理器拥有多个功能单元。</p>
</div>
<div class="paragraph">
<p>在动态调度流水线中，所有指令都顺序经历发射阶段（顺序发射）；但是，它们可能在第二阶段（读取操作数阶段）停顿或者相互旁路，从而进人乱序执行状态。记分牌（scoreboarding）技术允许在有足够资源且不存在数据依赖时乱序执行指令。它的名字源于开创了这项技术的CDC600记分牌。还有一个比较重要的算法为Tomasulo 算法。它们之间的主要区别在于，Tomasulo算法通过对寄存器进行有效的动态重命名来处理反依赖和输出依赖。此外。还可以对Tomasulo算法进行扩展，用来处理推测，这种技术通过预测一个分支的输出、执行预则目标地址的指令、在预测错误时采取纠正措施，降低控制依赖的影响。虽然使用记分牌可能足以支持简单的处理器，但更复杂、更高性能的处理器则要利用推测技术。</p>
</div>
</div>
<div class="sect3">
<h4 id="_控制冒险"><a class="link" href="#_控制冒险">4.4.4. 控制冒险</a></h4>
<div class="paragraph">
<p>控制冒险出现在以下情况：需要根据一条指令的结果做出决定，而其他指令正在执行。</p>
</div>
<div class="paragraph">
<p>假设洗衣店的工作人员接到一个令人高兴的任务：清洁足球队队服。根据衣服的污浊程度，需要确定清洗剂的用量和水温设置是否合适，以致能洗净衣物又不会由于清洗剂过量而磨损衣物。在洗衣流水线中，必须等到第二步结束，检查已经烘干的衣服，才知道是否需要改变洗衣机设置。这种情况该怎么办？</p>
</div>
<div class="paragraph">
<p>有两种办法可以解决洗衣问题中的控制冒险，也适用于计算机中的相同问题，以下是第一种办法。</p>
</div>
<div class="paragraph">
<p>停顿：第一批衣物被烘干之前，按顺序操作，并且重复这一过程直到找到正确的洗衣设置为止。这种保守的方法当然有效，但速度很慢。计算机中相同的问题是条件分支指令。请注意，在取出分支指令后，紧跟着在下一个时钟周期就会取下一条指令。但是流水线并不知道下一条指令应该是什么，因为它刚刚从存储器中取出分支指令！就像洗衣问题一样，一种可能的解决方案是在取出分支指令后立即停顿，一直等到流水线确定分支指令的结果并知道要从哪个地址取下一条指令为止。</p>
</div>
<div class="paragraph">
<p>对于较长的流水线，通常无法在第二阶段解决分支指令的问题，那么每个条件分支指令都停顿，将导致更严重的速度下降。由此产生了解决控制冒险的第二个方法：</p>
</div>
<div class="paragraph">
<p>预测：如果你确定清洗队服的设置是正确的，就预测它可以工作，那么在等待第一批衣服被烘干的同时清洗第二批衣服。如果预测正确，这个方法不会减慢流水线。但是如果预测错误，就需要重新清洗做预测时所清洗的那些衣服。</p>
</div>
<div class="paragraph">
<p>计算机确实采用预测来处理条件分支。一种简单的方法是总是预测条件分支指令不发生跳转。如果预测正确，流水线将全速前进。只有条件分支指令发生跳转时，流水线才会停顿。更成熟的分支预测是预测一些条件分支指令发生跳转，而另一些不发生跳转。在洗衣的类比中，夜晚和主场比赛的队服采用一种洗衣设置，而白天和客场比赛的队服则采用另一种设置。在计算机程序中，循环底部是条件分支指令，并会跳转回到循环的顶部。由于它们很可能发生分支并且向回跳转，所以可以预测发生分支并跳到靠前的地址处。</p>
</div>
<div class="paragraph">
<p>这种分支预测方法依赖于始终不变的行为，没有考虑到特定分支指令的特点。与之形成鲜明对比的是，动态硬件预测器根据每个条件分支指令的行为进行预测，并在程序生命周期内可能改变条件分支的预测结果。对于洗衣例子，使用动态预测方法，一名店员查看队服的污程度并预测洗衣设置，同时根据最近的成功预测调整下一次的题测。动态预测的一种常用实现方法是保存每个条件分支是否发生分支的历史记录，然后根据最近的过去行为来预测未来。历史记录的数量和类型足够多时，动态分支预测器的正确率超过90%。当预测错误时，流水线控制必须确保预测错误的条件分支指令之后的指令执行不会生效，并且必须从正确的分支地址处重新启动流水线。在洗衣例子中，必须停止接受新的任务，以便可以重新启动预测错误的任务如同其他解决冒险的方案一样，较长的流水线会恶化预测的性能，并增加预测错误的代价。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_例外"><a class="link" href="#_例外">4.5. 例外</a></h3>
<div class="paragraph">
<p>控制逻辑是处理器设计中最有挑战的部分：验证正确性最为困难，同时也最难进行时序优化。例外（cexception）和中断（interupt）是控制逻辑需要实现的任务之一。除分支指令外，它是另一种改变指令执行控制流的方式。最初，人们使用它们是为了处理CPU内部的意外事件，例如未定义指令。后续经扩展也可处理与CPU进行通信的LO设备。</p>
</div>
<div class="paragraph">
<p>许多体系结构设计者和相关书籍作者并不区分中断和例外，经常使用其中一种同时指代两者。比如，Intelx86中就是使用中断。在本书中，我们使用例外来指代意外的控制流变化，而这些变化无须区分产生原因是来自于处理器内部还是外部；使用中断仅仅指代由处理器外部事件引发的控制流变化。下表是一些示例，包括例外的类型、引发例外的事件来源以及在RISC-V体系结构中的表示。</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">事件类型</th>
<th class="tableblock halign-left valign-top">例外来源</th>
<th class="tableblock halign-left valign-top">RISC-V中的表示</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">系统重启</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">外部</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">例外</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">I/O设备请求</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">外部</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">中断</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">用户程序进行操作系统调用</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">内部</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">例外</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">未定义指令</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">内部</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">例外</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">硬件故障</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">皆可</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">皆可</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>通常，检测和处理例外的控制逻辑会处于处理器的时序关键路径上，这对处理器时钟频率和性能都会产生重要影响。如果对控制逻辑中的例外处理不给予充分重视，一旦尝试在复杂设计中添加例外处理，将会明显降低处理器的性能。这和处理器验证一样复杂</p>
</div>
<div class="sect3">
<h4 id="_risc_v体系结构中如何处理例外"><a class="link" href="#_risc_v体系结构中如何处理例外">4.5.1. RISC-V体系结构中如何处理例外</a></h4>
<div class="paragraph">
<p>在目前所讲过的实现中，只存在两种例外类型：未定义指令和硬件故障。例如，假设在指令add x1, x2, x1执行时出现硬件放障。当例外发生时，处理器必须执行的基本动作是：在系烧例外程序计数器(Supervisor Exception Program Counter,SEPC)中保存发生例外的指令地址，同时将控制权转交给操作系统。</p>
</div>
<div class="paragraph">
<p>之后，操作系统将做出相应动作，包括为用户程序提供系统服务，硬件故障时执行预先定义好的操作，或者停止当前程序的执行并报告错误。完成例外处理的所有操作后，操作系统使用SEPC寄存器中的内容重启程序的正常执行。可能是继续执行原程序，也可能是终止程序。</p>
</div>
<div class="paragraph">
<p>操作系统进行例外处理，除了引发例外的指令外，还必须获得例外发生的原因。目前使用两种方法来通知操作系统。RISC-V中使用的方法是设置系统例外原因寄存器（SupervisorExcption Cause Register. SCAUSE)，该寄存器中记录了例外原因。</p>
</div>
<div class="paragraph">
<p>另一种方法是使用向量式中断(vectored intecrupt)。该方法用基址寄存器加上例外原因（作为偏移）作为目标地址来完成控制流转换。基址寄存器中保存了向量式中断内存区域的起始地址。</p>
</div>
<div class="paragraph">
<p>操作系统可根据例外向量起始地址来确定例外原因。如果不使用此种方法，如RISC-V，就需要为所有例外提供统一的入口地址，由操作系统解析状态寄存器来确定例外原因。对于使用向量式例外的设计者，每个例外入口需要提供比如32字节或8条指令大小的区域，供操作系统记录例外原因并进行简单处理。通过添加一些额外寄存器和控制信号，并稍微扩展控制逻辑，就可以完成对各种例外的处理。</p>
</div>
</div>
<div class="sect3">
<h4 id="_流水线实现中的例外"><a class="link" href="#_流水线实现中的例外">4.5.2. 流水线实现中的例外</a></h4>
<div class="paragraph">
<p>流水线实现中，将例外处理看成另一种控制冒险。例如，假设add指令执行时产生硬件故障。正如之前章节中处理发生跳转的分支一样，我们需要在流水线上清除掉add之后的指令，并从新地址开始取指。和处理分支指令不同的是，例外会引起系统状态的变化。</p>
</div>
<div class="paragraph">
<p>处理分支预测错误时，我们将取指阶段的指令变为空操作（nop），以此来消除影响。对于进入译码阶段的指令，增加新逻辑控制译码阶段的多选器使输出为0，流水线停顿。添加一个新的控制信号ID.Flush，它与来自于冒险检测单元的stall信号进行或（OR）操作。使用该信号对进入译码阶段的指令进行清除。对于进入执行阶段的指令，我们使用一个新的控制信号EX.Flush，使得多选器输出为0。RISC-V体系结构中使用0000 00001C09 00001作为例外入口地址。为保证从正确地址开始取指，我们为PC多选器新增一个输入，保证能将上述例外入口地址送给PC寄存器。</p>
</div>
<div class="paragraph">
<p>上述例子指出了例外处理需要注意的一个问题：如果我们在add指令执行完毕后检测例外，程序员将无法获得xl寄存器中的原值，因为它已更新为add指令的执行结果。如果我们在add指令的EX阶段检测例外，可以使用EX.Flush信号去避免该指令在WB阶段更新寄存器。有一些例外类型，需要最终完成引发例外的指令的执行。最简单的方法就是清除掉该指令，并在例外处理结束后从该指令重新开始执行。</p>
</div>
<div class="paragraph">
<p>最后一步是，在SEPC寄存器中保存引发例外的指令的地址。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_指令间的并行性"><a class="link" href="#_指令间的并行性">4.6. 指令间的并行性</a></h3>
<div class="paragraph">
<p>编译器或处理器来猜测指令的行为并提前开始执行。如果猜测正确则进行指令提交，错误则清除结果并从执行正确的指令。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>推测的概念</p>
</li>
<li>
<p>基于硬件的推测</p>
</li>
<li>
<p>以多发射和静态调度来利用指令级并行</p>
</li>
<li>
<p>以动态调度、多发射和推测来利用指令级并行</p>
</li>
<li>
<p>用于指令交付和推测的高级技术</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>流水线技术挖掘了指令间潜在的并行性，这种并行性被称为指令级并行（ILP）。提高指令级并行度主要有两种方法。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>增加流水线的级数，让更多的指令重叠执行</p>
<div class="literalblock">
<div class="content">
<pre>仍然使用上文提到的洗衣店进行类比。假设洗衣阶段所需时间比其他阶段都长，我们可以将洗衣阶段再细分为洗涤、漂洗和甩干三个阶段。这样就将一个四级流水线变为六级流水线。不论是处理器还是洗衣店，如需获得最高加速比，还要重新调整其他阶段的时长至相等来平衡流水线。加深流水线后，由于有更多的操作可以重叠执行，指令间的并行度更高。同时，时钟周期变短，主频变高，处理器性能也就更高。</pre>
</div>
</div>
</li>
<li>
<p>增加流水线内部的功能部件数量，这样可以每周期发出多条指令</p>
<div class="literalblock">
<div class="content">
<pre>这种技术被称为多发射(multiple issue)。一个拥有三个洗衣机和三个烘干机的多发射洗衣店代替了之前的家庭式洗衣机和烘干机。也许你还需要招聘一些助手来折叠和收纳，这样被能在相同时间内完成之前的三倍工作量。唯一的缺点在于，需要在相邻流水阶段之间传递伤载，并保证所有机器都满负荷工作，这增加了额外的工作量。</pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>每周期发射多条指令，使得指令执行频率可以超过时钟频率。换句话来说，就是CPI可以小于1。举例，一个主频为3GHz、发射宽度为4的多发射处理器，峰值速度为每秒执行120亿条指令，理论上CPI为0.25，或IPC为4。如果这是一个五级流水的处理器那么同一时间内流水线中最多会有20条指令在执行。目前高端处理器的发射宽度为每周期3~6条指令，普通处理器的发射宽度一般为2。不过，多发射技术会有一些限制，例如哪些指令可以同时执行、如果发生冒险如何处理等。</p>
</div>
<div class="paragraph">
<p>实现多发射处理器主要有两种方法，区别在于编译器和硬件的不同分工。如果指令发射与否的判断是在编译时完成的，称为静态多发射（static multiple issue）。如果指令发射与否的判断是在动态执行过程中由硬件完成的，称为动态多发射(dynamic multiple issue)。这两个方法可能还有其他一些名称，但都不够准确或限制过严。</p>
</div>
<div class="paragraph">
<p>在多发射流水线中，需要处理如下两个主要任务：</p>
</div>
<div class="paragraph">
<p>1.将指令打包并放入发射槽。处理器如何判断本周期发射多少条指令?发射哪些指令？在大多数静态发射处理器中，编译器会完成这部分工作。而在动态发射处理器中，这部分工作通常会在运行时由硬件自动完成，编译器可以通过指令调度来提高发射效率。</p>
</div>
<div class="paragraph">
<p>2.处理数据和控制冒险。在静态发射处理器中，编译器静态处理了部分或所有指令序列中存在的数据和控制冒险。相应的，大多数动态发射处理器是在执行过程中使用硬件技术来解决部分或所有类型的冒险。</p>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_存储层次结构"><a class="link" href="#_存储层次结构">5. 存储层次结构</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_存储技术及其优化"><a class="link" href="#_存储技术及其优化">5.1. 存储技术及其优化</a></h3>
<div class="ulist">
<ul>
<li>
<p>SRAM技术</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>SRAM技术（Static Random Access Memory）</strong>是一种基于触发器（flip-flop）的存储技术，每个位的数据由一组互补的晶体管（通常为6个）构成。这种结构使得 SRAM 在保持数据时不需要周期性的刷新，因此其访问速度非常快。SRAM 的优点包括高速访问、低功耗（在无数据更改时）以及简单的控制电路，不需要刷新操作。但缺点在于单位存储密度较低，占用芯片面积较大，成本高昂，因此通常用于需要高速存取的缓存（如 CPU 的 L1、L2 缓存），而不适合作为大容量主存。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>DRAM技术</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>DRAM技术（Dynamic Random Access Memory）</strong>是一种基于电容的存储技术，每个位的数据存储在一个电容上，并通过一个晶体管进行访问。由于电容会随时间泄漏电荷，DRAM 需要定期刷新数据以保持其内容。DRAM 的主要优点是存储密度高、单位成本低，因此常被用于构建大容量主存（RAM）。然而，DRAM 的缺点是访问速度较慢，因为其需要刷新操作，此外，刷新还会消耗额外的能量并引入一定的延迟。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>SDRAM技术</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>SDRAM技术（Synchronous Dynamic Random Access Memory）</strong>是一种同步动态随机存储器，与 DRAM 的主要区别在于其与处理器的时钟信号同步工作。SDRAM 在时钟信号的上升沿或下降沿进行操作，能够通过流水线化访问技术，在一个周期内完成多组数据的读写操作，从而显著提高了存取速度。SDRAM 的优点包括访问速度更快，支持流水线操作，并且能够更好地与现代处理器的工作方式兼容。其缺点与 DRAM 类似，包括需要定期刷新、功耗较高，同时由于复杂度增加，设计和制造成本也较高。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>闪存、磁盘</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>闪存（Flash Memory）</strong>是一种非易失性存储技术，利用电荷存储在浮动栅极晶体管中来保存数据，即使断电数据也不会丢失。闪存通常分为 NAND 闪存和 NOR 闪存两种类型，NAND 闪存以高存储密度和较低成本广泛用于存储卡、USB 驱动器和固态硬盘（SSD），而 NOR 闪存以较快的随机读取速度适用于嵌入式系统的代码存储。闪存的优点包括非易失性、低功耗、高存储密度和耐用性，特别是 NAND 闪存具有极高的写入和擦除耐久性。但缺点是擦写速度相对较慢，擦写操作需要以块为单位进行，随机写入性能较差，同时闪存的寿命有限，写入次数达到一定阈值后可能会导致单元失效。</p>
</div>
<div class="paragraph">
<p><strong>磁盘（Disk）</strong>是传统的存储设备，主要包括硬盘驱动器（HDD）和光盘（如 CD、DVD）。磁盘通过机械部件（如旋转盘片和读写磁头）或光学原理来读取和写入数据。硬盘具有大容量和较低成本的优点，因此在长期数据存储、备份和非实时访问的场景中广泛应用。其缺点包括访问速度较慢（相较于闪存或 RAM），功耗较高，机械部件容易磨损，抗震性较差，且在频繁随机访问情况下性能表现不佳。光盘相较于硬盘，成本更低，便于长期存档，但容量较小且速度更慢。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>图形数据RAM</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>图形数据 RAM（Graphics Data RAM，GDRAM）</strong>是一种专门为图形处理器（GPU）优化的高速存储技术，用于存储和访问图形数据，例如纹理、顶点和像素信息。现代图形数据 RAM 的代表包括 GDDR（Graphics Double Data Rate）和 HBM（High Bandwidth Memory）。其优点是高带宽和低延迟，能够满足图形处理所需的大量数据传输需求，同时支持并行处理，以加速渲染任务。但其缺点是成本较高，功耗较大，通常作为专用存储资源，仅在高性能 GPU 和图形处理应用中使用。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>堆叠式或嵌入式DRAM</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>堆叠式或嵌入式 DRAM（Stacked or Embedded DRAM）</strong>是一种集成于芯片内部或与处理器直接堆叠在一起的动态随机存储器技术。它通过缩短存储器和处理器之间的数据传输距离，实现更快的访问速度和更低的能耗。嵌入式 DRAM（eDRAM）通常作为芯片上的缓存存储器，用于提高高性能计算、图形处理和嵌入式系统的效率，而堆叠式 DRAM 通过 3D 封装技术将 DRAM 堆叠到处理器上，常见于高端服务器和图形处理器中。
其优点包括访问延迟低、带宽高、能耗低以及与处理器集成度高，从而减轻主存储器的压力并提升系统整体性能。但缺点是制造工艺复杂，成本较高，同时容量相较于独立 DRAM 较小，因此多用于对性能和功耗要求较高的特定场景，而不是作为主存。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>相变存储器技术</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>相变存储器（Phase-Change Memory, PCM）</strong>是一种非易失性存储技术，通过材料（通常为碲锑合金）在晶态和非晶态之间的相变来表示二进制数据。这种存储技术利用相变材料电阻值的差异来读取和写入数据，具有接近 DRAM 的访问速度，同时具备闪存的非易失性。PCM 的优点包括高读写速度、高存储密度、长写入寿命以及断电数据不丢失的特性。由于其无需定期刷新，可以显著减少能耗，特别适用于嵌入式设备、大数据存储和云计算领域。
PCM 的缺点在于制造工艺复杂且成本较高，同时写入操作能耗较大，相变材料在高频写入下可能退化，影响设备寿命。此外，PCM 的存储密度尚未完全赶上 NAND 闪存，因此在大容量应用中的经济性尚需进一步优化。</p>
</div>
</div>
<div class="sect2">
<h3 id="_存储层次结构的一般框架"><a class="link" href="#_存储层次结构的一般框架">5.2. 存储层次结构的一般框架</a></h3>
<div class="paragraph">
<p>缓存是位于处理器与存储器之间的速度更快的存储器。作用为将存储器中的数据提前放入速度更快的缓存中，处理器读写数据时先在缓存内查找，从而同时获得大容量与高速的存储器。</p>
</div>
<div class="sect3">
<h4 id="_块的位置"><a class="link" href="#_块的位置">5.2.1. 块的位置</a></h4>
<div class="paragraph">
<p>在较高存储层次结构中，块的放置可以使用一系列方案，从直接映射到组相联，再到全相联。实际上整个方案可以被认为是组相联方案的变体，其中组的数量和魅族中块的数量不相同：</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">机制</th>
<th class="tableblock halign-left valign-top">组的数量</th>
<th class="tableblock halign-left valign-top">每组中块的数量</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">直接映射</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">cache中的块数</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">组相联</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(\frac{cache中的块数}{相联度}\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">相联度（一般为2~16）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">全相联</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">cache中的块数</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>增加相联度的好处是通常会降低失效率。失效率的改进来自于减少竞争同一位置而产生的失效。首先，来看能获得多少性能改进。最大的改进出现在直接映射变化到两路组相联时。随着cache容量的增加，相联度的提高对性能改进作用很小；这是因为大容量cache的总失效率较低，因此改善失效率的机会减少，并且由相联度引起的失效率的绝对改进明显减少。如前所述，相联度增加的潜在缺点是增加了代价和访问时间。</p>
</div>
</div>
<div class="sect3">
<h4 id="_块的识别"><a class="link" href="#_块的识别">5.2.2. 块的识别</a></h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">机制</th>
<th class="tableblock halign-left valign-top">定位方法</th>
<th class="tableblock halign-left valign-top">需要比较的次数</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">直接映射</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">索引</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">组相联</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">索引组，查找组中的元素</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">相联度</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">全相联</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">查找所有cache表项</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">cache容量</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">独立的查找表</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>在存储层次结构中，直接映射、组相联或全相联映射的选择取决于失效代价与相联度实现代价之间的权衡，包括时间和额外硬件开销。在片上包含二级cache允许实现更高的相联度。这是因为命中时间不再关键，设计者也不必依靠标准SRAM芯片来构建模块。除非容量很小，否则cache不使用全相联映射方式，其中比较器的成本并不是压倒性的，而绝对失效率的改进才是最明显的。</p>
</div>
<div class="paragraph">
<p>在虚拟存储系统中，页表是一张独立的映射表，它用来索引内存。除了表本身需要的存空间外，使用索引表还会引起额外的存储访问。使用全相联映射和额外的页表有以下几个原因：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>全相联有其优越性，因为失效代价非常高。</p>
</li>
<li>
<p>全相联允许软件使用复杂的替换策略以降低失效率。</p>
</li>
<li>
<p>全相联很容易索引，不需要额外的硬件，也不需要进行查找。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>因此，虚拟存储系统通常使用全相联。</p>
</div>
<div class="paragraph">
<p>组相联映射通常用于cache和TLB，访问时包括索引和组内查找。一些系统使用直接映cache，这是因为访问时间短并且实现简单。访问时间短是因为查找时不需要进行比较。这样的设计选择取决于很多实现细节，例如，cache是否集成在片上、实现cache的技术以及cache的访问时间对处理器周期时间的重要性。</p>
</div>
</div>
<div class="sect3">
<h4 id="_块的替换"><a class="link" href="#_块的替换">5.2.3. 块的替换</a></h4>
<div class="paragraph">
<p>当相联的cache发生失效时，我们必须决定要替换哪个块。在全相联的cache中，所有的块都是替换的候选者。如果cache是组相联的，则必须在一组的块中进行选择。当然，直接映射cache中的替换很容易，因为只有一个候选者。</p>
</div>
<div class="paragraph">
<p>在组相联或全相联的cache中有两种主要的替换策略：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>随机：随机选择候选块，可能使用一些硬件辅助实现。</p>
</li>
<li>
<p>最近最少使用(LRU)：被替换的块是最久没有被使用过的块。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>实际上，在相联度不低（典型的是两路到四路）的层次结构中实现LRU的代价太高，这是因为追踪记录使用信息的代价很高。即使对于四路组相联，LRU通常也是近似实现的，例如，追踪记录哪一对块是最近最少使用的（需要使用1位），然后追踪记录每对块中哪一块是最近最少使用的（每对需要使用1位）。</p>
</div>
<div class="paragraph">
<p>对于较大的相联度，LRU是近似的或使用随机替换策略。在cache中，替换算法由硬件实现，这意味着方案应该易于实现。随机替换算法用硬件很容易实现，对于两路组相联cache，随机替换的失效率比LRU替换策略的失效率高约1.l倍。随着cache容量变大，两种替换策略的失效率下降，并且绝对差异也变小。实际上，随机替换算法的性能有时可能比用硬件简单实现的近似LRU更好。</p>
</div>
<div class="paragraph">
<p>在虚拟存储中，LRU的一些形式都是近似的，因为当失效代价很大时，失效率的微小降低都很重要。通常提供参考位或其他等价的功能使操作系统更容易追踪记录一组最近使用较少的页。由于失效代价很高且相对不频繁发生，主要由软件来近似这项信息的做法是可行的。</p>
</div>
</div>
<div class="sect3">
<h4 id="_写入策略"><a class="link" href="#_写入策略">5.2.4. 写入策略</a></h4>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">写策略</th>
<th class="tableblock halign-left valign-top">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">写穿透</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">处理器在进行写操作时同时向缓存与主存中写入，为避免写主存引起的长延时，还会增加写缓冲区。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">写返回</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">处理器进行写操作时只对缓存进行写入，并标记脏位。在这个块需要替换时才会写到主存中。此方法减少了对主存的频繁写入。</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>任何存储层次结构的一个关键特性是如何处理写操作。我们已经看到两个基本选项：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>写穿透：信息将写入cache中的块和存储层次结构中较低层的块（对cache而言是主存）</p>
</li>
<li>
<p>写返回：信息仅写人cache中的块。修改后的块只有在它被替换时才会写入层次结构中的较低层。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>写返回和写穿透都有其各自的优点。写返回的主要优点如下：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>处理器可以按cache而不是内存能接收的速率写单个的字。</p>
</li>
<li>
<p>块内的多次写操作只需对存储层次结构中的较低层进行一次写操作。</p>
</li>
<li>
<p>当写回块时，由于写一整个块，系统可以有效地利用高带宽传输。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>写穿透具有以下优点：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>失效比较简单，代价也比较小，这是因为不需要将块写回到存储层次结构中的较低层。</p>
</li>
<li>
<p>写穿透比写返回更容易实现，尽管实际上写穿透cache仍然需要写缓冲区。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>在虚拟存储系统中，只有写返回策略才是实用的，这是因为写到存储层次结构较低层的延迟很大。尽管允许存储器的物理和逻辑宽度更宽，并对DRAM采用突发模式，处理器产生写操作的速率通常还是超过存储系统可以处理它们的速率。因此，现在最低一级的cache通常采用写回策略。</p>
</div>
</div>
<div class="sect3">
<h4 id="_3c模型一种理解存储层次结构的直观模型"><a class="link" href="#_3c模型一种理解存储层次结构的直观模型">5.2.5. 3C模型：一种理解存储层次结构的直观模型</a></h4>
<div class="paragraph">
<p>在本节中，我们将介绍一种模型，该模型可以很好地洞察存储层次结构中引起失效的原因，以及存储层次结构中的变化对失效的影响。我们将用cache来解释这些想法，尽管这些想法对其他层次也都直接适用。在此模型中，所有失效都被分为以下三类（3C模型）：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>强制失效：对没有在cache中出现过的块进行第一次访问时产生的失效，也称为冷启动失效。</p>
</li>
<li>
<p>容量失效：cache无法包含程序执行期间所需的所有块而引起的失效。当某些块被替换出去，随后再被调入时，将发生容量失效。</p>
</li>
<li>
<p>冲突失效：在组相联或者直接映射cache中，很多块为了竞争同一个组导致的失效。冲突失效是直接映射或组相联cache中的失效，而在相同大小的全相联cache中不存在。这种cache失效也称为碰撞失效(collision miss)。下图显示了失效率如何按照引起的原因被分为三种。改变cache设计中的某一方面可以直接影响这些失效的原因。由于冲突失效来自对同一cache块的争用，因此提高相联度可减少冲突失效。但是，提高相联度可能会延长访问时间，从而降低整体性能。</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/5.2.5.png" alt="5.2.5">
</div>
</div>
<div class="paragraph">
<p>简单地增大cache容量可以减少容量失效，实际上，多年来二级cache容量一直在稳步增长。当然，在增大cache的同时，我们也必须注意访问时间的增长，这可能导致整体性能降低。因此，尽管一级cache也在增大，但是非常缓慢。</p>
</div>
<div class="paragraph">
<p>由于强制失效是对块的第一次访问时产生的，因此，对cache系统来说，减少强制失效次数的主要方法是增加块大小。由于程序将由较少的cache块组成，因此这将减少对程序每一块都要访问一次时的总访问次数。如上所述，块容量增加太多可能对性能产生负面影响，因为失效代价会增加。</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">设计变化</th>
<th class="tableblock halign-left valign-top">对失效率的影响</th>
<th class="tableblock halign-left valign-top">可能对性能产生的负面影响</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">增加cache容量</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">降低失效率</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">可能延长访问时间</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">增加相联度</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">由于减少了冲突失效，降低了失效率</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">可能延长访问时间</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">增加块容量</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">由于空间局部性，对很宽范围内变化的块的大小，降低了失效率</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">增加失效损失，块太大还会增大失效率</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>将失效分为3C是个有用的定性模型。在实际cache设计中，很多设计选择相互影响，改变一个cache特性通常会影响另一些失效率的组成部分。尽管存在这些缺点，但该模型仍是深入了解cache设计性能的有效方法。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_可靠的存储器层次"><a class="link" href="#_可靠的存储器层次">5.3. 可靠的存储器层次</a></h3>
<div class="sect3">
<h4 id="_失效的定义"><a class="link" href="#_失效的定义">5.3.1. 失效的定义</a></h4>
<div class="paragraph">
<p>假设有某种服务的需求，用户可以看到一个系统在两种分别有需求的服务的状态之间交替：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>服务完成：交付的服务与需求相符。</p>
</li>
<li>
<p>服务中断：交付的服务与需求不同。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>失效导致状态1到状态2的转换，而从状态2到状态l的转换过程被称为恢复。失效可能是永久性的或间歌性的，间歇性失效更为复杂。因为当系统在两种状态之间摇摆时，诊断更加困难。而永久性失效更容易诊断。</p>
</div>
<div class="paragraph">
<p>这里引出两个相关术语：可靠性和可用性。可靠性是一个系统能够持续提供用户需求的服务的度量，即从参考时刻到失效的时间间隔。因此，平均无故障时间（MTTF）是可靠性的度量方法。与之相关的一个术语是年度失效率（AFR），它是指给定MTTF一年内预期的器件失效百分比。当MTTF变大时，可能会产生误导性的结果，而AFR会带来更直观的结果。</p>
</div>
<div class="paragraph">
<p>服务中断使用平均修复时间（MTTR）来衡量。平均失效间隔时间\((MTBF)=MTTF+MTTR\)。尽管MTBF被广泛使用，MTTF却更加合适。然后，可用性是指系统正常工作时间在连续两次服务中断间隔时间中所占的比例：</p>
</div>
<div class="stemblock">
<div class="content">
\[可用性 = \frac{MTTF}{MTTF + MTTR}\]
</div>
</div>
<div class="paragraph">
<p>请注意，可靠性和可用性是可量化的，它们不仅仅是可信性的同义词。降低MTTR可以提高MTTF进而提高可用性。例如，用于故障检测、诊断和修复的工具可减少修复失效的时间。从而提高可用性。我们希望系统有很高的可用性。一种简写是“每年可用性中9的数量”。</p>
</div>
<div class="paragraph">
<p>为了提高MTTF，可以提高器件的质量，也可以设计能够在器件出现故障的情况下继续运行的系统。因此，由于器件的失效可能不会导致系统的失效，需要根据上下文对失效进行定义。为了明确二者的区别，用术语故障来表示器件的失效：以下是提高MTTF的三种方法：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>故障避免技术：通过合理构建系统来避免故障的出现。</p>
</li>
<li>
<p>故障容忍技术：使用冗余技术，即使出现故障，仍然可以按照需求服务。</p>
</li>
<li>
<p>故障预测技术：预测故障的出现和构建，从而允许在器件故障前进行替换。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_汉明编码"><a class="link" href="#_汉明编码">5.3.2. 汉明编码</a></h4>
<div class="paragraph">
<p>理查德·汉明（Richard Hamming）发明了一种广泛应用于存储器的冗余技术，并因此获得1968年的图灵奖。二进制数间的距离对于理解冗余码很有帮助。汉明距离是两个等长二进制数对应位置不同的位的数量。例如，011011和001111的距离为2。如果在一种编码中，码字之间的最小距离为2.且其中有1位错误，将会发生什么？这会将一个有效的码字转化为无效码字。因此，如果能够检测一个码字是否有效，就可以检测出1位的错误，称为1位错误检测编码。</p>
</div>
<div class="paragraph">
<p>汉明使用奇偶校验码进行错误检测。在奇偶校验码中，要计数一个字中1的个数是奇数还是偶数。当一个字被写人存储器时，奇偶校验位也被写入（1表示奇数，0表示偶数）。也就是说，N+1位字中1的个数永远是偶数。当读出该字时，奇偶校验位也一并读出并检查。如果计算出的校验码与存储的不匹配，则发生错误。</p>
</div>
<div class="paragraph">
<p>如果有2位同时出错，则1位奇偶校验位技术无法检测到错误，因为码字奇偶性不变。（实际上，1位奇偶校验可以检测任意奇数个错误，但是实际情况中，发生3位错误的概率远低于2位错误的概率。所以实际中1位奇偶校验码仅用于检测1位错误。）</p>
</div>
<div class="paragraph">
<p>当然，奇偶校验码不能纠正错误，汉明想要做到检错的同时又能纠错。如果码组中最小距离为3，那么任意发生1位错误的码字与其对应的正确码字的距离，要小于它与其他有效码字的距离。他想出了一个容易理解的将数据映射到距离3的码字，为纪念汉明，我们将这种方法称为汉明纠错码（ECC）。我们使用额外的奇偶校验位确定单个错误的位置。以下是计算汉明纠错码的步骤：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>从左到右由1开始依次编号，这与传统的从最右侧由0开始编号相反。</p>
</li>
<li>
<p>将编号为2的整数幂的位标记为奇偶校验位（1, 2, 4, 8, 16, &#8230;&#8203;）。</p>
</li>
<li>
<p>剩余其他位用于数据位（3, 5, 6, 7, 9, l0, 11, 12, l3, 14, l5, &#8230;&#8203;）。</p>
</li>
<li>
<p>奇偶校验位的位置决定了其对应的数据位，如下所示：</p>
<div class="ulist">
<ul>
<li>
<p>校验位1（\(0001_2\)）检查1, 3, 5, 7, 9, 11, &#8230;&#8203;位，这些位的编号最右一位为1（\(0001_2、0011_2、0101_2、0111_2、1001_2、1011_2, ...\)）。</p>
</li>
<li>
<p>校验位2（\(0010_2\)）检查2, 3, 6, 7, 10, 11, 14, 15, &#8230;&#8203;位，这些位的编号最右第二位为1。</p>
</li>
<li>
<p>校验位4（\(0100_2\)）检查4~7, 12~15, 20~23, &#8230;&#8203;位，这些位的编号最右第三位为l。</p>
</li>
<li>
<p>校验位8（\(1000_2\)）检查8~15, 24~31, 40~47, &#8230;&#8203;位，这些位的编号最右第四位为1。</p>
<div class="literalblock">
<div class="content">
<pre>请注意，每个数据位都被至少两个奇偶校验位覆盖。</pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>设置奇偶校验位，为各组进行偶校验。</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_cache的性能评估与改进"><a class="link" href="#_cache的性能评估与改进">5.4. cache的性能评估与改进</a></h3>
<div class="paragraph">
<p>CPU时间可被分成CPU用于执行程序的时间和CPU用来等待访存的时间。通常，假设cache命中的访问时间只是正常CPU执行时间的一部分。因此，</p>
</div>
<div class="stemblock">
<div class="content">
\[CPU时间 =（CPU执行的时钟周期数+等待存储访问的时钟周期数）\times 时钟周期\]
</div>
</div>
<div class="paragraph">
<p>假设等待存储访问的时钟周期数主要来自于cache失效，同时，限制后续的讨论只针对简单的存储系统模型。在真实的处理器中，读写操作产生的停顿十分复杂，准确的性能预测通常需要对处理器和存储系统进行非常详细的模拟。</p>
</div>
<div class="paragraph">
<p>等待存储访问的时钟周期数可以被定义为，读操作带来的停顿周期数加上写操作带来的停顿周期数：</p>
</div>
<div class="stemblock">
<div class="content">
\[等待存储访问的时钟周期数=读操作带来的停顿周期数+写操作带来的停顿周期数\]
</div>
</div>
<div class="paragraph">
<p>读操作带来的停顿周期数可以由每个程序的读操作数目、读操作失效率和读操作的失效代价来定义。</p>
</div>
<div class="stemblock">
<div class="content">
\[读操作带来的停顿周期数 = \frac{读操作数目}{程序} \times 读失效率 \times 读失效代价\]
</div>
</div>
<div class="paragraph">
<p>写操作要更复杂些。对于写穿透策略，有两个停顿的来源：一个是写失效，通常在连续写之前需要将数据块取回;另一个是写缓冲停顿，通常在写缓冲满时进行写操作会引发该停顿。因此，写操作带来的停顿周期数等于下面两部分的总和：</p>
</div>
<div class="stemblock">
<div class="content">
\[写操作带来的停顿周期数 = \frac{写操作数目}{程序} \times 写失效率 \times 写失效代价 + 写缓冲满时的停顿周期\]
</div>
</div>
<div class="paragraph">
<p>由于写缓冲停顿主要依赖于写操作的密集度，而不只是它的频度，不可能给出一个简单的计算此类停顿的等式。幸运的是，如果系统中有一个容量合理的写缓冲（例如，四个或者更多字），同时主存接收写请求的速度能够大于程序的平均写速度，写缓冲引起的停顿将会很少，几乎能够忽略。如果系统不能满足这些要求，那么这个设计可能不合理。设计者要么使用更深的写缓冲，要么使用写返回策略。</p>
</div>
<div class="paragraph">
<p>写返回策略也会额外增加停顿，主要来源于当数据块被替换并需要将其写回到主存时。</p>
</div>
<div class="paragraph">
<p>在大多数写穿透cache的结构中，读和写的失效代价是相同的（都是将数据块从内存取至cache所花的时间）。假设写缓冲停顿是可以忽略不计的，就可以使用失效率和失效代价来同时刻画读操作和写操作：</p>
</div>
<div class="stemblock">
<div class="content">
\[等待存储访间的时钟周期数 = \frac{访存操作数目}{程序} \times 写失效率 \times 写失效代价\]
</div>
</div>
<div class="paragraph">
<p>该公式也可以记作:</p>
</div>
<div class="stemblock">
<div class="content">
\[等待存储访问的时钟周期数 = \frac{指令数目}{程序} \times \frac{失效次数}{指令数目} \times 写失效代价\]
</div>
</div>
<div class="sect3">
<h4 id="_cache的性能优化策略"><a class="link" href="#_cache的性能优化策略">5.4.1. cache的性能优化策略</a></h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>使用更为灵活的替换策略降低cache失效率</p>
</li>
<li>
<p>在cache中查找数据块</p>
</li>
<li>
<p>替换数据块的选择策略</p>
</li>
<li>
<p>使用多级cache减少失效代价</p>
</li>
<li>
<p>通过分块进行软件优化</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_优化缓存性能"><a class="link" href="#_优化缓存性能">5.5. 优化缓存性能</a></h3>
<div class="sect3">
<h4 id="_采用小而简单的第一级缓存缩短命中时间降低功耗"><a class="link" href="#_采用小而简单的第一级缓存缩短命中时间降低功耗">5.5.1. 采用小而简单的第一级缓存，缩短命中时间、降低功耗</a></h4>
<div class="paragraph">
<p>提高时钟频率和降低功耗的双重压力推动了对第一级缓存大小的限制。类似地，使用较低级别的相联度可以缩短命中时间、降低功耗，不过这种权衡要比涉及缓存大小的权衡复杂一些。</p>
</div>
<div class="paragraph">
<p>缓存命中过程中的关键计时路径由3个步骤组成：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>使用地址中的索引确定标签存储器的地址</p>
</li>
<li>
<p>将读取的标签值与地址进行比较</p>
</li>
<li>
<p>如果缓存为组相联缓存，则设置多路选择器以选择正确的数据项。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>直接映射的缓存可以将标签检查与数据传输重叠，有效缩短命中时间。此外，在采用低相联度时，由于减少了必须访问的缓存行，所以通常还可以降低功耗。</p>
</div>
<div class="paragraph">
<p>尽管随着新一代微处理器的出现，片上缓存的总量已经大幅增加，但由于大容量L1缓存对时钟频率的影响，Ll缓存大小最近的涨幅很小，甚至根本没有增长。在选择相联度时，另一个考虑因素是消除地址别名的可能性。</p>
</div>
<div class="paragraph">
<p>随着能耗变得至关重要，设计师们开始关注减少缓存访问所需能耗的方法。除了相联度之外，另一个决定缓存访问所需能耗的关键因素是缓存中块的数量，因为它决定了被访问的“行”的数量。设计师可以通过增加块大小（保持总缓存大小不变）来减少行数，但是这会增加缺失率，对于较小的L1缓存而言尤其如此。</p>
</div>
<div class="paragraph">
<p>另一种方法是将缓存分为多个存储体，这样一次访问将只激活缓存的一部分，也就是包含所需块的那个存储体。多体缓存主要用于增加缓存的带宽。多体缓存也会降低能耗，因为访问的缓存更少了。许多多核芯片中的L3缓存在逻辑上是统一的，但物理上是分散的，实际上就相当于一个多体缓存。一次请求实际上只会访问物理L3缓存中的一个缓存（也就是一个存储体），具体哪个缓存取决于请求中提供的地址。</p>
</div>
<div class="paragraph">
<p>在最近的设计中，有3种其他因素导致了在第一级缓存中使用更高的相联度。第一，许多处理器在访问缓存时至少需要两个时钟周期，因此命中时间较长可能不会产生很大影响。第二，为了将TLB排除在关键路径之外（TLB带来的延迟可能要大于高相联度导致的延迟），几乎所有L1缓存都应当是虚拟地址索引的。这就将缓存的大小限制为页面大小与相联度的乘积，因为只有页内的位才能用于索引。对于在完成地址变换之前对缓存进行索引的问题，还有其他解决方案，但提高相联度是最具吸引力的一种，它还有其他好处。第三，在引入多线程（参见第3章）之后，冲突缺失会增加，从而使提高相联度更有吸引力。</p>
</div>
</div>
<div class="sect3">
<h4 id="_采用路预测以缩短命中时间"><a class="link" href="#_采用路预测以缩短命中时间">5.5.2. 采用路预测以缩短命中时间</a></h4>
<div class="paragraph">
<p>这是另一种可以减少冲突缺失，同时又能保持直接映射缓存命中速度的方法。在路预测技术(way prediction）中，缓存中另外保存了一些位，用于预测下一次缓存访问中的路（即组中的块）。这种预测意味着要提前设定多路选择器，以选择所需要的块，并且在这个时钟周期中，在读取缓存数据的同时，只需要并行执行一次标签比较。如果缺失，则会在下一个时钟周期中再查看其他块，以找出匹配项。</p>
</div>
<div class="paragraph">
<p>在一个缓存的每个块中添加块预测位。根据这些位选定要在下一次缓存访问中尝试哪些块。如果预测正确，则缓存访问延迟就等于这一快速命中时间。如果预测错误，则尝试其他块，改变路预测器，并且延迟会增加一个时钟周期。模拟结果表明，对于一个两路组相联缓存，路预测准确率超过90%；对于四路组相联缓存，路预测准确率超过80%；指令缓存上的准确率高于对数据缓存。如果路预测能够至少快10%（这是非常可能的），路预测方法可以缩短两路组相联缓存的存储器平均访问时间。路预测于20世纪90年代中期首次用于MIPS R10000。它在使用两路组相联缓存的处理器中很流行，也用在几款使用四路组相联缓存的ARM处理器中。对于速度非常快的处理器，要将时延控制在一个周期是非常具有挑战性的，而这对于降低路预测失误代价非常关键。</p>
</div>
<div class="paragraph">
<p>还有一种扩展形式的路预测，它使用路预测位（本质上就是附加地址位）来判断实际访问的缓存块，也可以用来降低功耗。这种方法也可称为路选择（way selection)，当路预测正确时，它可以节省功耗，但在路预测错误时则会显著增加时间，这是因为需要重复进行访问，而不仅是重复标签匹配与选择过程。这种优化方法只有在低功耗处理器中才可能有意义。Inoue等人[1999]根据SPEC95基准测试进行估算，对于四路组相联缓存使用路选择方法，可以使指令缓存的平均访问时间增加1.04倍，数据缓存增加1.13倍，但与普通的四路组相联缓存相比，指令缓存的平均缓存功耗降为原来的0.28，数据缓存降为原来的0.35。路选择方法的一个重要缺点就是它增大了实现缓存访问流水化的难度。然而，随着能耗问题受关注度的增加，适时对缓存做低功耗处理的方案越来越有意义。</p>
</div>
</div>
<div class="sect3">
<h4 id="_通过缓存访问流水化和采用多体缓存来提升带宽"><a class="link" href="#_通过缓存访问流水化和采用多体缓存来提升带宽">5.5.3. 通过缓存访问流水化和采用多体缓存来提升带宽</a></h4>
<div class="paragraph">
<p>这类优化方法通过实现缓存访问的流水化，或者通过拓宽多体缓存，实现在每个时钟周期内进行多次访问，从而提高缓存的带宽。这类优化方法可同时用于实现提高指令吞吐率的超流水化和超标量技术。这些优化方法主要面向L1，这里的访问带宽限制了指令吞吐率。L2和L3级存中也会使用多个存储体，但主要是作为一种功耗管理技术。</p>
</div>
<div class="paragraph">
<p>L1缓存实现流水化后，可以采用更高的时钟频率，但代价是会增加延迟。例如，对于20世纪90年代中期的lntel Pentium处理器，指令缓存访问的流水线需要1个时钟周期；对于20世纪90年代中期至2000年的Pentium Pro到Pentium Ⅲ，需要2个时钟周期；对于2000年出现的Pentium4和现在的lntelCore i7，需要4个时钟周期。指令缓存访问的流水化实现上增加了流水线的段数，增加了分支预测错误的代价。相应地，数据缓存的流水化增加了从发出载入指令到使用数据之间的时钟周期数。如今，即使只是为了分开访问和命中检测这种简单的情况，所有处理器都会使用某种一级缓存流水化方法，而许多高速处理器则会采用三级或更多级缓存流水化方法。</p>
</div>
<div class="paragraph">
<p>指令缓存的流水化要比数据缓存容易一些，因为处理器可以依赖于高性能的分支预测来减轻延迟造成的影响。许多超标量处理器可以在一个时钟周期内发出和执行一个以上的存储器访问（允许一次载入或存储操作是常见情况，一些处理器允许进行多次载入）。为了在每个时钟周期内处理多个数据缓存访问，可以将缓存划分为独立的存储体，每个存储体为一次独立的访问提供支持。分体方式最初用于提高主存储器的性能，现在也用于现代DRAM芯片和缓存中。IntelCorei7的L1缓存中有4个存储体（可以支持在每个时钟周期内进行两次存储器访问）。</p>
</div>
<div class="paragraph">
<p>显然，当访问请求均匀分布在缓存组之间时，分体方式的效果最佳，所以将地址映射到存储体的方式会影响存储器系统的行为。一种简单有效的映射方式是将缓存块地址按顺序分散在这些存储体中，这种方式称为顺序交错(sequential interleaving)。例如，如果有4个存储体，0号存储体中的所有缓存块地址都是4的倍数，1号存储体中的所有缓存块地址都是模4余1，以此类推。采用分体方式还可以降低缓存和DRAM的功耗。</p>
</div>
<div class="paragraph">
<p>多体方式在L2缓存或L3缓存中也有应用，但原因不同。L2缓存中有多个存储体时，如果这些存储体没有冲突，那么可以同时处理多次L1缓存缺失——这是支持第四种优化方式非阻塞式缓存的关键能力。IntelCore i7中的L2缓存有8个存储体，而ARM Cortex处理器使用了具有1-4个存储体的L2缓存。前面曾经提到，采用分体方式还可以降低功耗。</p>
</div>
</div>
<div class="sect3">
<h4 id="_采用非阻塞缓存以增加缓存带宽"><a class="link" href="#_采用非阻塞缓存以增加缓存带宽">5.5.4. 采用非阻塞缓存，以增加缓存带宽</a></h4>
<div class="paragraph">
<p>对于允许乱序执行的流水化计算机，其处理器不必因为一次数据缓存缺失而停顿。例如，在等待数据缓存返回缺失数据时，处理器可以继续从指令缓存中取指。非阻塞缓存（nonblocking cache，或称无锁缓存，lockup-free cache）允许数据缓存在一次缺失期间继续提供缓存命中，从而进一步强化了这种方案的潜在优势。这种“缺失时仍然命中”优化方法在缺失期间非常有用，它虽然并没有真正忽略处理器的请求，但降低了实际的缺失代价。还有一种精巧而复杂的选择：如果能够重叠多个缺失，缓存就能进一步降低实际的缺失代价。这被称为“多次缺失时仍然命中”(hit under multiple miss)或者“缺失时缺失”(miss under miss)优化方法。只有当存储器系统可以为多次缺失提供服务时，第二种优化方法才有好处。大多数高性能处理器(比如Intel Core)通常支持这两种优化方法，而很多低端处理器仅在L2中提供了有限的非阻塞支持。</p>
</div>
<div class="paragraph">
<p>对非阻塞缓存进行性能评估时，真正的难度在于一次缓存缺失不一定会使处理器停顿。在这种情况下，很难判断一次缺失造成的影响，因此也就难以计算存储器平均访问时间。实际缺失代价并不等于这些缺失之和，而是等于处理器停顿的非重叠时间。非阻塞缓存的优势非常复杂，因为它取决于存在多次缺失时的缺失代价、存储器访问模式以及处理器在处理单次缺失时能够执行多少条指令。</p>
</div>
<div class="paragraph">
<p>通常，乱序处理器能够隐藏在L2缓存中命中但在L1数据缓存中缺失的大部分缺失代价，但无法隐藏更低层次缓存中缺失的大部分代价。在决定要支持多少个未处理缺失时，需要考虑多种因素，如下所述。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>缺失流中的时间与空间局部性，它决定了一次缺失能否触发对低级缓存或对存储器的新访问操作。</p>
</li>
<li>
<p>对访问请求做出回应的存储器或缓存的带宽。</p>
</li>
<li>
<p>为了允许最低级别的缓存（这一级别的缺失时间是最长的）中出现更多的未处理缺失，需要在较高级别上支持至少同等数量的缺失，这是因为这些缺失必须在最高级别的缓存上启动。</p>
</li>
<li>
<p>存储器系统的延迟。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>实现非阻塞缓存</strong></p>
</div>
<div class="paragraph">
<p>尽管非阻塞缓存有提高性能的潜力，但其实现却并非易事。出现了两种类型的挑战：仲裁命中与缺失之间的冲突；跟踪尚未解决的缺失，以便知道何时可以处理载入或存储操作。</p>
</div>
<div class="paragraph">
<p>先考虑第一个问题。在阻塞式缓存中，缺失会导致处理器停顿，在缺失得到处理之前，不会发生对缓存的其他访问。而在非阻塞式缓存中，命中可能会与低一级存储器中返回的缺失发生冲突。如果允许存在多个尚未解决的缺失（几乎当前的所有处理器都允许这样做），那么缺失之间很可能会发生冲突。这些冲突必须得到解决，通常的做法是：首先为命中赋予比缺失更高的优先级，其次是在出现互相冲突的缺失时对其进行排序。</p>
</div>
<div class="paragraph">
<p>第二个问题的出现是因为我们需要跟踪多个尚未解决的缺失。在阻塞式缓存中，我们总是知道正在返回的缺失是哪个，因为只有一个缺失是尚未解决的。而在非阻塞式缓存中，这种情况就很少成立。乍看起来，你可能会认为这些缺失总是按顺序返回的，所以可以维护一个简单的队列，用以返回一个等待时间最长的缺失。但考虑一个发生在L1中的缺失。它在L2中可能发生一次命中，也可能造成一次缺失；如果L2是非阻塞式的，那么向L1返回缺失的顺序就未必与它们最初的发生顺序一致了。缓存访问时间不一致的多核系统及其他多处理器系统，也可能会引入这一复杂性。</p>
</div>
<div class="paragraph">
<p>在返回一个缺失时，处理器必须知道是哪个载入或存储操作导致了这一缺失，这样指令才能进行下去；它还必须知道应当将数据放到缓存中的什么位置（以及针对这个块的标签设置）。在当前的处理器中，这一信息保存在一组寄存器中，通常称为缺失状态处理寄存器（Miss StatusHandling Register，MSHR）。如果我们允许存在n个尚未解决的缺失，就会有n个MSHR，其中每一个中都保存了关于某一个缺失应当进入缓存中的什么位置，以及这一缺失的任意标签位的取值等信息，还包含了关于哪个载入或存储指令导致了这一缺失的信息。因此，在发生缺失时，我们分配一个MSHR来处理这个缺失，输入关于这一缺失的适当信息，并用MSHR的索引号来标记存储器请求。存储器系统在返回数据时使用该标签，从而使缓存系统能够将数据和标签信息传送给适当的缓存块，并向生成这一缺失的载人或存储操作发出“通知”，告诉它数据现在已经可用，它可以恢复执行了。非阻塞式缓存显然需要额外的逻辑处理，从而需要一点能耗。但很难精确评估它们的能耗开销，这是因为它们可能会缩短停顿时间，从而降低执行时间和相应的能耗。</p>
</div>
<div class="paragraph">
<p>除了上述问题之外，多处理器存储器系统，无论是单芯片的还是多芯片的，还必须处理与存储器一致性有关的复杂实现问题。另外，由于缓存缺失不再具有原子性（因为请求和响应是分离的，可能会在多个请求之间发生交错），所以存在出现死锁的可能性。</p>
</div>
</div>
<div class="sect3">
<h4 id="_利用关键字优先和提前重新执行以降低缺失代价"><a class="link" href="#_利用关键字优先和提前重新执行以降低缺失代价">5.5.5. 利用关键字优先和提前重新执行以降低缺失代价</a></h4>
<div class="paragraph">
<p>这种技术的基础是处理器通常一次仅需要缓存块中的一个字。这一策略显得“缺乏耐心”无须等待整个块载入完成，就可以发送请求的字并重新执行处理器。下面是两种具体策略。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>关键字优先：首先从存储器中请求缺失的字，在其到达缓存之后立即发给处理器；让处理器能够在载入块中其他的字时继续执行。</p>
</li>
<li>
<p>提前重新执行：以正常顺序提取字，但只要块中的被请求字到达缓存，就立即将其发送给处理器，让处理器继续执行。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>一般说来，这些技术只对使用大缓存块的设计有利。注意，在载入某个块中的其余内容时，缓存通常可以继续满足对其他块的访问请求。</p>
</div>
<div class="paragraph">
<p>不过，根据空间局部性原理，下一次访问很可能会指向这个块的其余内容。和非阻塞缓存一样，其缺失代价也不好计算。在采用关键字优先策略时，如果存在第二次请求，则实际缺失代价等于从本次访问开始到第二部分内容到达之前的非重叠时间。关键字优先和提前重新执行的好处取决于块的大小以及对块中尚未获取的部分进行另一次访问的可能性。例如，对于在i7 6700上运行的SPECimt2006（它采用了提前重新执行和关键字优先策略）来说，当有一个块发生缺失时，平均可以多做l次存储访问（平均1.23次，范围从0.5到3.0）。</p>
</div>
</div>
<div class="sect3">
<h4 id="_合并写缓冲区以降低缺失代价"><a class="link" href="#_合并写缓冲区以降低缺失代价">5.5.6. 合并写缓冲区以降低缺失代价</a></h4>
<div class="paragraph">
<p>因为所有存储内容都必须发送到层次结构的下一级，所以写直达缓存依赖于写缓冲区。即使是写回缓存，在替代一个块时也会使用一个简单的缓冲区。如果写缓冲区为空，则数据和整个地址被写到缓冲区中，从处理器的角度来看，写操作已经完成；在写缓冲区准备将字写入存储器时，处理器继续自己的工作。如果缓冲区中包含其他经过修改的块，则可以检查它们的地址，看看新数据的地址是否匹配写缓冲区某个条目的有效地址。如果匹配，则将新数据与这个条目合并在一起。这种优化方法称为写合并（writemerging）。Intel Core i7和其他许多处理器都采用了写合并方法。</p>
</div>
<div class="paragraph">
<p>如果缓冲区已满，而且没有匹配的地址，则缓存（和处理器）必须一直等到缓冲区中拥有空白条目为止。由于多字写入的速度通常快于每次只写入一个字的写操作，所以这种优化方法可以更高效地使用存储器。Skadron和Clark[1997]发现，即使是在一个合并4项的写缓冲区中，所生成的停顿也会导致5%-10%的性能损失。</p>
</div>
</div>
<div class="sect3">
<h4 id="_采用编译器优化以降低缺失率"><a class="link" href="#_采用编译器优化以降低缺失率">5.5.7. 采用编译器优化以降低缺失率</a></h4>
<div class="paragraph">
<p>前面介绍的技术都需要改变硬件。下面这种技术可以在不对硬件做任何改变的情况下降低缺失率。</p>
</div>
<div class="paragraph">
<p>这种神奇的效果来自软件优化——硬件设计人员最喜爱的解决方案！处理器与主存储器之间的性能差距越拉越大，已经促使编译器开发人员深入研究存储器的层次结构，以判断能否在程序编译时通过各种优化技术来提高性能。同样，研究包括两个方面：指令缓存缺失的性能改进和数据级存缺失的性能改进。下面介绍的优化技术在很多现代编译器中得到了应用。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>循环交换</p>
<div class="literalblock">
<div class="content">
<pre>一些程序中存在嵌套循环，它们会以非连续顺序访问存储器中的数据。只要交换一下这些循环的嵌套顺序，就可以使程序代码按照数据的存储顺序来访问它们。如果缓存中无法容纳这些数组，这一技术可以通过改善空间局部性来减少缺失；通过重新排序，可以使缓存块中的数据在被替换之前，得到最大限度的利用。</pre>
</div>
</div>
</li>
<li>
<p>分块
这种优化方法通过改善时间局部性来减少缓存缺失。我们还是要处理多个数组，其中有的数组按行访问，有的按列访问。由于在每个循环迭代中都用到了行与列，所以按行或按列来存储数组并不能解决问题[（按行存储称为行主序（rowmajor order），按列存储称为列主序（column major order）]。这种正交访问方式意味着在进行循环交换之类的转换操作之后，仍然有很大的改进空间。</p>
<div class="literalblock">
<div class="content">
<pre>分块算法不是对一个数组的整行或整列进行操作，而是对其子矩阵（或称块）进行操作。其目的是在缓存中载入的数据被替换之前，最大限度地利用它。</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_对指令和数据进行硬件预取以降低缺失代价或缺失率"><a class="link" href="#_对指令和数据进行硬件预取以降低缺失代价或缺失率">5.5.8. 对指令和数据进行硬件预取，以降低缺失代价或缺失率</a></h4>
<div class="paragraph">
<p>通过将执行过程与访存过程重叠，非阻塞级存能有效地降低缺失代价。另一种方法是在处理器真正需要某个数据之前，预先获取它们。指令和数据都可以预先提取，既可以直接放在缓存中，也可以放在一个访问速度快于主存储器的外部缓冲区中。</p>
</div>
<div class="paragraph">
<p>指令预取经常在缓存外部的硬件中完成。通常，处理器在一次缺失时提取两个块：被请求的块和下一个相邻块。被请求的块放在它返回时的指令缓存中，预取块被放在指令流缓冲区中。如果被请求的块当前存在于指令流级缓冲区中，则取消该缓存请求，从流缓冲区中读取这个块，并发出下一条预取请求。</p>
</div>
<div class="paragraph">
<p>类似方法可应用于数据访问[Jouppi.1990]。Palacharla 和Kessler[1994]研究了一组科学计算程序，并考查了多个可以处理指令或数据的流缓冲区。他们发现，对于一个具有两个64KiB四路组相联缓存的处理器（一个用于缓存指令，另一个用于缓存数据），8个流缓冲区可以捕获其所有缺失的50%-70%。</p>
</div>
<div class="paragraph">
<p>Intel core i7支持利用硬件预先提取到L1和L2中，最常见的预取情况是预取下一行。一些较早的lntel处理器使用更激进的硬件预取，但会导致某些应用程序的性能降低，一些高级用户会因此而关闭这一功能。</p>
</div>
<div class="paragraph">
<p>预取操作需要利用空闲的存储带宽，但如果它干扰了其他关键路径缺失内容的访问，反而会导致性能下降。在编译器的帮助下，可以减少无用预取。当预取操作正常执行时，它对功耗的影响可以忽略。如果预取的数据并未被用到或者替换了有用数据，预取操作会对功耗产生负面影响</p>
</div>
</div>
<div class="sect3">
<h4 id="_用编译器控制预取以降低缺失代价或缺失率"><a class="link" href="#_用编译器控制预取以降低缺失代价或缺失率">5.5.9. 用编译器控制预取，以降低缺失代价或缺失率</a></h4>
<div class="paragraph">
<p>硬件预取之外的另一种方法是，编译器插入预取指令，以便在处理器需要数据之前请求数据。共有以下两种预取。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>寄存器预取将数据值载入一个寄存器。</p>
</li>
<li>
<p>缓存预取仅将数据载入缓存，而不载入寄存器。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>这两种预取都可能触发异常，也可能不触发；也就是说，其地址可能会也可能不会导致虚拟地址错误异常和保护冲突异常。按照这一概念划分，普通的载入指令可被视为“故障性寄存器预取指令”。如果一次预取可能导致异常，那么就把它转为空操作，空操作不会触发缺页错误。这样的非故障性预取是我们想要的。</p>
</div>
<div class="paragraph">
<p>最有效的预取对程序来说是“语义上不可见的”：它不会改变寄存器和存储器的内容，也不会导致虚拟存储器错误。今天的大多数处理器提供非故障性缓存预取能力。本节采用非故障性缓存预取，也称为非绑定（nonbinding）预取。</p>
</div>
<div class="paragraph">
<p>只有当处理器在预取数据时能够继续工作的情况下，预取才有意义；也就是说，缓存在等待返回预取数据时不会停顿，而是继续提供指令和数据。可以想见，这些计算机的数据缓存通常是非阻塞性的。</p>
</div>
<div class="paragraph">
<p>与硬件控制的预取操作类似，这里的目标也是将执行过程与数据预取过程重叠。循环是重要的预取优化目标，因为它们本身很适合进行预取优化。如果缺失代价很小，编译器只需将循环展开一两次，在执行时调度这些预取操作。如果缺失代价很大，它会使用软件流水线或者将循环展开多次，以预先提取数据，供后续迭代使用。</p>
</div>
<div class="paragraph">
<p>不过，发出预取指令会带来指令开销，所以编译器必须确保这些开销不会大于所得到的好处。如果程序能够将注意力放在那些可能导致缓存缺失的访问上，就可以避免不必要的预取操作，同时大大缩短存储器平均访问时间。</p>
</div>
<div class="paragraph">
<p>尽管数组优化很好理解，但现代程序更倾向于使用指针。Luk和Mowry [1999]已经证明。基于编译器的预取优化有时也可以扩展到指针。在10个使用递归数据结构的程序中，在访问一个节点时预取所有指针，可以使一半程序的性能提高4%-31%，而其他程序的性能变化不超过原性能的2%。问题是预取是否针对级存中已经存在的数据，以及预取是否执行得足够早，以便数据在需要时及时到达。</p>
</div>
<div class="paragraph">
<p>许多处理器支持缓存预取指令，高端处理器（比如 Intel Core i7）还经常在硬件中完成某种自动预取。</p>
</div>
</div>
<div class="sect3">
<h4 id="_使用hbm扩展存储器层次结构"><a class="link" href="#_使用hbm扩展存储器层次结构">5.5.10. 使用HBM扩展存储器层次结构</a></h4>
<div class="paragraph">
<p>HBM 封装技术中封装的存储器容量，难以满足服务器中的大多数通用处理器对存储器的需求，所以人们建议使用与计算芯片封装在一起的DRAM来构建大容量的L4缓存。随着128MiB至1GiB以上HBM技术的出现，L4缓存的容量要远大于目前的片上L3缓存容量。使用如此之大的基于DRAM的缓存会带来一个问题：缓存标签放在哪里？这取决于标签的数量。假定我们使用的块大小为64B，那么lGiB的L4缓存需要96MiB的标签，远多于CPU上缓存中的静态存储器数量。将块大小增大至4KiB，会使标签存储急剧缩减至256000项，也就是总存储量小于1MiB。如果下一代多核处理器中的L3缓存达到4-16MiB或更多，那么这样的标签存储是可能接受的。但这样大的块大小有两个重要问题。</p>
</div>
<div class="paragraph">
<p>首先，如果许多块中的内容都不会用到，那么缓存的使用效率可能会比较低下；这称为碎片化问题，它也出现于虚拟存储器系统中。此外，如果许多数据都是没用的，那么传送这样大的数据块也是效率低下的。其次，由于数据块比较大，所以DRAM缓存中保存的不同数据块的数目就要少得多了，这样会导致更多的缺失，尤其是冲突缺失和一致性缺失。</p>
</div>
<div class="paragraph">
<p>第一个问题的部分解决方法是增加子块。子块允许一个缓存行中只有部分数据是有效的，当发生缺失时，可以只获取其中有效的子块。但对于解决第二个问题，子块无能为力。</p>
</div>
<div class="paragraph">
<p>使用较小的数据块时，标签存储是一个主要缺陷。该问题有一个可能有效的解决方案，就是直接把HBM作为L4缓存的标签存储到HBM中。乍看起来，这似乎是不可行的，因为每访问一次L4缓存都需要访问两次DRAM：一次用于标签，一次用于数据本身。由于随机 DRAM访问的时间较长，通常为100或更多个处理器时钟周期，所以这种方法曾经被放弃。Loh和Hill（2011）为这一问题提出了一种更聪明的解决方案：将标签和数据放在HBM SDRAM中的同一行中。尽管打开这个行（还有最后关闭这个行）需要大量时间，但访问同一行的不同部分所带来的CAS延迟，大约是访问一个新行所需时间的三分之一。因此，我们可以先访问这个块的标签部分，如果命中，则使用一次列访问来选择正确的字。Loh和Hi(L-H)还建议在设计L4HBM缓存的组织形式时，每个SDRAM行都包含一组标签（位于数据块的头部）和29个数据段，组成一个29路组相联缓存。在访问L4级存时，打开一个合适的行，并读取标签；一次命中只需要再增加一次列访问就可以获得匹配数据。</p>
</div>
<div class="paragraph">
<p>Qureshi和Loh(2012)年提出了一种称为熔合缓存（alloy cache）的改进方法，它可以缩短命中时间。熔合缓存将标签和数据融在一起，并使用一种直接映射的缓存结构。这一改进通过直接对HBM缓存进行索引，并对标签和数据进行突发传输，使L4缓存访问时间缩短到一个HBM周期。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_提高存储器系统的可靠性"><a class="link" href="#_提高存储器系统的可靠性">5.6. 提高存储器系统的可靠性</a></h3>
<div class="paragraph">
<p>大型缓存和主存储器显著增加了制造过程和操作过程中动态发生错误的可能性。由电路变化引起的可重复的错误称为硬错误(hard error）或永久性故障(permanent fault）。硬错误可能发生在制造过程中，也可能发生在操作过程中的电路更改中（例如，在多次写入之后闪存单元发生故障）。所有DRAM、闪存和大多数SRAM在制造时都留有备用行，因此通过编程用备用行替换有缺陷的行可以解决少量的制造缺陷。动态错误是指在电路不改变的前提下存储单元内容发生改变的情况，被称为软错误（sof error)或瞬态故障（transient fault)。</p>
</div>
<div class="paragraph">
<p>动态错误可以使用奇偶校验检测，可以使用纠错码（ECC）检测和纠正。因为指令缓存是只读的，所以用奇偶校验就够了。在更大型的数据缓存和主存储器中，则使用ECC技术来检测和纠正错误。奇偶校验只需要占用一个数据位就可以检测一系列数据位中的一个错误。由于无法使用奇偶校验来检测多位错误，所以必须限制用奇偶校验提供保护的位数。典型的比例是每8个数据位使用一个奇偶校验位。ECC可以检测两个错误并纠正一个错误，代价是每64个数据位占用8位的开销。</p>
</div>
<div class="paragraph">
<p>在规模庞大的系统中，出现多个错误乃至单个存储芯片完全失效的概率非常大。IBM引入了Chipkill来解决这一问题。许多大规模系统使用这一技术，比如IBM和SUN服务器以及GoogleClusters。(Intel将其自己的版本命名为SDDC。）Chipkill在本质上类似于磁盘中使用的RAID方法，它分散数据和ECC信息，以便在单个存储芯片完全失效时，可以从其余存储芯片中重构丢失数据。根据IBM的分析，假定有一台具有10000个处理器的服务器（每个处理器有4GiB存储器)，在3年的运行中出现不可恢复错误的数目如下所示。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>仅采用奇偶校验位——大约90000个，或者说每17分钟一个不可恢复（或未检测到）的故障。</p>
</li>
<li>
<p>仅采用ECC——大约3500个，或者说大约每7.5小时一个不可恢复（或未检测到）的故障。</p>
</li>
<li>
<p>Chipkill——大约每2个月一个不可恢复（或未检测到）的故障。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>看待这个问题的另一种方法是，在实现与Chipkill相同错误率的同时，求出其他两种方式可以保护的最大服务器数目（每个服务器拥有4GiB存储器）。采用奇偶校验位方法时，即使是一台仅包括一个处理器的服务器，其不可恢复的错误率也要高于由10000台服务器组成、受Chipkil保护的系统。采用ECC方法时，一个包含17台服务器的系统与一个包含10000台服务器的Chipkill系统的故障率大体相同。因此，对于仓库级计算机中的50 000-100 000台服务器来说，需要采用Chipkill方法。</p>
</div>
</div>
<div class="sect2">
<h3 id="_虚拟存储器和虚拟机"><a class="link" href="#_虚拟存储器和虚拟机">5.7. 虚拟存储器和虚拟机</a></h3>
<div class="ulist">
<ul>
<li>
<p>要实现多个程序同时运行，共享内存空间。将内存划分并通过页表将程序与真实的物理地址相联系，这样在程序看来是自己独占内存。</p>
</li>
<li>
<p>虚拟机可以使多个用户共享同一台计算机，且用户本身感知不到其他用户的存在。虚拟机监视器（VMM）决定如何将虚拟资源映射到物理资源上。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>主存可以为通常由磁盘实现的辅助存储充当“cache”。这种技术被称为虚拟存储。从历史上看，提出虚拟存储的主要动机有两个：允许在多个程序之间高效安全地共享内存，例如云计算的多个虚拟机所需的内存，以及消除小而受限的主存容量对程序设计造成的影响。50年后，第一条变成主要设计动机。</p>
</div>
<div class="paragraph">
<p>当然，为了允许多个虚拟机共享内存，必须保护虚拟机免受其他虚拟机影响，确保程序只读写分配给它的那部分主存。主存只需存储众多虚拟机中活跃的部分，就像cache只存放一个程序的活跃部分一样。因此，局部性原理支持虚拟存储和cache，虚拟存储允许我们高效地共享处理器以及主存。</p>
</div>
<div class="paragraph">
<p>在编译虚拟机时，无法知道哪些虚拟机将与其他虚拟机共享存储。事实上，共享存储的虚拟机在运行时会动态变化。由于这种动态的交互作用，我们希望将每个程序都编译到它自己的地址空间中——只有这个程序能访问的一系列存储位置。虚拟存储实现了将程序地址空间转换为物理地址。这种地址转换处理加强了各个程序地址空间之间的保护。</p>
</div>
<div class="paragraph">
<p>虚拟内存的第二个动机是允许单用户程序使用超出内存容量的内存。以前，如果一个程序对于存储器来说太大，程序员应该调整它。程序员将程序划分成很多段，并将这些段标记为互斥的。这些程序段在执行时由用户程序控制载入或换出，程序员确保程序在任何时候都不会访问未载入的程序段，并且载入的程序段不会超过内存的总容量。传统的程序段被组织为模块，每个模块都包含代码和数据。不同模块之间的过程调用将导致一个模块覆盖掉另一个模块。</p>
</div>
<div class="paragraph">
<p>可以想象，这种责任对程序员来说是很大的负担。虚拟存储的发明就是为了将程序员从这些困境中解脱出来，它自动管理由主存（有时称为物理内存，以区分虚拟存储）和辅助存储所代表的两级存储层次结构。</p>
</div>
<div class="paragraph">
<p>虽然虚拟存储和cache的工作原理相同，但不同的历史根源导致它们使用的术语不同。虚拟存储块被称为页，虚拟存储失效被称为缺页失效。在虚拟存储中，处理器产生一个虚拟地址，该地址通过软硬件转换为一个物理地址，物理地址可访问主存。这个过程被称为地址映射或地址转换：如今，由虚拟存储控制的两级存储层次结构通常是个人移动设备中的DRAM和闪存，在服务器中是DRAM和磁盘。如果我们使用图书馆类比，可以将虚拟地址视为书名，将物理地址视为图书馆中该书的位置，它可能是图书馆的索书号。</p>
</div>
<div class="paragraph">
<p>虚拟内存还通过重定位简化了执行时程序的载入。在用地址访问存储之前，重定位将程序使用的虚拟地址映射到不同的物理地址。重定位允许将程序载入主存中的任何位置。此外，现今所有的虚拟存储系统都将程序重定位成一组固定大小的块（页），从而不需要寻找连续内存块来放置程序：相反，操作系统只需要在主存中找到足够数量的页。</p>
</div>
<div class="paragraph">
<p>在虚拟存储中，地址被划分为虚拟页号和页内偏移。物理页号构成物理地址的高位部分。页内偏移不变，它构成物理地址的低位部分。页内偏移的位数决定页的大小。虚拟地址可寻址的页数与物理地址可寻址的页数可以不同。拥有比物理页更多数量的虚拟页是一个没有容量限制的虚拟存储的基础。</p>
</div>
<div class="paragraph">
<p>缺页失效的高成本是许多设计选择虚拟存储系统的原因。磁盘的缺页失效处理需要数百万个时钟周期。这种巨大的失效代价（主要由获得标准页大小的第一个字所花费的时间来确定）导致了设计虚拟存储系统时的几个关键决策：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>页应该足够大以分摊长访问时间。目前典型的页大小从4KiB到64KiB不等。支持32KiB和64KiB页的新型桌面和服务器正在研发，但是新的嵌入式系统正朝另一个方向发展，页大小为lKiB。</p>
</li>
<li>
<p>能降低缺页失效率的组织结构很有吸引力。这里使用的主要技术是允许存储中的页以全相联方式放置。</p>
</li>
<li>
<p>缺页失效可以由软件处理，因为与磁盘访问时间相比，这样的开销将很小。此外，软件可以用巧妙的算法来选择如何放置页面，只要失效率减少很小一部分就足以弥补算法的开销。</p>
</li>
<li>
<p>写穿透策略对于虚拟存储不合适，因为写人时间过长。相反，虚拟存储系统采用写回策略。</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_页的存放查找失效"><a class="link" href="#_页的存放查找失效">5.7.1. 页的存放、查找、失效</a></h4>
<div class="paragraph">
<p>由于缺页失效的代价非常高，设计人员通过优化页的放置来降低缺页失效频率。如果允许一个虚拟页映射到任何一个物理页，那么在发生缺页失效时，操作系统可以选择任意一个页进行替换。例如，操作系统可以使用复杂的算法和复杂的数据结构来跟踪页面使用情况，来选择在较长一段时间内不会被用到的页。使用先进而灵活的替换策略降低了缺页失效率，并简化了全相联方式下页的放置。</p>
</div>
<div class="paragraph">
<p>全相联映射的困难在于项的定位，因为它可以在较高存储层次结构中的任何位置。全部进行检索是不切实际的。在虚拟存储系统中，我们使用一个索引主存的表来定位页；这个结构称为页表，它被存在主存中。页表使用虚拟地址中的页号作为索引，找到相应的物理页号。每个程序都有自己的页表，它将程序的虚拟地址空间映射到主存。在图书馆类比中，页表对应于书名和图书馆位置之间的映射。就像卡片目录可能包含学校中另一个图书馆中书的表项，而不仅仅是本地的分馆，我们将看到该页表也可能包含不在内存中的页的表项。为了表明页表在内存中的位置，硬件包含一个指向页表首地址的寄存器，我们称之为页表寄存器。现在假定页表存在存储器中一个固定的连续区域中。</p>
</div>
<div class="paragraph">
<p>由于页表包含了每个可能的虚拟页的映射，因此不需要标签。在cache术语中，索引是用来访问页表的，这里由整个块地址即虚拟页号组成。</p>
</div>
<div class="paragraph">
<p>如果虚拟页的有效位为无效，则会发生缺页失效。操作系统获得控制。这种控制的转移通过例外机制完成。一旦操作系统得到控制、它必须在存储层次结构的下一级（通常是闪存或磁盘）中找到该页，并确定将请求的页放在主存中的什么位置。</p>
</div>
<div class="paragraph">
<p>虚拟地址本身并不会立即告诉我们该页在辅助存储中的位置。回到图书馆的类比，我们无法仅依靠书名就找到图书的具体位置。而是按目录查找，获得书在书架上的位置信息，比如说图书馆的索引书号。同样，在虚拟存储系统中，我们必须跟踪记录虚拟地址空间的每一页在辅助存储中的位置。</p>
</div>
<div class="paragraph">
<p>由于我们无法提前获知存储器中的某一页什么时候将被替换出去，因此操作系统通常会在创建进程时为所有页面在闪存或磁盘上创建空间。这个空间被称为交换区。那时，它也会创建一个数据结构来记录每个虚拟页在磁盘上的存储位置。该数据结构可以是页表的一部分，或者可以是具有与页表相同索引方式的辅助数据结构。</p>
</div>
<div class="paragraph">
<p>操作系统还会创建一个数据结构用于跟踪记录使用每个物理地址的是哪些进程和哪些虚拟地址。发生缺页失效时，如果内存中的所有页都正在使用，则操作系统必须选择一页进行替换。因为我们希望尽量减少缺页失效次数，所以大多数操作系统选择它们认为近期内不会使用的页进行替换。使用过去的信息预测未来，操作系统遵循最近最少优用（LRU）替换策略。操作系统查找最近最少使用的页，假定某一页在很长一段时间都没有被访问，那么该页再被访问的可能性比最近经常访问的页的可能性要小。被替换的页被写到辅助存储器中的交换区。</p>
</div>
</div>
<div class="sect3">
<h4 id="_快速地址变换技术tlb"><a class="link" href="#_快速地址变换技术tlb">5.7.2. 快速地址变换技术（TLB）</a></h4>
<div class="paragraph">
<p>由于页表存储在主存中，因此程序每个访存请求至少需要两次访存：第一次访存获得物理地址，第二次访存获得数据。提高访问性能的关键在于页表的访问局部性。当使用虚拟页号进行地址转换时，它可能很快再次被用到，因为对该页中字的引用同时具有时间局部性和空间局部性。</p>
</div>
<div class="paragraph">
<p>因此，现代处理器包含一个特殊的cache以追踪记录最近使用过的地址转换。这个特殊的地址转换cache通常被称为快表（TLB）。TLB就相当于记录目录中的一些书的位置的小纸片：我们在纸片上记录一些书的位置，并且将小纸片当成图书馆索书号的cache，这样就不用一直在整个目录中搜索了。</p>
</div>
<div class="paragraph">
<p>TLB中的每个标签项保存虚拟页号的一部分，每个数据项保存一个物理号。因为每次引用都访问TLB而不是页表，所以TLB需要包括其他状态位，例如脏位和用位。TLB也适用于多级页表。TLB从最后一级页表中载入物理地址和保护标签即可。</p>
</div>
<div class="paragraph">
<p>每次引用时，在TLB中查找虚拟页号。如果命中，则使用物理页号来形成地址，相应的引用位被置位。如果处理器要执行写操作，那么脏位也会被置位。如果TLB发生失效，我们必须确定是缺页失效或只是TLB失效。如果该页在内存中，TLB失效表明缺少该地址转换。在这种情况下，处理器可以将（最后一级）页表中的地址转换加载到TLB中，并重新访问来处理失效。如果该页不在内存中，那么TLB失效意味着真正的缺页失效。在这种情况下，处理器调用操作系统的例外处理。由于TLB的项数比主存中的页数少得多，TLB失效比缺页失效更频繁。</p>
</div>
<div class="paragraph">
<p>TLB失效可以通过硬件或软件处理。实际上，两种方法之间几乎没有性能差异，因为它们的基本操作相同。</p>
</div>
<div class="paragraph">
<p>发生TLB失效并从页表中检索到失效的地址转换后，需要选择要替换的TLB表项。由于TLB表项包含引用位和脏位，所以当替换某一TLB表项时，需要将这些位复制回对应的页表项。这些位是TLB表项中唯一可修改的部分。使用写回策略——在失效时将这些表项写回而不是任何写操作都写回——是非常有效的，因为我们期望TLB失效率很低。一些系统使用其他技术来粗略估计引用位和脏位，这样在失效时无须写入TLB，只需载入新的表项。</p>
</div>
<div class="paragraph">
<p>TLB中相联度的设置非常多样。一些系统使用小的全相联TLB，因为全相联映射的失效率较低；同时由于TLB很小，全相联映射的成本也不是太高。其他一些系统使用容量大的TLB，通常其相联度较小。在全相联映射的方式下，由于硬件实现LRU方案成本太高，替换表项的选择就很复杂。此外，由于TLB失效比缺页失效更频繁，因此需要用较低的代价来处理，而不能像缺页失效那样选择一个开销大的软件算法。所以很多系统都支持随机选择替换表项。</p>
</div>
</div>
<div class="sect3">
<h4 id="_通过虚拟存储器提供保护"><a class="link" href="#_通过虚拟存储器提供保护">5.7.3. 通过虚拟存储器提供保护</a></h4>
<div class="paragraph">
<p>页式虚拟存储器（包括缓存页表条目的TLB）是避免进程相互影响的主要机制。多道程序设计（multiprogramming，几个同时运行的程序共享一台计算机的资源）需要在各个程序之间提供保护和共享，从而产生了进程（process）的概念。进程就是一个程序呼吸的空气、生存的空间——也就是一个正在运行的程序加上继续运行它所需的全部状态。在任意时刻，必须能够从一个进程切换到另一个进程。这种交换被称为进程切换(process switch)或上下文切换(context switch)。</p>
</div>
<div class="paragraph">
<p>操作系统和体系结构联合起来就能使进程共享硬件而不会相互干扰。为此，在运行一个用户进程时，体系结构必须限制用户进程能够访问的资源，但要允许操作系统进程访问更多资源。体系结构至少要做到以下几点。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>提供至少两种模式，指出正在运行的进程是用户进程还是操作系统进程。后者有时被称为内核（kemel）进程或管理（supervisor）进程。</p>
</li>
<li>
<p>提供用户进程可以使用但不能写入的处理器状态的一部分。这种状态包括用户/管理模式位、异常启用/禁用位和存储器访问权限信息。之所以禁止用户写入这些状态信息，是因为如果用户可以授予自己管理员权限、禁用异常或者改变存储器访问权限，操作系统就不能控制用户进程了。</p>
</li>
<li>
<p>提供处理器借以从用户模式转为管理模式及反向转换的机制。前一种转换通常通过系统调用（system call）完成，使用一种特殊指令将控制传递到管理代码空间的一个专用位置。保存系统调用时刻的程序计数器，处理器转入管理模式。返回用户模式的过程类似于子程序返回过程，恢复到先前的用户/管理模式。</p>
</li>
<li>
<p>提供限制存储器访问的机制，这样在上下文切换时不需要将进程切换到磁盘就能保护该进程的存储器状态。固定大小的页面（通常长4KiB或8KiB）通过一个页表由虚拟地址空间映射到物理地址空间。这些保护性限制就包含在每个页表项中。保护性限制可以决定一个用户进程能否读取写入这个页而，以及能否从这个页而执行代码。此外，如果一个进程没有包含在页表中，那它就既不能读取也不能写人一个页面。由于只有操作系统才能更新页表，所以分页机制提供了全面的访问保护。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>分页虚拟存储器意味着每次存储器访问在逻辑上都要花费至少两倍的时间，一次存储器访问用于获取物理地址，第二次访问用于获取数据。这种操作成本太高了。解决方案是依靠局部性原理。如果这些访问具有局部性，那么访问操作的地址变换(address translation）也肯定具有局部性。只要将这些地址变换放在一个特殊的缓存中，存储器访问就很少需要第二次访问操作来变换地址了。这种特殊的地址变换级存被称为变换旁路缓冲区（TLB）。</p>
</div>
<div class="paragraph">
<p>TLB条目类似于缓存条目，其中的标签保存虚拟地址的一部分，数据部分保存物理页地址保护字段、有效位，通常还有一个使用位和一个脏位（diry bit）。操作系统在改变这些位时，首先改变页表中的值，然后使相应的TLB项失效。当从页表重新载入这个条目时，TLB即获得这些位的准确副本。</p>
</div>
</div>
<div class="sect3">
<h4 id="_通过虚拟机提供保护"><a class="link" href="#_通过虚拟机提供保护">5.7.4. 通过虚拟机提供保护</a></h4>
<div class="paragraph">
<p>虚拟机最早是在20世纪60年代后期提出的，多年以来一直是大型机计算的重要组成部分。尽管它在20世纪80年代和90年代的单用户计算机领域被忽视，但近来再度得到广泛关注，原因如下：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>隔离与安全在现代系统中的重要性提高了；</p>
</li>
<li>
<p>标准操作系统的安全性和可靠性出现了问题；</p>
</li>
<li>
<p>许多不相关的用户（比如一个数据中心或云中的用户）会共享同一计算机；</p>
</li>
<li>
<p>处理器原始速度的飞速增长，使虚拟机的开销更容易被人接受。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>最广义的虚拟机定义基本上包括了所有提供标准软件接口的仿真方法，比如JavaVM。我们感兴趣的是那些在二进制指令集体系结构（ISA)级别提供完整系统级环境的虚拟机。最常见的情况是，VM支持的ISA与底层硬件相同。然而，VM也有可能支持不同的ISA，在ISA之间迁移时经常采用这种方法，这样在迁移到新ISA之前，软件仍能在原ISA上使用。在我们重点关注的虚拟机中，VM使用的ISA与其底层硬件相匹配。这种虚拟机称为（操作）系统虚拟机(system virtual machine)，IBM VM/370、VMware ESX Server 和Xen都属于此类虚拟机。它们给人一种错觉：虚拟机用户拥有整台计算机，包括操作系统的副本。一台计算机可以运行多个虚拟机，可以支持多种操作系统。在传统平台上，一个操作系统“拥有”所有硬件资源但在使用虚拟机时，多个操作系统一起共享硬件资源。</p>
</div>
<div class="paragraph">
<p>为虚拟机提供支持的软件称为虚拟机监视器（VMM）或管理程序（bypervisor），VMM是虚拟机技术的核心。底层硬件平台称为宿主机（host），其资源在客户VM之间共享。VMM决定了如何将虚拟资源映射到物理资源：物理资源可以分时共享、划分，甚至可以在软件内模拟。VMM比传统操作系统小得多，VMM的一个隔离部分大约只有10000行代码。</p>
</div>
<div class="paragraph">
<p>一般来说，处理器虚拟化的成本取决于工作负载。用户级别的处理器操作密集型程序（比如SPECCPU2006）的虚拟化开销为零，这是因为很少会调用操作系统，所有程序都以原速运行。与之相对，I/O密集型工作负载通常也是操作系统密集型的，会执行许多系统调用（以满足I/O需求）和特权指令（频繁使用会导致高昂的虚拟化开销）。这一开销的大小取决于必须由VMM模拟的指令数和模拟这些指令的缓慢程度。因此，如果客户VM与宿主机运行的ISA相同，则这个体系结构和VMM的目标就是直接在原始硬件上运行几乎所有指令，这与我们的预期一致。如果工作负载也是I/O密集型的，那么由于处理器经常要等待I/O，所以处理器虚拟化的成本可以完全被较低的处理器利用率所掩盖。</p>
</div>
<div class="paragraph">
<p>尽管我们这里关心的是VM提供保护的功能，但VM还有两个具有重大商业价值的优点。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>软件管理——VM提供了一种抽象，可以运行整个软件栈，甚至包括诸如DOS之类的旧操作系统。一种典型的部署是用一部分VM运行遗留操作系统，大量VM运行当前稳定的操作系统版本，而一少部分VM用于测试下一个操作系统版本。</p>
</li>
<li>
<p>硬件管理——需要多台服务器的原因之一是，希望每个应用程序都能在独立的计算机上与其兼容的操作系统一起运行，这种隔离可以提高系统的可靠性。VM使得这些分享软件栈能够独立运行，却共享硬件，从而减少了服务器的数量。另一个例子是，大多数较新的VMM支持将正在运行的VM迁移到另一台计算机上，以均衡负载或从发生故障的硬件中退出。云计算的兴起使得将整个VM迁移到另一个物理处理器的能力变得越来越有用。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>以上就是云服务器（比如Amazon的云服务器）依赖虚拟机的两个原因。</p>
</div>
</div>
<div class="sect3">
<h4 id="_对虚拟机监视器的要求"><a class="link" href="#_对虚拟机监视器的要求">5.7.5. 对虚拟机监视器的要求</a></h4>
<div class="paragraph">
<p>VM监视器必须完成哪些任务?它向客户软件提供一个软件接口，必须使不同客户软件的状态相互隔离，还必须保护自己以免受客户软件的破坏（包括客户操作系统）。定性需求包括：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>客户软件在VM上的运行情况应当与在原始硬件上完全相同，当然，与性能相关的行为或者因为多个VM共享固定资源所造成的局限除外；</p>
</li>
<li>
<p>客户软件应当不能直接修改实际系统资源的分配。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>为了实现处理器的“虚拟化”，VMM必须控制几乎所有操作———对特权状态的访问、地址变换、I/O、异常和中断，即使当前运行的客户VM和操作系统只是临时使用它们也是如此。</p>
</div>
<div class="paragraph">
<p>例如，在计时器中断时，VMM将挂起当前正在运行的客户VM，保存其状态，处理中断判断接下来运行哪个客户VM，然后载入其状态。依赖计时器中断的客户VM由VMM提供个虚拟计时器和一个仿真计时器中断。</p>
</div>
<div class="paragraph">
<p>为了进行管理，VMM的管理权限必须高于客户VM，后者通常以用户模式运行；这样还确保任何特权指令的执行都由VMM处理。系统虚拟机的基本需求几乎与上述分页虚拟存储器的需求相同。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>至少两种处理器模式：系统模式和用户模式。</p>
</li>
<li>
<p>仅在系统模式下可用的指令的一些特权子集，如果在用户模式下执行将会导致异常。所有系统资源都只能通过这些指令进行控制。</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_虚拟机的指令集体系结构支持"><a class="link" href="#_虚拟机的指令集体系结构支持">5.7.6. 虚拟机的指令集体系结构支持</a></h4>
<div class="paragraph">
<p>如果在设计ISA期间就为VM做了规划，就很容易减少VMM必须执行的指令数，缩短模拟这些指令所需的时间。如果一种体系结构允许VM直接在硬件上运行，则可以贴上可虚拟化的标签，IBM370体系结构便拥有这个标签。</p>
</div>
<div class="paragraph">
<p>遗憾的是，由于直到最近才开始考虑将VM用于桌面系统和基于PC的服务器应用程序，所以大多数指令集在设计时没有考虑虚拟化问题，其中包括80x86和大多数原始的RISC体系结构，尽管后者的问题比前者少。x86体系结构的最新特性试图弥补早期的缺陷，而RISC-V明确地包含了对虚拟化的支持。</p>
</div>
<div class="paragraph">
<p>由于VMM必须确保客户系统只能与虚拟资源进行交互，所以传统的客户操作系统是作为一种用户模式程序在VMM上运行的。因此，如果一个客户操作系统试图通过特权指令访问或修改与硬件资源相关的信息（比如，读取或写人页表指针），它会从用户模式陷人VMM。VMM随后可以对相应的实际资源进行适当的修改。</p>
</div>
<div class="paragraph">
<p>因此，如果任何以用户模式执行的指令试图读写此类敏感信息就会发生异常，从用户模式陷入VMM特权级别，VMM可以截获它，并根据客户操作系统的需要，向其提供敏感信息的一个虚拟化版本。</p>
</div>
<div class="paragraph">
<p>如果缺乏此类支持，则必须采取其他措施。VMM必须采取特殊的防范措施。找出所有存在问题的指令，并确保客户操作系统执行它们时能够正常运行，这样自然就会增加VMM的复杂度，降低VM的运行性能。一个有吸引力的扩展允许VM和操作系统在不同的特权级别上操作，每个特权级别都不同于用户级别。通过引入一个额外的特权级别，一些操作系统操作——例如超过了授予用户程序的权限，但不需要VMM的干预（因为它们不会影响任何其他VM）——就可以直接执行，而无须捕获和调用VMM的开销。</p>
</div>
</div>
<div class="sect3">
<h4 id="_虚拟机对虚拟存储器和io的影响"><a class="link" href="#_虚拟机对虚拟存储器和io的影响">5.7.7. 虚拟机对虚拟存储器和I/O的影响</a></h4>
<div class="paragraph">
<p>由于每个VM中的每个客户操作系统都管理其自己的页表集，所以虚拟存储器的虚拟化就成为另一项挑战。为了实现虚拟存储器的虚拟化，VMM区分了实际存储器（real memory）和物理存储器（physical memory）的概念（这两个词经常被视为同义词），使实际存储器成为虚拟存储器与物理存储器之间的独立、中间级存储器。（有人用虚拟存储器、物理存储器和机器存储器来命名这3个层级。）客户操作系统通过它的页表将虚拟存储器映射到实际存储器，VMM页表将客户的实际存储器映射到物理存储器。虚拟存储器体系结构可以通过页表指定（如在IBMVM/370和80x86中），也可以通过TLB结构指定（如在许多RISC体系结构中）。</p>
</div>
<div class="paragraph">
<p>VMM没有再为所有存储器访问进行多一层的中间访问，而是维护了一个影子页表（shadowpagetable），直接从客户虚拟地址空间映射到硬件的物理地址空间。通过检测客户页表的所有修改，VMM能保证硬件在变换地址时使用的影子页表项与客户操作系统环境的页表项一一对应，除了用正确的物理页替换了客户表中的实际页。因此，只要客户试图修改它的页表，或者试图访问页表指针，VMM就必须加以捕获。这通常通过以下方法实现：对客户页表提供写保护，并捕获客户操作系统对页表指针的所有访问尝试。前面曾经指出，如果对页表指针的访问属于特权操作，就会很自然地进行捕获。</p>
</div>
<div class="paragraph">
<p>IBM370体系结构在20世纪70年代添加了一个由VMM管理的中问层，解决了页表问题。客户操作系统和以前一样保存自己的页表，所以就不再需要影子页表了。AMD在其80x86处理器上采用了类似的方案。</p>
</div>
<div class="paragraph">
<p>在许多RISC计算机中，为了实现TLB的虚拟化，VMM管理实际TLB，并拥有每个客户VM的TLB内容的副本。为了实现这一功能，所有访问TLB的指令都必须被捕获。具有进程ID标签的TLB可以将来自不同VM与VMM的条目混合在一起，所以不需要在切换VM时刷新TLB。与此同时，VMM在后台支持VM的虚拟进程ID与实际进程ID之间的映射。</p>
</div>
<div class="paragraph">
<p>体系结构中最后一个要虚拟化的部分是I/O。到目前为止，这是系统虚拟化中最困难的一部分，原因在于连接到计算机的I/O设备数在增加，而且这些I/O设备的类型也更加多样。另外一个难题是在多个VM之间共享实际设备，还有一个难题是需要支持不同的设备驱动程序，这一点在同一VM系统上支持不同客户操作系统时尤为困难。为了维持这种VM抽象，可以为每个VM提供每种I/O设备驱动程序的一个通用版本，然后交由VMM来处理实际的I/O。</p>
</div>
<div class="paragraph">
<p>将虚拟I/O设备映射到物理I/O设备的方法取决于设备类型。例如，VMM通常会对物理磁盘进行分区，为客户VM创建虚拟磁盘，而VMM会维护虚拟磁道与扇区到物理磁道与扇区的映射。网络接口通常会在非常短的时间片内在VM之间共享，VMM的任务就是跟踪虚拟网络地址的消息，以确保客户VM只收到发给自己的消息。</p>
</div>
</div>
<div class="sect3">
<h4 id="_扩展指令集以实现高效虚拟化和更高的安全性"><a class="link" href="#_扩展指令集以实现高效虚拟化和更高的安全性">5.7.8. 扩展指令集，以实现高效虚拟化和更高的安全性</a></h4>
<div class="paragraph">
<p>在过去5到10年里，处理器设计师们，包括AMD和Intel的设计师(还包括一定范围内的ARM设计师），已经引入了指令集扩展来更高效地支持虚拟化。性能提升的两个主要领坡是对页表和TLB（虚拟存储器的基石）的处理，以及I/O，特别是处理中断和DMA。虚拟存储器性能的提升主要是通过避免不必要的TLB刷新和使用嵌套页表机制（IBM几十年前就已采用），而不是一套完整的影子列表。为提升I/O性能，增加了一些体系结构扩展。以允许设备直接使用DMA移动数据（不再需要VMM生成一个副本），而且允许客户操作系统直接处理设备中断和命令。在那些需要进行大量内存管理操作或大量使用I/O的应用中，这些扩展都展现了非常明显的性能提升。</p>
</div>
<div class="paragraph">
<p>由于现在广泛采用公共云系统来运行一些至关重要的应用程序，所以人们开始关注这些应用程序中的数据安全性。任何一段恶意代码，只要它的访问权限高于必须保证安全的数据，就会危及系统。比如，你正在运行一个信用卡处理应用程序，你就必须确保恶意用户不能获得信用卡号码，即使他们正在使用同一硬件并且有意攻击操作系统甚至VMM。利用虚拟化技术，可以禁止外部用户访问不同VM中的数据，这种方式所提供的保护显然要远高于一个多程序环境。但如果攻击者攻破了VMM，或者可以通过观察另一VM而得到信息，那么上述保护可能还不够。例如，假设攻击者穿透了VMM，他就可以重新映射存储器来访问数据中的任意部分。</p>
</div>
<div class="paragraph">
<p>或者，也可以在能够访问信用卡的代码中植入特洛伊木马来发起攻击。因为特洛伊木马与信用卡处理应用程序运行在同一个VM中，所以特洛伊木马只需要利用操作系统的缺陷来获取关键数据。大多数网络攻击用到了某种形式的特洛伊木马，通常是利用某种操作系统缺陷，这些木马或是将访问权限返给攻击者，并保持CPU仍然在特权模式下运行，或是允许攻击者上传一段代码，并将它们伪装成操作系统的一部分加以运行。无论是哪种情况，攻击者都获得了对CPU的控制，而且利用更高权限模式，可以进一步获取VM的任意内容。注意，加密本身并不能阻止这种攻击者。如果存储器中的数据没有加密（通常是这种情况），攻击者就可以访问所有此类数据。另外，如果攻击者知道加密密钥的存放位置，就可以自由访问密钥，然后访问加密数据。</p>
</div>
<div class="paragraph">
<p>Intel推出了一组指令集扩展，称为软件保护扩展（SGX)，允许用户程序创建飞地(enclave)。飞地就是一部分代码和数据，只有在使用时才会进行加密和解密，而且只能使用用户代码提供的密钥。由于飞地总是加密的，所以，针对虚拟存储器或l/O的标准OS操作可以访问这些飞地（例如，移动一个页），但不能提取任何信息。要使一个飞地正常工作，所有用到的代码和数据都必须是这个飞地的组成部分。尽管人们对细粒度保护技术已经讨论了几十年，但一直没有得到多少推动，一方面是由于其开销很高，另一方面是因为其他一些效率更高、侵人性更低的解决方案已经为人们所接受。随着网络攻击和在线机密信息数量的增加，人们开始重新检视用于提升细粒度安全性的技术。与Intel的SGX类似，IBM和AMD最近的处理器都支持对存储器的实时加密。</p>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_数据级并行"><a class="link" href="#_数据级并行">6. 数据级并行</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>数据级并行是指通过同时执行多个数据元素的相同操作来加速计算的并行性。在数据级并行中，处理器能够同时处理多个数据点，通常通过特殊的硬件支持来实现。这种并行方式不依赖于程序中控制结构的分支，而是通过对相同操作的多个数据元素进行并行处理来提高计算速度。数据级并行的核心思想是将大规模数据操作（如数组或矩阵中的每个元素）划分为多个并行任务，利用多核或SIMD（单指令多数据）架构同时执行这些任务，从而显著提高程序的执行效率。</p>
</div>
<div class="paragraph">
<p>数据级并行广泛应用于科学计算、图像处理、数字信号处理（DSP）、矩阵运算等领域，因为这些应用常常涉及到大量相同的计算操作。通过并行化这些数据操作，可以在很大程度上提高计算性能。实现数据级并行的常见方法包括向量处理器、图形处理单元（GPU）等硬件，通过多条数据通路和同时执行多个计算来加速处理过程。数据级并行不仅提高了处理效率，还使得大规模计算任务能够在较短的时间内完成。</p>
</div>
<div class="paragraph">
<p>尽管可以在MIMD计算机上编写运行在不同处理器上的独立程序，但是，为了实现更宏大、更协调的目标，程序员通常会编写一个运行在MIMD计算机中所有处理器上的程序，不同的处理器通过条件语句执行不同的代码段。这种编程风格称为单程序多数据流（Single Program Multiple Data,SPMD），它是在MIMD计算机上编程的一种常用方法。最接近多指令流单数据流（MISD）的处理器应该是“流处理器”了，这种处理器在单数据流上以流水线方式执行一系列计算：解析来自网络的输入，分析数据，解压缩，查找匹配，等等。相比之下，与MISD相反的类型——SIMD更受欢迎一些。SIMD(Singlelnstruction stream,Multiple Data streams)计算机对数据向量进行操作。例如，单个SIMD指令将64个数据流发送到64个ALU上，以在单个时钟周期内完成64次加法来将64个数字相加。SIMD的优点是所有的并行执行单元都是同步的，它们都响应自同一程序计数器（PC）中发出的同一指令。从程序员的角度看，这与他们已经很熟悉的SISD的概念非常接近。尽管每个单元将执行相同的指令，但是每个执行单元都有自己的地址寄存器，因此每个单元可以有不同的数据地址。一个顺序应用程序编译后，既可能在组织为SISD的串行硬件上运行，也可能在组织为SIMD的并行硬件上运行。SIMD的初衷是在数个执行单元上分摊控制单元的成本。因此，SIMD的另一个优点是减少了指令带宽和空间—SIMD只需要同时执行代码的一个副本，消息传递的MIMD可能需要在每个处理器中都存有一个副本，而共享存储器的MIMD可能需要多个指令缓存。SIMD在处理for循环中的数组时效果最好。因此，为了在SIMD上并行运行，程序中必须存在大量相同结构的数据，这称为数据级并行(data-level parallelism)。SIMD在处理case和switch语句时效果最差，在这些语句中，每个执行单元必须根据单元内存放的不同数据对这些数据执行不同的操作。存放有错误数据的执行单元必须被禁止执行、以便存放有正确数据的执行单元可以继续工作。在有n个case语句的情况下，SIMD处理器基本上只能以峰值性能的l/n工作。</p>
</div>
<div class="paragraph">
<p>单指令流多数据流（SIMD）使得一条向量指令代表了多条指令，同时流水化处理多条数据，从而减少了指令获取和解码的带宽。同时由于每条向量指令的行为已知，可以有效避免竞争冒险的出现。</p>
</div>
<div class="sect2">
<h3 id="_向量体系结构"><a class="link" href="#_向量体系结构">6.1. 向量体系结构</a></h3>
<div class="paragraph">
<p>对SIMD更加古老、更加优雅的解释被称为向量体系结构，这与Seymour Cray在20世纪70年代开始设计的计算机密切相关。这种体系结构与具有大量数据级并行的问题非常匹配。与早期的阵列处理器一样，64个ALU并不是同时执行64次加法，而是采用向量体系结构流水化ALU，从而以更低的成本获得良好的性能。向量体系结构的基本原理是从内存中收集数据元，将它们按顺序放人一大组寄存器中，使用流水化的执行单元在寄存器中依次对它们进行操作，然后将结果写回内存。向量体系结构的一个关键特性是拥有一组向量寄存器。这样，一个向量体系结构中可能具有32个向量寄存器，每个寄存器包含64个64位宽的数据元。</p>
</div>
<div class="paragraph">
<p>向量处理器大大降低了动态指令带宽。相比之下向量RISC-V相对于传统的RISC-V体系结构大大减少了指令数量。这种减少是因为一次向量操作可以处理多个个数据元，并且在RISC-V指令体系结构中近一半的循环开销指令在向量代码中无须存在。指令取指和执行次数的减少的确可以节省能耗。</p>
</div>
<div class="paragraph">
<p>另一个重要的区别是流水线冒险的频率不同。在传统的RISC-V代码中，如每个fadd.d指令必须等待fmul.d指令完成，每个fsd指令必须等待fadd.d指令完成，而且每个fadd.d指令和fmul.d指令还必须等待fld指令完成。在向量处理器中，每个向量指令只会停顿每个向量中的第一个数据元，然后后续数据元将顺利地沿着流水线流动。因此，每个向量操作仅需要一次流水线停顿，而不是每个数据元都停顿一次。</p>
</div>
<div class="paragraph">
<p>通过循环展开可以消除传统RISC-V上的流水线停顿。但是，指令带宽的巨大差异依然不能减少。因为向量中的各数据元是相互独立的，所以它们可以并行操作，这非常类似于Intel x86AVX指令中的子字并行。所有现代向量计算机都具有向量功能单元，该单元具有多个并行流水线，每个时钟周期可计算出两个或更多个结果。</p>
</div>
<div class="paragraph">
<p><strong>向量与标量</strong></p>
</div>
<div class="paragraph">
<p>与传统指令系统体系结构（在本节中被称为标量体系结构）相比，向量指令具有几个重要的属性：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>单个向量指令指定了大量工作——相当于执行了完整的循环。正因为这样，指令取指和译码带宽大大减少。</p>
</li>
<li>
<p>通过使用向量指令，编译器或程序员确认了向量中的每个结果都是独立的，因此硬件无须再检查向量指令内的数据冒险。</p>
</li>
<li>
<p>当程序中存在数据级并行时，相比使用MIMD多处理器，使用向量体系结构和编译器的组合更容易写出高效的应用程序。</p>
</li>
<li>
<p>硬件只需要在两条向量指令之间检查向量操作数之间的数据冒险，而无须检查向量中的每个数据元。减少检查的次数可以节省能耗和时间。</p>
</li>
<li>
<p>访问存储器的向量指令具有确定的访问模式。如果向量中的数据元位置都是连续的，则可以从一组存储器中交叉访问数据块，从而快速获取向量。因此，对整个向量而言，主存储器的延迟开销看上去只有一次，而不是对向量中的每个字都产生一次。</p>
</li>
<li>
<p>因为整个循环被具有已知行为的向量指令所取代，所以通常由循环引发的控制冒险不再存在。</p>
</li>
<li>
<p>与标量体系结构相比，节省的指令带宽和冒险检查以及对存储器带宽的有效利用，使得向量体系结构在功耗和能耗方面更具有优势。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>综上所述，在同等数据量的前提下，向量操作可以比一组标量操作序列更快完成。如果应用程序当中经常使用这些向量操作，设计者将更有动力在设计中加入向量单元。</p>
</div>
<div class="sect3">
<h4 id="_向量执行时间"><a class="link" href="#_向量执行时间">6.1.1. 向量执行时间</a></h4>
<div class="paragraph">
<p>向量运算序列的执行时间主要取决于3个因素：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>操作数向量的长度；</p>
</li>
<li>
<p>操作之间的结构冒险；</p>
</li>
<li>
<p>多个向量操作间的数据依赖关系。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>给定向量长度和启动速率（向量单元接受新操作数或生成新结果的速率），可以计算出一条向量指令的执行时间。</p>
</div>
<div class="paragraph">
<p>所有现代向量计算机都有具备多条并行流水线（或通道，lane）的向量功能单元。这些道在每个时钟周期可以生成一个或更多结果。与此同时这些计算机还可能拥有一些未完全流水化的功能单元。为简便起见，我们的RV64V实现方式有一条通道，各个操作的启动速率为每个时钟周期一个元素。因此，一条向量指令的执行时间（以时钟周期为单位）大约就是向量长度。</p>
</div>
<div class="paragraph">
<p>为了简化关于向量执行和向量性能的讨论，我们使用护航指令组（convoy）的概念，它是一组可以一起执行的向量指令。护航指令组中的指令不能包含任何结构冒险，否则需要在不同护航指令组中先后启动这些指令。可以通过计算护航指令组的数目来估计一段代码的性能。为了保持分析过程简单，假定在开始执行任意其他指令（标量或向量）之前，护航指令必须已经执行完成。</p>
</div>
<div class="paragraph">
<p>除了具有结构冒险的向量指令序列之外，具有写后读相关冒险的序列也应该位于单独的护航指令组中。然而，链接（chaining）操作可以让它们位于同一护航指令组中，因为链接操作允许向量操作在其向量源操作数的各个元素可用时立即启动：链中第一个功能单元的结果被“前递”给第二个功能单元。实践中经常采用以下方式来实现链接：允许处理器同时读写一个特定的向量寄存器，不过读写的是不同元素。早期的链接实现类似于标量流水线中的前递，但这限制了链中源指令与目标指令的时序。最近的链接实现采用灵活链接，这种方式允许向量指令链接到几乎任意其他活动的向量指令，只要不生成结构冒险就行。所有现代向量体系结构都支持灵活链接，这也是本章的假设之一。</p>
</div>
<div class="paragraph">
<p>为了将护航指令组转换为执行时间，需要一种度量来估计护航指令组的长度。这种度量被称为钟鸣(chime)，就是执行一个护航指令组所需的时间单位。因此，执行由m个护航指令组构成的向量序列需要m个钟鸣。当向量长度为n时，对于简单的RV64V实现来说，大约为\(m \times n\)个时钟周期。</p>
</div>
<div class="paragraph">
<p>钟鸣近似值忽略了处理器特有的一些额外开销，其中许多开销依赖于向量长度。因此，以钟鸣为单位测量时间时，对于长向量的近似要优于对短向量的近似。我们将使用钟鸣测量结果（而不是每个结果的时钟周期）来明确表示我们忽略了某些开销。</p>
</div>
<div class="paragraph">
<p>如果知道向量序列中的护航指令组数，就知道了用钟鸣表示的执行时间。在以钟鸣为单位测量执行时间时，所忽略的一个额外时间开销是对单个时钟周期内启动多条向量指令的限制。如果在一个时钟周期内只能发射一条向量指令（大多数向量处理器均如此），那钟鸣数会低估护航指令组的实际执行时间。由于向量的长度通常远大于护航指令组中的指令数，所以我们简单地假定这个护航指令组是在一个钟鸣中执行的。</p>
</div>
<div class="paragraph">
<p>另一个额外时间开销要比指令发射数量的限制重要得多。钟鸣模型忽略的最重要的开销是向量启动延迟（start-up time），即向量功能单元的流水线被向量指令填满之前，以时钟周期为单位的延迟。启动延迟主要由向量功能单元的流水线延迟决定。对于RV64V.我们使用与Cray-l相同的流水线深度，不过在更现代的处理器中，这些延迟有增加的趋势。特别是向量载入操作的延迟。所有功能单元都被完全流水化。浮点加的流水线深度为6个时钟周期，浮点乘为7个时钟周期，浮点除为20个时钟周期，向量载入为12个时钟周期。</p>
</div>
<div class="paragraph">
<p>有了这些向量基础知识之后，接下来的几节将介绍一些优化方式，这些优化可以提高性能，或者增加在向量体系结构中良好运行的程序类型。具体来说，它们将回答如下问题。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>向量处理器怎样执行单个向量才能在每个时钟周期执行多于一个元素？每个时钟周期处理多个元素可以提高性能。</p>
</li>
<li>
<p>向量处理器如何处理那些向量长度与最大向量长度不匹配的程序？由于大多数应用程序向量与硬件体系结构向量长度不匹配，所以需要一种高效的解决方案来处理这一常见情景。</p>
</li>
<li>
<p>如果要向量化的代码中含有IF语句，会发生什么?如果可以高效地处理条件语句，就能向量化更多的代码。</p>
</li>
<li>
<p>向量处理器需要从存储器系统中获得什么？如果没有足够的存储带宽，向量执行可能会徒劳无益。</p>
</li>
<li>
<p>向量处理器如何处理多维矩阵？为使向量体系结构能够很好地工作，必须对这个常见数据结构进行向量化。</p>
</li>
<li>
<p>向量处理器如何处理稀疏矩阵？这一常见数据结构也必须进行向量化。</p>
</li>
<li>
<p>如何为向量计算机编程？如果体系结构方面的创新不能与编程语言及其编译器技术相匹配，就不可能得到广泛应用。4.2.4多条通道：每个时钟周期处理多个元素向量指令集的一个关键好处是，软件仅使用一条很短的指令就能向硬件传送大量并行任务。一条向量指令可以包含数十个独立运算，而其编码使用的位数与一条传统的标量指令相同。为了执行一条向量指令，向量指令的并行语义允许实现使用一个深度流水化的功能单元（就像我们研究过的RV64V实现一样）、一组并行功能单元，或者并行功能单元与流水线功能单元的组合。图4-2说明了如何使用并行流水线来执行一个向量加法指令，从而提高向量性能。</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_单指令流多数据流simd"><a class="link" href="#_单指令流多数据流simd">6.1.2. 单指令流多数据流（SIMD）</a></h4>
<div class="paragraph">
<p>单指令流多数据流（SIMD, Single Instruction, Multiple Data）是一种数据级并行的计算模型，其中多个数据元素同时执行相同的指令。SIMD 架构允许处理器在一个时钟周期内对多个数据进行并行操作，而不需要多条独立的指令流。简而言之，SIMD 通过将同一指令应用于多个数据元素来加速计算过程。</p>
</div>
<div class="paragraph">
<p>在 SIMD 中，处理器的每个指令执行都针对多个数据元素，这些数据元素通常是数组、矩阵或向量中的元素。与传统的顺序执行单个数据流的处理方式不同，SIMD 允许通过并行计算在单个指令周期内完成多个操作。SIMD 利用特殊的硬件结构，如向量寄存器和多路复用器，来处理多个数据元素，这使得它能够在图形处理、音频处理、视频解码和科学计算等领域大幅提升性能。</p>
</div>
<div class="paragraph">
<p>SIMD 的特点之一是，它不需要对控制流进行并行化，而只关注数据并行化。这使得 SIMD 架构非常适合于那些数据操作模式高度重复且相似的任务，例如图像处理中的像素操作或向量运算。</p>
</div>
<div class="paragraph">
<p>SIMD 的优点包括显著提高运算速度和效率，尤其在需要大量相同计算的任务中，如大规模矩阵运算、图形渲染和数字信号处理。此外，SIMD 在硬件实现上较为简单，能够有效提高处理器的吞吐量。</p>
</div>
<div class="paragraph">
<p>然而，SIMD 也有其局限性。它依赖于特定的程序结构和数据格式，只有在数据可以并行处理时才能发挥优势。如果程序中数据间依赖较多或存在复杂的控制流结构，SIMD 的优势就会受到限制。此外，SIMD 需要硬件的支持，现代的多核处理器和图形处理单元（GPU）普遍支持 SIMD 指令集，如 Intel 的 SSE 和 AVX，AMD 的 3DNow!，以及 ARM 的 NEON 等。</p>
</div>
<div class="paragraph">
<p>向量指令集的一个关键好处是，软件仅使用一条很短的指令就能向硬件传送大量并行任务。一条向量指令可以包含数十个独立运算，而其编码使用的位数与一条传统的标量指令相同。为了执行一条向量指令，向量指令的并行语义允许实现使用一个深度流水化的功能单元（就像RV64V实现一样）、一组并行功能单元，或者并行功能单元与流水线功能单元的组合。</p>
</div>
<div class="paragraph">
<p>RV64V指令集有一个特性：所有向量算术指令只允许一个向量寄存器的第N个元素与其他向量寄存器的第N个元素进行运算。这一特性极大地简化了高度并行向量单元的设计，该单元可以构造为多个并行通道。和高速公路一样，我们可以通过添加更多通道来提高向量单元的峰值吞吐量。如从单通道变为四通道之后，一次钟鸣的时钟周期数由32个降为8个。若想让多通道带来优势，应用程序和体系结构都必须支持长向量；否则，它们会快速执行，耗尽指令带宽，并需要ILP技术提供足够的向量指令。</p>
</div>
<div class="paragraph">
<p>每条通道都包含向量寄存器堆的一部分以及来自每个向量功能单元的一条执行流水线。每个向量功能单元使用多条流水线（每条通道一条流水线），以每个时钟周期一个元素组的速度执行向量指令。第一条通道保存所有向量寄存器的第一个元素（元素0），所以任何向量指令的第一个元素的源操作数与目标操作数都在第一通道中。这种分配方式使得该通道本地的算术流水线无须与其他通道通信就能完成运算。通过避免通道间的通信，减少了构建高并行执行单元所需要的连接成本与寄存器堆端口，同时也解释了向量计算机为什么能够在每个时钟周期内完成多达64个运算（16通道，每条通道包含2个算术单元和2个载人存储单元）。</p>
</div>
<div class="paragraph">
<p>增加多条通道是提高向量性能的一种常用技术，它几乎不需要增加控制复杂性，也不需要对现有机器代码进行修改。它还允许设计人员在晶片面积、时钟频率、电压和能耗之间进行权衡啊，而且不需要牺牲峰值性能。如果向量处理器的时钟频率减半，那么将通道数量加倍就能保证原峰值性能。</p>
</div>
</div>
<div class="sect3">
<h4 id="_向量长度寄存器处理未知向量长度的循环"><a class="link" href="#_向量长度寄存器处理未知向量长度的循环">6.1.3. 向量长度寄存器：处理未知向量长度的循环</a></h4>
<div class="paragraph">
<p>条带挖掘技术使得每个向量运算都是针对向量大小小于或等于最大向量长度的情况来完成的。</p>
</div>
<div class="paragraph">
<p>向量寄存器处理器有一个自然向量长度，这一长度由最大向量长度（mv1）决定。该长度不大可能与程序中的实际向量长度相匹配。此外，在实际程序中，待定向量运算的长度在编译时通常是未知的。事实上，一段代码可能需要不同的向量长度。例如，考虑以下代码：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">for (i = 0; i &lt; n; i=i+1)
	Y[i] = a * X[i] + Y[i];</code></pre>
</div>
</div>
<div class="paragraph">
<p>所有这些向量运算的大小都取决于n，但n的取值甚至可能直到运行时才知道。n的值还可能是某个函数（该函数中包含上述循环）的参数，因而会在执行时发生变化。</p>
</div>
<div class="paragraph">
<p>这些问题的解决方案是添加一个向量长度寄存器（vl）。vl控制所有向量运算的长度，包括向量载入与存储运算。但vl中的值不能大于最大向量长度（mvl）。只要实际长度小于或等于ml，就能解决上述问题。这个参数意味着向量寄存器的长度可以随着计算机的发展而增大，而不需要改变指令集。</p>
</div>
<div class="paragraph">
<p>如果n的值在编译时未知，因而可能大于mv1，该怎么办呢?为了解决第二个问题（向量长于最大长度），可以使用一种名为条带挖掘（stripmining）的技术。条带挖掘是指生成一些代码，使每个向量运算都是针对向量大小小于或等于mv1的情况来完成的。一个循环处理迭代数为mv1倍数的情况，另一个循环处理剩下的迭代，这些迭代数量必须小于mvl。RISC-V有一种更好的方法，不用为条带挖掘单独使用一个循环。指令setvl取mvl和循环变量n中的较小的那个值写入vl（及另一个临时标量寄存器中）。如果循环的迭代次数大于n，则该循环最快能够计算mvl个值，所以setvl将vl设定为mvl。如果n小于mvl.在循环的最后一次迭代中，它应当仅计算最后n个元素，所以setvl将vl设定为n。setvl还会写入另一个标量寄存器，用于帮助之后的循环进行记录。</p>
</div>
</div>
<div class="sect3">
<h4 id="_谓词寄存器predicate_registers处理向量循环中的if语句"><a class="link" href="#_谓词寄存器predicate_registers处理向量循环中的if语句">6.1.4. 谓词寄存器（Predicate Registers）：处理向量循环中的IF语句</a></h4>
<div class="paragraph">
<p><strong>允许处理器在执行指令时跳过某些操作，从而实现分支控制</strong></p>
</div>
<div class="paragraph">
<p>根据Amdahl定律我们知道，中低度向量化程序的加速比非常有限。循环内部存在条件（IF语句）与使用稀疏矩阵是向量化程度较低的两个主要原因。循环中包含IF语句的程序无法使用前面讨论的技术以向量模式运行，因为IF语句会在循环中引入控制相关。同样，我们无法利用前面看到的各项功能高效地实现稀疏矩阵。下面讨论处理条件执行的策略，稀疏矩阵留待后文讨论。</p>
</div>
<div class="paragraph">
<p>考虑以C语言编写的以下循环：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">for (i = 0; i &lt; 64; i=i+1)
	if (X[i] != 0)
		X[i] = X[i] - Y[i];</code></pre>
</div>
</div>
<div class="paragraph">
<p>由于这一循环体需要条件执行，所以它通常不能向量化；但是，如果我们可以选择性地只执行`X[i] != 0`的循环体，那就可以实现减法的向量化。</p>
</div>
<div class="paragraph">
<p>实现这一功能的常见扩展称为向量掩码控制（vector-mask control)。在RV64V中，谓词寄存器保存此掩码，为一条向量指令中的每个元素运算提供了条件执行方式。这些寄存器使用一个布尔向量来控制向量指令的执行，就像条件执行指令使用布尔条件来判断是否要执行一个标量指令一样。当谓词寄存器p0被置位时，所有后续向量指令都仅针对一部分向量元素执行，这些元素在谓词寄存器中的对应项为1。如果目标向量寄存器中的某些项在谓词寄存器中的对应值为0，那它们就不会受到向量运算的影响。和向量寄存器一样，谓词寄存器也是可配置、可禁用的。启用一个谓词寄存器会将它初始化为全1，也就是说，后续的向量指令运算将对所有向量元素运行。</p>
</div>
<div class="paragraph">
<p>使用向量掩码寄存器确实是有开销的。对于标量体系结构，在条件不满足时，条件执行的指令仍然需要执行时间。无论如何，通过消除分支和相关的控制依赖确实可以加快条件指令的执行速度.即使这有时会做一些无用功。与此类似，采用向量掩码执行的向量指令仍然需要相同的执行时间，即使掩码为0的元素也是如此。同样，即使掩码中有大量0，使用向量掩码控制的速度仍然远快于使用标量模式的速度。向量处理器与GPU之间的一个区别是处理条件语句的方式。向量处理器将谓词寄存器作为体系结构状态的一部分，并且依靠编译器来显式地操控掩码寄存器。而GPU使用硬件来操控GPU软件无法看到的内部掩码寄存器，以实现相同效果。在这两种情况下，无论相应的掩码位是1还是0，硬件都要花时间执行向量元素，所以GFLOPS速率在使别掩码时会下降。</p>
</div>
</div>
<div class="sect3">
<h4 id="_存储体"><a class="link" href="#_存储体">6.1.5. 存储体</a></h4>
<div class="paragraph">
<p>载入存储向量单元的行为要比算术功能单元复杂得多。载入操作的启动延迟就是它从存储器向寄存器中载入第一个字的时间。如果可以在无停顿的情况下提供向量的其他元素，那么向量启动速率就等于提取或存储新字的速度。与较简单的功能单元不同，这一启动速率不一定是一个时钟周期，因为存储体（bank）的停顿可能会降低实际吞吐量。</p>
</div>
<div class="paragraph">
<p>一般情况下，载入/存储单元的初始化延迟要高于算术单元——在许多处理器中要多于100个时钟周期。对于RV64V，我们假定初始化延迟为12个时钟周期，与Cray-1相同。（最近的向量计算机使用缓存来降低向量载入与存储的延迟。）</p>
</div>
<div class="paragraph">
<p>为了保持每个时钟周期提取或存储一个字的启动速率，存储器系统必须能够提供或接受较多的数据。将访问对象分散在多个独立的存储体中，通常可以保证所需速率。稍后你会看到，拥有大量存储体对于处理那些访问多行或多列数据的向量载入或存储指令非常有用。</p>
</div>
<div class="paragraph">
<p>大多数向量处理器使用存储体，这允许进行多个独立访问，而不是简单的存储器交错，原因如下：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>许多向量计算机支持每个时钟周期执行多个载入或存储操作，访问存储体的周期时间通常比处理器周期时间高几倍。为了支持多个载入或存储操作的同时访问，存储器系统需要有多个存储体，还要能够独立控制对这些存储体的寻址。</p>
</li>
<li>
<p>大多数向量处理器支持载入或存储非连续的数据字。在这种情况下，需要进行独立的组寻址，而不是交叉寻址。</p>
</li>
<li>
<p>大多数向量计算机支持多个处理器共享同一存储器系统，所以每个处理器会生成其自己的独立寻址流。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>从更宏观的角度来看，向量载入/存储单元的角色类似于向量处理器中的预取单元，它们都通过向处理器提供数据流来提供数据带宽。</p>
</div>
</div>
<div class="sect3">
<h4 id="_步幅"><a class="link" href="#_步幅">6.1.6. 步幅</a></h4>
<div class="paragraph">
<p>向量中的相邻元素在存储器中的位置不一定是连续的。考虑下面这段用C语言编写的非常简单的矩阵乘法代码：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">for (i = 0;i &lt; 100: i=i+1)
	for (j = 0;j &lt; 100; j=j+1) {
		A[i][j] = 0.0;
		for (k = 0;k &lt; 100; k = k+1)
			A[i][j] = A[i][j] + B[i][j] * D[k][j];
	}</code></pre>
</div>
</div>
<div class="paragraph">
<p>我们可以将B的每一行与D的每一列的乘法向量化，以k为索引变量对内层循环进行条带挖掘。</p>
</div>
<div class="paragraph">
<p>为此，我们必须考虑如何对B中的相邻元素及D中的相邻元素进行寻址。在为数组分配存诸器时，该数组被线性化，并且必须以行主次序（如C语言）或列主次序（如Fortran语言）进行布局。这种线性化意味着行中的元素或者列中的元素在存储器中是不相邻的。例如，上面的C代码以行主次序来分配存储器，所以内层循环中各次迭代在访问D的元素时，这些元素之间的间隔等于行大小乘以8（每一项的字节数），共800字节。在基于缓存的系统中，通过分块有可能提高局部性。对于没有缓存的向量处理器，需要用另一种方法来提取在存储器中不相邻的向量元素。</p>
</div>
<div class="paragraph">
<p>对于那些要收集到一个寄存器中的元素，它们之间的距离称为步幅（stride）。在这个例子中，矩阵D的步幅为l00个双字(800字节)，矩阵B的步幅为1个双字（8字节）。对于以列为主的排序（Fortran 语言采用这一顺序）.这两个步幅会颠倒过来：矩阵D的步幅将为1.也就是说连续元素之间相隔1个双字（8字节），而矩阵B的步幅为100，也就是100个双字（800字节）。因此，如果不对循环进行重新排序，编译器就不能隐藏矩阵B和0中连续元素之间的长距离。</p>
</div>
<div class="paragraph">
<p>一旦将向量载入向量寄存器，它的表现就好像它的元素在逻辑上是相邻的。因此，仅利用具有步幅功能的向量载入及向量存储操作，向量处理器就可以处理大于1的步幅，这种步幅称为非单位步幅（nonunit stride）。向量处理器的一大优势就是能够访问非连续存储地址，并将其重组成一个稠密的结构。</p>
</div>
<div class="paragraph">
<p>缓存在本质上是处理单位步幅数据的。增加块大小有助于降低大型科学数据集（步幅为单位步幅）的缺失率，但增大块大小也可能会对那些以非单位步幅访问的数据产生负面影响。尽管分块技术可以解决其中一些问题但在某些问题上，高效访问非连续数据的能力仍然是向量处理器的一个优势。</p>
</div>
<div class="paragraph">
<p>在RV64V中，可寻址单位为1字节，所以我们示例中的步幅将为800。由于矩阵的大小在编译时可能是未知的，或者就像向量长度一样，在每次执行相同语句时可能会发生变化，所以必须对步幅值进行动态计算。像向量起始地址一样，向量步幅可以放在通用寄存器中。然后，RV64V指令VLDS（load vector with stride）将向量提取到向量寄存器中。同样，在存储非单位步幅向量时，使用指令VSTS(store vector with stride)。</p>
</div>
<div class="paragraph">
<p>支持大于1的步幅会使存储器系统变得复杂。一旦引人非单位步幅，就可能频繁访问同个存储体。当多个访问争用一个存储体时，就会发生存储体冲突，从而使某个访问陷入停领。如果满足以下条件，就会产生存储体冲突，进而造成停顿：</p>
</div>
<div class="stemblock">
<div class="content">
\[\frac{bank数}{步幅与bank数的最大公约数} &lt; bank繁忙时间\]
</div>
</div>
</div>
<div class="sect3">
<h4 id="_向量体系中稀疏矩阵的处理"><a class="link" href="#_向量体系中稀疏矩阵的处理">6.1.7. 向量体系中稀疏矩阵的处理</a></h4>
<div class="paragraph">
<p>前面曾经提到，稀疏矩阵很常见，所以使用一些技术来让使用稀疏矩阵的程序在向量模式下执行是很重要的。在稀疏矩阵中，向量元素通常是以某种压缩形式存储的，然后被间接访问。假定有一种简化的稀疏结构，我们可能会看到类似下面的代码：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">for (i = 0; i &lt; n; i=i+1)
	A[K[i]] = A[K[i]] + C[M[i]];</code></pre>
</div>
</div>
<div class="paragraph">
<p>这段代码实现数组A与数组C的稀疏向量求和，用索引向量K和M来指定A与C中的非零元素。（A和C的非零元素数必须相等，为n，所以K和M大小相同。）</p>
</div>
<div class="paragraph">
<p>支持稀疏矩阵的主要机制是采用索引向量的集中一分散(gather-scatter)操作。这种操作的目的是支持在稀疏矩阵的压缩表示（即不包含零）和正常表示（即包含零）之间进行转换。集中操作取得索引向量(index vector)，并在此向量中提取元素，元素位置等于基础地址加上索引向量中给定的偏移量。其结果是向量寄存器中的一个密集向量。在以密集形式对这些元素进行操作之后，可以再使用同一索引向量，通过分散存储操作，以扩展方式存储该稀疏向量。对此类操作的硬件支持称为集中一分散，几乎所有现代向量处理器都具备这一功能。RV64V指令为vldx（载入索引向量，也就是集中）和vstx（存储索引向量，也就是分散）。例如，如果x5、x6、x7和x28中包含以上序列中向量的起始地址，就可以用向量指令来对内层循环进行编码，如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-asm" data-lang="asm">vsetdcfg 4*FP64 		#4个64位浮点向量寄存器
vld		 v0. x7 		#载入K[]
vldx	 v1. x5. v0) 	#载入A[K[]]
vld		 v2. x28 		#载入M[]
vldi 	 v3. x6. v2)	#载入C[M[]]
vadd	 vl. vl. v3
vstx	 v1. x5. v0)	#存储 A[K[]]
vdisable				#禁用向量寄存器</code></pre>
</div>
</div>
<div class="paragraph">
<p>利用这一技术，可以以向量模式运行访问稀疏矩阵的代码。简单的向量化编译器无法自动将以上源代码向量化，因为编译器不知道K的元素是不同的值，因此也就不存在相关性。所以。需要程序员通过显式地在代码中指示编译器，可以放心地以向量模式运行这个循环。</p>
</div>
<div class="paragraph">
<p>尽管索引载入与存储（集中与分散）操作都可以流水化，但由于存储体在开始执行指令时是未知的，所以它们的运行速度通常远低于非索引载入或存储操作。寄存器堆还必须在向量单元的通道之间提供通信，以支持集中和分散操作。</p>
</div>
<div class="paragraph">
<p>执行集中和分散操作的每个元素都有各自的地址，所以不能对它们进行分体处理，而且在存储器系统的许多位置都可能存在冲突。因此，即使在基于缓存的系统上，每次访问也会造成严重的延迟。但是，如果架构师不是对这种不可预测的访问采取放任态度，而是针对这一情景进行设计，使用更多的硬件资源，那么存储器系统就能提供更好的性能。</p>
</div>
<div class="paragraph">
<p>在GPU中，所有载入都是集中操作，所有存储都是分散操作，因为没有单独的指令限制地址必须是连续的。为了将可能较慢的集中和分散操作转换为更高效的存储器单位步幅访问，GPU硬件必须在执行期间识别顺序地址，并且GPU程序员必须确保一次集中或分散操作中的所有地址都位于相邻位置。</p>
</div>
</div>
<div class="sect3">
<h4 id="_向量体系结构编程"><a class="link" href="#_向量体系结构编程">6.1.8. 向量体系结构编程</a></h4>
<div class="paragraph">
<p>向量体系结构的优势在于，编译器可以在编译时告诉程序员某段代码是否会向量化，通常还会给出一些提示，说明这段代码为什么没有向量化。这种简单的执行模型可以让其他领域的专家快速掌握修改代码来提高性能的方法，并提示编译器特定操作（比如集中一分散式的访存请求）间不存在依赖关系以提高性能。这就是编译器与程序员之间的对话，每一方都就如何提高性能给对方一些提示，从而简化向量计算机的编程。</p>
</div>
<div class="paragraph">
<p>今天，影响程序在向量模式下能否成功运行的主要因素是程序本身的结构：循环是否有真正的数据相关？能否调整它们的结构，使其没有此类相关？这一因素受算法选择的影响，在一定程度上还受编码方式的影响。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_图形处理器"><a class="link" href="#_图形处理器">6.2. 图形处理器</a></h3>
<div class="paragraph">
<p>GPU（Graphics Processing Unit，图形处理单元）是专门为图形和视频处理设计的高性能处理器。最初，GPU 主要用于加速计算机图形渲染，如二维和三维图形的生成、图像处理和显示。随着技术的发展，GPU 的计算能力逐渐超越了传统图形处理，成为一种强大的通用计算平台，尤其在需要并行处理的大规模数据计算中，具有显著的优势。</p>
</div>
<div class="paragraph">
<p>GPU 的核心特点是拥有大量的计算核心，能够同时处理大量数据。与 CPU（中央处理单元）不同，CPU 主要优化了顺序计算和较复杂的控制逻辑，而 GPU 更加专注于大规模并行计算，特别是数据并行任务。GPU 中的计算核心通常是简化的处理单元，专门设计用于处理并行任务，因此它能够高效地执行大量相同类型的计算操作，例如矩阵乘法、向量运算和像素处理。</p>
</div>
<div class="paragraph">
<p>除了传统的图形渲染，现代 GPU 还广泛应用于科学计算、人工智能、深度学习、数据分析和物理模拟等领域。GPU 的高吞吐量和并行计算能力使得它非常适合进行大规模的计算任务，特别是在深度学习中的矩阵运算和神经网络训练中，GPU 显示出了远超 CPU 的性能。GPU 加速器通过并行化的计算模式，可以将数据密集型任务的处理时间大大缩短。</p>
</div>
<div class="paragraph">
<p>GPU 的优点包括高并行度、高吞吐量和对浮点运算的优化。它能够处理大量的计算任务，特别适用于图形渲染、图像处理、科学计算和机器学习等应用。GPU 在能效方面也表现出色，因为它们能够在较低的时钟频率下，通过大量的并行计算来完成工作。下表为CPU与GPU的区别：</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">特点</th>
<th class="tableblock halign-left valign-top">CPU</th>
<th class="tableblock halign-left valign-top">GPU</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">设计目标</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">专为处理广泛的任务和复杂的控制逻辑而设计，通常用来执行操作系统、应用程序以及各种计算任务。它擅长处理单线程任务和需要高指令集支持的复杂控制流。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">最初为图形渲染任务设计，专注于高效执行大量的并行数据计算。随着计算技术的发展，GPU 被扩展用于高并行计算的通用任务，如科学计算、机器学习和数据处理。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">计算核心</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">通常拥有较少的核心（2到32个核心），每个核心的时钟频率较高。每个核心都具备较强的运算能力，适用于执行复杂的顺序计算和多任务处理。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">包含大量的处理核心（数百个甚至更多），每个核心相对简单，能够执行大量的相同操作。GPU 的设计目的是通过并行处理大量数据来加速特定类型的计算，如图像处理和大规模矩阵运算。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">并行性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">擅长处理少量复杂任务，尤其是需要频繁分支、控制流和复杂计算的任务。它的并行性通常体现在多核并行处理上，但核数较少，主要依靠较高的时钟频率来提升性能。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">天生设计为处理大量并行计算任务，具有极高的数据并行性。GPU 通过数百或数千个核心同时处理相同的操作，从而加速处理大规模数据集，尤其是在没有复杂控制流的情况下，如图像、视频和矩阵计算。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">处理能力</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">虽然单个核心的处理能力较强，能够有效处理复杂的算法、分支判断和系统管理任务，但它在处理大规模并行任务时并不高效。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在执行大规模数据并行任务时，比 CPU 更高效。GPU 在执行重复性计算任务（如图形渲染、深度学习训练、科学计算等）时，能够显著提高吞吐量，尤其适合大规模矩阵运算和向量计算。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">存储结构</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">内存层次结构复杂，通常有多级缓存（L1、L2、L3），并且具有直接访问较大的主存（RAM）的能力。CPU 的缓存和内存结构优化了频繁的指令和数据访问。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">也有自己的内存结构，通常包括高速的共享内存和全局内存。GPU 使用统一的内存访问模式来处理大规模并行任务，但内存访问的延迟较高，因此通常需要通过优化内存访问模式来提高性能。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">任务适应性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">适合处理复杂的逻辑运算、输入/输出操作、网络管理和多任务操作等，能够执行多种类型的程序和应用，尤其是那些包含大量分支、条件判断和动态任务的程序。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">非常适合数据密集型的任务，如图像渲染、科学计算、大规模并行处理和机器学习训练等。GPU 更适合没有太多分支、顺序依赖的计算，尤其是在需要大规模并行计算的应用中表现突出。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">编程模型</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">拥有复杂的指令集和强大的控制逻辑，支持多种编程语言和并发模型。程序员可以通过常见的编程模型（如多线程编程）来编写代码。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">虽然现代 GPU 也支持并行计算任务，但其编程模型相对复杂，需要使用特定的编程框架（如 CUDA 或 OpenCL）来实现并行计算。GPU 的计算模型强调数据并行性，编程时需要考虑数据访问模式和内存管理。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">能效</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">由于每个核心都设计得更为复杂，CPU 在处理多线程和高频率任务时能效较高，但在大规模并行任务上的能效较低。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">尽管每个核心较简单，但由于其高度并行的架构，GPU 能在执行大规模并行计算时提供优异的能效。GPU 的并行计算能力在处理密集型计算时比 CPU 高效得多，尤其在图形处理和机器学习等任务中能耗相对较低。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">适用领域</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">适用于操作系统、数据库管理、大多数应用程序和多任务处理等广泛领域，特别是需要高计算精度和灵活性的任务。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">主要用于图形渲染、科学计算、深度学习、大数据分析、加密解密等领域，在图像和视频处理、AI 训练和推理等方面有着卓越的表现。</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_检测与增强循环级并行"><a class="link" href="#_检测与增强循环级并行">6.3. 检测与增强循环级并行</a></h3>
<div class="paragraph">
<p>我们准确地定义一个循环何时是并行的（即可向量化的）、相关性如何阻碍循环成为并行的，以及用于消除几类相关性的技术。发现和利用循环级并行，对于利用DLP和TLP以及附录H中介绍的更激进的静态ILP方法（例如，VLIW）都至关重要。</p>
</div>
<div class="paragraph">
<p>循环级并行通常在源代码级别或接近源代码级别进行研究，而对ILP的大多数分析是在编译器生成指令之后进行的。循环级分析需要确定循环的操作数在这个循环的各次迭代之间存在哪种相关性。就目前来说，我们将仅考虑数据相关；在某一时刻写入操作数，并在稍后的时刻读取时，会出现这种相关性。</p>
</div>
<div class="paragraph">
<p>循环级并行的分析主要是判断后续迭代中的数据访问是否依赖于在先前迭代中生成的数据值；这种相关称为跨迭代相关(loop-carried dependence)。为了了解一个循环是并行的，我们首先看看源代码：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">for (i = 999; i &gt;= 0; i=i-1)
	x[i] = x[i] + s;</code></pre>
</div>
</div>
<div class="paragraph">
<p>在这个循环中，对x[i]的两次使用是相关的，但这是同一个迭代内的相关，不是跨迭代相关。在不同迭代中对i的连续使用之间存在跨迭代相关，但这种相关涉及一个容易识别和消除的归纳变量。</p>
</div>
<div class="paragraph">
<p>因为要寻找循环之间的并行，需要识别诸如循环、数组引用和归纳变量计算之类的结构，所以与机器码级别相比，编译器在源代码级别或相近源代码级别进行这一分析要更轻松一些。</p>
</div>
<div class="paragraph">
<p>我们的分析需要首先找出所有跨迭代相关。这一相关信息是不确切的，也就是说，它告诉我们此相关可能存在。考虑以下示例：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">for (i = 0; i &lt; 100; i=i+1) {
	A[i] = B[i] + C[i];
	D[i] = A[i] + E[i];
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个例子中对A的第二次引用不需要转换为载入指令，因为我们知道这个值是由上一个语句计算并存储的。因此，对A的第二个引用可能就是引用计算A的寄存器。为了执行这一优化，需要知道这两个引用总是指向同一存储器地址，而且不存在对相同位置的干扰访问。通常，数据相关分析告诉我们只有一个引用可能依赖于另一个引用；要确定两个引用一定指向同一地址.需要进行更复杂的分析。在上面的例子中，进行这一简单分析就足够了，因为这两个引用都处于同一基本块中。</p>
</div>
<div class="paragraph">
<p>跨迭代相关经常是递推(recurrence）形式。当一个变量基于它在先前迭代中的取值进行定义时，就会发生递推；这个先前迭代往往就是前面的迭代，如以下代码段所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">for (i = 1; i &lt; 100; i=i+1)
	Y[i] = Y[i-1] + Y[i];</code></pre>
</div>
</div>
<div class="paragraph">
<p>检测递推非常重要，原因有二：一些体系结构（特别是向量计算机）对执行递推提供了特殊支持；而对于IP而言，递推形式的跨迭代相关有可能并不会成为开发并行性的阻碍。</p>
</div>
<div class="sect3">
<h4 id="_查找相关"><a class="link" href="#_查找相关">6.3.1. 查找相关</a></h4>
<div class="paragraph">
<p>显然，查找程序中的相关对于确定哪些循环可能包含并行以及消除名称相关都很重要。C或C+\+等语言中存在数组和指针，Fortran中存在按引用传递的参数，这些语法都增加了相关分析的复杂度。由于标量变量引用明确指向名称，所以用别名对它们进行分析是比较轻松的，因为指针和引用参数会增加分析过程的复杂性和不确定性。</p>
</div>
<div class="paragraph">
<p>编译器通常是如何检测相关的呢？几乎所有相关分析算法都假定数组索引是仿射的（afine)。用最简单的话说，如果一维数组索引可以写为\(a \times i + b\)的形式，其中a和b是常数，i是循环索引变量，那么它就是仿射的。如果多维数组每一维的索引都是仿射的，就称这个多维数组的索引是仿射的。稀疏数组访问（其典型形式为x[y[i]]）是非仿射访问的主要示例之一。</p>
</div>
<div class="paragraph">
<p>要判断一个循环中对同一数组的两次引用之间是否存在相关，等价于判断两个仿射函数能否针对不同索引取同一个值（这些索引没有超出循环范围）。例如，假定我们以索引值\(a \times i + b\)存储了一个数组元素，并以索引值\(c \times i + d\)从同一数组中载入，其中i是FOR循环索引变量，其变化范围是m~n。如果满足以下两个条件，则存在相关性。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>有两个迭代索引j和k.它们都在循环范围内，即m≤j≤n.m≤k≤n。</p>
</li>
<li>
<p>此循环以索引\(a \times j + b\)存储一个数组元素，然后以\(c \times k + d\)提取同一数组元素，即\(a \times j + b = c \times k + d\)。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>一般来说，我们在编译时不能判断是否存在相关。例如，a、b、c和d的值可能是未知的（它们可能是其他数组中的值），从而不可能判断是否存在相关。在其他情况下，在编译时进行相关测试的开销可能非常高，但的确可以确定是否存在相关：例如，可能要依靠多重嵌套循环的迭代索引来进行访问。但是，许多条目主要包含一些简单的索引，其中a、b、c和d都是常数。对于这些情况，有可能为相关性设计合理的编译时测试。</p>
</div>
<div class="paragraph">
<p>举个例子，最大公约数（GCD）测试非常简单，但足以判定不存在相关的情况。它基于以下事实：如果存在跨迭代相关，那么GCD(c,a)必须能够整除(d-b)。（回想一下，有两个整数x、y，在计算y除法运算时，如果能够找到一个整数商，使运算结果没有余数，则说x能够整除y。）</p>
</div>
<div class="paragraph">
<p>GCD不能整除足以确保不存在相关。但在某些情况下，GCD测试认为可以整除，跨选代相关也不存在。例如，一种情况可能是因为GCD测试没有考虑循环边界。</p>
</div>
<div class="paragraph">
<p>一般来说，确定是否实际存在相关是一个NP完全（NP-complete）问题。然而，在实践中。许多常见情况可以以较低的成本进行精确分析。最近，使用不同层次精确测试的方法的通用性和成本都有所提高，并被证明是准确和高效的。（如果一个测试能够精确地判断是否存在相关，就说这一测试是确切的。尽管一般情况是“NP完全”的，但对于受限情况，是存在确切测试的，其成本也要低得多。）</p>
</div>
<div class="paragraph">
<p>除了检测是否存在相关以外，编译器还希望划分相关的类型。编译器可以通过这种分类来识别名称相关，并在编译时通过重命名和复制操作消除这些相关。</p>
</div>
<div class="paragraph">
<p>相关分析是检测循环级别并行的一种基本工具。针对向量计算机、SIMD计算机或多处理器进行有效的程序编译，都依赖于这种分析。相关分析的主要缺点是它仅适用于非常有限的一些情况，也就是用于分析单个循环嵌套中引用之间的相关以及使用仿射索引功能的情景。因此，在许多情况下，面向数组的相关分析不能告诉我们希望知道的内容；例如，分析用指针而不是数据索引完成的访问可能要困难得多。(这就是对于许多为并行计算机设计的科学应用程序，Fortran仍然优于C和C+\+的一个理由。）同理，分析过程调用之间的引用也极为困难。因此，尽管依然需要分析那些以顺序语言编写的代码，但我们也需要编写显式并行循环的方法，比如 OpenMP和CUDA。</p>
</div>
</div>
<div class="sect3">
<h4 id="_清除相关计算"><a class="link" href="#_清除相关计算">6.3.2. 清除相关计算</a></h4>
<div class="paragraph">
<p>前而曾经提到，相关计算的最重要形式之一是递推。点积是递推的一个完美示例：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">for (i = 9999; i &gt;= 0; i=i-1)
	sum = sum + x[i] * y[i];</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个循环不是并行的，因为它的变量求和存在跨迭代相关。但是，我们可以将它转换为一组循环，其中一个是完全并行的，而另一个是部分并行的。第一个循环将执行这个循环中完全并行的部分。它看起来如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">for (i = 9999; i &gt;= 0; i=i-1)
	sum[i] = x[i] + y[i];</code></pre>
</div>
</div>
<div class="paragraph">
<p>注意，这一求和已经从标量扩展到向量值（这种转换被称为标量扩展，scalar expansion)，这一转换使新的循环成为完全并行的循环。但是，在完成转换时，需要进行归约步骤，对向量的元素求和，类似如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">for (i = 9999; i &gt;= 0; i=i-1)
	finalsum = finalsum + sum[i];</code></pre>
</div>
</div>
<div class="paragraph">
<p>尽管这个循环不是并行的，但它有一种非常特殊的结构，称为归约（reduction）。归约在线性代数中很常见，它还是仓库级计算机中主要并行原型MapReduce的关健部分。一般来说，任何函数都可用作归约运算符，常见情况中包含诸如max和min之类的运算符。</p>
</div>
<div class="paragraph">
<p>在向量和SIMD体系结构中，归约有时是由特殊硬件处理的，这使得归约步骤的执行速度比在标量模式下快得多。具体做法是实现一种技术，它类似于可在多处理器环境中实现的技术。下例中的代码变换可以使用任意数量的处理器，但为简便起见，我们假定有l0个处理器。在归约求和的第一步中，每个处理器执行以下运算（p是处理器号，范围为0-9）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">for (i = 9999; i &gt;= 0; i=i-1)
	finalsum[p] = finalsum[p] + sum[i+1000*p];</code></pre>
</div>
</div>
<div class="paragraph">
<p>这个循环在10个处理器中的每一个上对1000个元素求和，它是完全并行的。然后用简单的标量循环来完成最后l0个总和的计算。向量处理器和SIMD处理器中使用了类似的方法。</p>
</div>
<div class="paragraph">
<p>以上变换依赖于加法的结合性质，注意到这一点很重要。尽管拥有无限范围与精度的算术运算具有结合性质，但计算机运算却不具备结合性：对于整数运算来说，是因为其范围有限；对于浮点运算来说，既有范围原因，又有精度原因。因此，使用这些代码变换技术有时会导致一些错误行为，尽管这种现象很少发生。为此，大多数编译器要求显式启用那些依赖结合性的优化。</p>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_线程级并行"><a class="link" href="#_线程级并行">7. 线程级并行</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>在多个处理器上同时执行多个线程，提高程序性能及吞吐量。</p>
</div>
<div class="paragraph">
<p>处理器之间共享数据有两种方法：</p>
</div>
<div class="paragraph">
<p>1.所有处理器共享一块内存（集中式共享存储器/对称共享存储器）。</p>
</div>
<div class="paragraph">
<p>2.每个处理器有自己的内存但其他处理器可以访问（分布式共享存储器）</p>
</div>
<div class="sect2">
<h3 id="_多处理器体系结构"><a class="link" href="#_多处理器体系结构">7.1. 多处理器体系结构</a></h3>
<div class="paragraph">
<p>为了利用拥有n个处理器的MIMD多处理器，通常必须拥有至少n个要执行的线程或进程。因为现在大多数多核芯片中存在多线程，所以这个数字要高出2-4倍。单个进程中的独立线程通常由程序员指定或由操作系统（根据多个独立请求）创建。在另一种极端情况下，一个线程可能由一个循环的数十次迭代组成，这些迭代是由利用该循环中数据并行性的并行编译器生成的。分配给一个线程的计算量称为粒度大小（grain size）。尽管这一数值在考虑如何高效利用线程级并行时很重要，但线程级并行与指令级并行的重要定性区别在于：线程级并行是由软件系统或程序员在较高层级确定的，这些线程由数百条乃至数百万条可以并行执行的指令组成。</p>
</div>
<div class="paragraph">
<p>线程还能发挥数据级并行的优势，但是开销通常高于使用SIMD处理器或GPU的情况。这意味着数据的粒度必须足够大才能高效地利用并行。例如，尽管向量处理器或GPU也许能够高效地实现短向量运算的并行化，但当并行分散在许多线程中时，粒度大小可能会非常小。以至于这种开销使得在MMD中利用并行性的成本高得令人却步。</p>
</div>
<div class="paragraph">
<p>根据所包含的处理器数量，可以将现有共享存储器的多处理器分为两类，而处理器的数量又决定了存储器的组织方式和互连策略。我们是按照存储器的组织方式来称呼多处理器的，因为处理器的数量可能会随时间变化。</p>
</div>
<div class="paragraph">
<p>第一类称为对称（共享存储器）多处理器（symmetric(shared-memory)multiprocessor.SMP），或集中式共享存储器多处理器（centralized shared-memory multiprocessor），其待点是核数量较少，通常不超过32个。由于此类多处理器中的处理器数目非常少，所以处理器可以共享一个集中式存储器并且平等地访问它，这就是对称一词的由来。在多核芯片中，存储器通常在多核之间以集中式的方式共享；大多数（并非全部）多核是SMP。[注意，有些文献使用SMP表示共享存储器处理器（shared memory processor），但这种用法是错误的。]</p>
</div>
<div class="paragraph">
<p>一些多核对最外层的缓存有不一致的访问，这种结构称为NUCA(nonuniform cache access).因此不是真正的SMP，即使它们只有一个主存储器。IBMPower8设计了一套分布式的L3缓存不同的地址有不同的访问延迟。</p>
</div>
<div class="paragraph">
<p>在由多个多核芯片组成的多处理器中，每个多核芯片通常都有独立的存储器。因此，存储器是分布式的，而不是集中式的。许多使用分布式存储器的设计可以快速访问局部存储器，而对远程存储器的访问要慢得多。与对局部存储器和远程存储器的访问时间的差异相比，它们对各种远程存储器的访问时间则相差无几。在这样的设计中，程序员和软件系统需要知道访问的是局部存储器还是远程存储器，但是可以忽略远程存储器中的访问分布。由于随着处理器数量的增加，SMP方法的吸引力越来越小，所以大多数的众核处理器使用某种形式的分布式存储器。</p>
</div>
<div class="paragraph">
<p>SMP体系结构有时也称为一致存储器访问（uniform memory access.UMA）多处理器，这一名称源自以下事实：所有处理器访问存储器的延迟都是一致的，即使当存储器被分为多个组时也是如此。在另一种设计方法中，多处理器采用物理分布式存储器，称为分布式共享存储器(distributedshared memory，DSM)。为了支持更多的处理器，存储器必须分散在处理器之间，而不应当是集中式的；否则，存储器系统就无法在不大幅延长访问延迟的情况下为大量处理器提供高带宽支持。</p>
</div>
<div class="paragraph">
<p>随着处理器性能的快速提高以及处理器对访存带宽需求的增加，偏好选择分布式存储器的多处理器继续缩小。多核处理器的引入意味着连双芯片多处理器（可能有16~64个处理器核心）也会采用分布式存储器。处理器数目的增加也提升了对高带宽互连的需求。有向网络（即交换机）和间接网络（通常是多维网络）均被用于实现互连。</p>
</div>
<div class="paragraph">
<p>将存储器分散在节点上，既增加了带宽，也降低了到局部存储器的延迟。DSM多处理器也称为NUMA（非一致存储器访问），因为访问时间取决于数据在存储器中的位置。DSM的主要缺点是让在处理器之间传送数据的过程变复杂了，而且需要在软件开发中付出更多努力才能利用分布式存储器提升的存储带宽。因为大多数基于多核的多处理器（具有多个处理器芯片）使用分布式存储器，所以我们将从这个角度来解释分布式存储器多处理器的工作方式。</p>
</div>
<div class="paragraph">
<p>在SMP和DSM这两种体系结构中，线程之间的通信是通过共享地址空间完成的，也就是说，任何拥有正确访问权限的处理器都可以对任意存储地址进行访问。与SMP和DSM相关的共享存储器一词指的是地址空间(address space）是共享的。</p>
</div>
<div class="paragraph">
<p>相比之下，集群和仓库级计算机看起来像由网络连接的独立计算机，如果没有在两个处理器上同时运行的软件协议的帮助，那么一个处理器就无法访问另一个处理器的存储器。此类设计使用消息传送协议在处理器之间传送数据。</p>
</div>
<div class="sect3">
<h4 id="_并行处理的挑战"><a class="link" href="#_并行处理的挑战">7.1.1. 并行处理的挑战</a></h4>
<div class="paragraph">
<p>多处理器的应用范围很广：从运行基本上互无通信的独立任务，到运行一些必须在线程之间通信才能完成任务的并行程序。有两个重要的障碍使并行处理变得极富挑战性，这两个障碍都可以用Amdahl定律来解释。要克服这些障碍，通常需要一种全面的方法来选择算法及其实现、底层的编程语言和系统、操作系统及其支持功能，以及体系结构和硬件实现。尽管在许多情况下，其中之一是关键瓶颈，但当处理器数量接近100或更多时，通常需要注意软件和硬件的所有方面。</p>
</div>
<div class="paragraph">
<p>第一个障碍与程序中有限的并行性相关，第二个障碍源于较高的通信成本。由于并行性有限，所以很难在任意并行处理器中实现良好的加速比。</p>
</div>
<div class="paragraph">
<p>并行处理的第二个重要挑战涉及并行处理器进行远程访问所带来的高延迟。在现有的共享存储器多处理器中，不同核之间的数据通信可能耗费35-50个时钟周期，不同芯片上的核之间的数据通信可能耗费100到500甚至更多个时钟周期（对于大规模多处理器而言)，具体取决于通信机制、互连网络的类型以及多处理器的规模。高通信延迟显然会造成巨大的影响。</p>
</div>
<div class="paragraph">
<p>并行度不足和远程通信延迟太高是在使用多处理器时最大的两个性能难题。应用程序并行度不足的问题必须通过在软件中采用并行性能更高的新算法来解决，还要在软件系统中尽可能多地使用完整的处理器。远程延迟过高的影响可以由体系结构和程序员来降低。例如。我们可以利用硬件机制（比如缓存共享数据）或软件机制（比如调整数据的结构，使应用程序尽量访问局部存储器）来降低远程访问的频率。我们可以利用多线程或预取（来优化这些延迟。本章主要关注用来降低远程通信延迟所导致的影响的技术。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_集中式对称共享存储器体系结构"><a class="link" href="#_集中式对称共享存储器体系结构">7.2. 集中式/对称共享存储器体系结构</a></h3>
<div class="paragraph">
<p>使用大型多级缓存可以大大降低处理器对存储带宽的需求，这个重要发现促进了集中式存储器多处理器的发展。最初，这些单核的处理器占据了整个主板，而存储器位于共享总线上随着近期更高性能处理器的出现、存储器需求超出了一般总线的能力，最近的微处理器直接将存储器连接到单个芯片中、这个芯片有时称为后端总线（backside）或内存总线（memory bus），以区别于连接至I/O的总线。在访问一个芯片的局部存储器时，无论是为了I/O操作，还是为了从另一个芯片进行访问，都需要通过“拥有”该存储器的芯片。因此，对存储器的访问是非对称的：对局部存储器的访问更快一些，而对远程存储器的访问要慢一些。在多核结构中，存储器由一个芯片上的所有核共享，但是从一个多核的存储器到另一个多核的存储器的访问仍然是非对称的。</p>
</div>
<div class="paragraph">
<p>采用对称共享存储器的计算机通常支持对共享数据与私有数据的缓存。私有数据（privatc非对称的。data）供单个处理器使用，而共享数据（shared data）则由多个处理器使用，基本上是通过读写共享数据来实现处理器之间的通信。在私有数据项被缓存时，它的位置被移往缓存，缩短了平均访问时间并降低了所需要的存储带宽。由于没有其他处理器使用数据，所以程序行为与单处理器中的行为相同。在级存共享数据时，可能会在多个缓存中复制共享值。除了降低访问延迟和所需要的存储带宽之外，这一复制过程还可以减少争用—一当多个处理器同时读取共享数据项时可能会出现这种争用。不过，共享数据的缓存也引入了一个新问题：缓存一致性。</p>
</div>
<div class="sect3">
<h4 id="_多处理器缓存一致性概念"><a class="link" href="#_多处理器缓存一致性概念">7.2.1. 多处理器缓存一致性概念</a></h4>
<div class="paragraph">
<p>缓存共享数据会引入一个新的问题。因为两个不同的处理器是通过各自的缓存来保留存储器视图的，所以针对同一存储地址，它们可能会看到不同的值。这一难题一般称为缓存一致性问题。注意，之所以存在一致性问题，是因为我们既拥有全局状态（主要由主存储器决定），又拥有局部状态（由各个缓存确定，它们是每个处理器核私有的）。因此，在一个可能会共享某一级别缓存（比如L3）的多核系统中，尽管某些级别的缓存是私有的（比如L1和L2），但一致性问题仍然存在，必须解决。</p>
</div>
<div class="paragraph">
<p>通俗地说，如果每次读取某一数据项都会返回该数据项的最新写入值，就说这个存储器系统是一致的。这一定义尽管看似正确，但有些含混且过于简单，实际情况要复杂得多。这个简单定义包含了存储器系统行为的两个方面，这两个方面对于编写正确的共享存储器程序都至关重要。第一个方面称为一致性(coherence)，它定义了读操作能返回什么值。第二个方面称为连贯性（consistency），它决定了一个写入值什么时候被读操作返回。</p>
</div>
<div class="paragraph">
<p>首先来看一致性。如果存储器系统满足以下条件，则说它是一致的。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>处理器P对位置X的读操作跟在P对X的写操作之后，并且在P的写操作和读操作之同没有其他处理器对X执行写操作，此读操作总是返回P写入的值。</p>
</li>
<li>
<p>如果一个处理器对位置X的读操作紧跟在另一个处理器对X的写操作之后，读写操作的间隔时间足够长，而且在两次访问之间没有其他处理器对X执行写操作，那么该读操作将返回写人值。</p>
</li>
<li>
<p>对同一位置执行的写操作是被串行化（serialized）的，也就是说，在所有处理器看来.任意两个处理器对相同位置执行的两次写操作顺序相同。例如，如果数值1和数值2被先后写到一个位置，则处理器永远不可能先从该位置读取到数值2，之后再读取到数值1。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>第一个特性只保持了程序顺序——即使在单处理器中，我们也希望具备这一特性。第二个特性定义了一致性存储器视图的含义：如果处理器持续读取到一个旧数据值，我们就可以明确地说该存储器是不一致的。</p>
</div>
<div class="paragraph">
<p>对写操作串行化的需求更加微妙，但同样重要。假定我们没有实现写操作的串行化，而且处理器P先写入位置X，然后P2写入位置X。对写操作进行串行化可以确保每个处理器都能看到P2在某一时刻完成的写操作。如果没有对写操作进行申行化，那么某些处理器可能会先看到P2的写入结果，后看到P1的写入结果，并将P1写入的值无限期保存下去。避免此类难题的最简单方法是确保对同一位置执行的所有写操作在所有处理器看来都是同一顺序，这一特性称为写操作串行化(write serialization)。</p>
</div>
<div class="paragraph">
<p>尽管上述三条特性足以确保一致性，但什么时候才能看到写入值也是一个很重要的问题。我们不能要求在某个处理器向X中写入一个值之后，另一个读取X的处理器能够马上看到这个写入值。比如，如果一个处理器对X的写操作仅比另一个处理器对X的读操作早一点儿，那就不可能确保该读操作会返回这个写入值，因为写入值当时甚至可能还没有离开处理器。写人值到底必须在多久之后被读操作读到？这一问题由存储器一致性模型（memory consistency model）决定,后面将进行讨论。</p>
</div>
<div class="paragraph">
<p>一致性和连贯性是互补的：一致性确定了向同一存储地址的读写行为，而连贯性则确定了对于其他存储地址的访问的读写行为。现在，做出以下两条假定。第一，在所有处理器都看到写入结果之后，写操作才算完成（并允许进行下一次写人）。第二。对于任何其他存储器访问，处理器不会改变任何写入顺序。这两个条件是指：如果一个处理器先写入位置A，然后写入位置B，那么任何能够看到B中新值的处理器也必须能够看到A中的新值。这些限制条件使处理器能够调整读操作的顺序，但强制处理器必须按照程序顺序来完成写操作。</p>
</div>
</div>
<div class="sect3">
<h4 id="_一致性的基本实现方案"><a class="link" href="#_一致性的基本实现方案">7.2.2. 一致性的基本实现方案</a></h4>
<div class="paragraph">
<p>多处理器与I/O的一致性问题尽管在起源上类似，但具有不同的特性，因此解决方案也有所不同。在I/O情景中存在多个数据副本非常罕见（应当尽量避免），而在多个处理器上运行的程序则通常在几个缓存中拥有同一数据的多个副本。在一致性多处理器中，缓存提供了对共享数据项的迁移（migration）与复制（replication）功能。</p>
</div>
<div class="paragraph">
<p>一致性级存提供的迁移功能可以将数据项移动到本地缓存中，并以透明方式加以使用。这种迁移既降低了访问远程共享数据项的延迟，也降低了对共享存储器的带宽要求。</p>
</div>
<div class="paragraph">
<p>因为缓存在本地级存中持有数据项的一个副本，所以一致性缓存还为那些被同时读取的北享数据提供了复制功能。复制功能既降低了访问延迟，又减少了对被读共享数据项的争用。支持迁移与复制功能对于共享数据的访问性能非常重要。因此，多处理器没有试图通过软件来避免这一问题的发生，而是采用了一种硬件解决方案，通过引人协议来保持缓存的一致性。</p>
</div>
<div class="paragraph">
<p>为多个处理器保持缓存一致性的协议称为缓存一致性协议(cache coherence protocol）。实现缓存一致性协议的关键在于跟踪数据块的所有共享状态。任何缓存块的状态都是使用与该块相关联的状态位来保持的，类似于单处理器缓存中保留的有效位和脏位。目前使用的协议有两类，分别采用不同的技术来跟踪共享状态。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>目录协议——特定物理内存块的共享状态保存在一个位置中，称为目录。共有两种目录式缓存一致性，它们的差异很大。在SMP中，可以使用一个集中目录，与存储器或其他某个串行化点相关联，比如多核的最外层缓存。在DSM中，使用单个目录没有意义，因为这种方法会生成单个争用点，而且考虑到拥有8个或更多核的存储器需求，很难扩展到多个多核芯片。</p>
</li>
<li>
<p>监听协议——如果一个缓存拥有某一物理内存块中的数据副本，它就可以跟踪该块的共享状态，而不必将共享状态保存在同一个目录中。在SMP中，缓存通常可以通过某种广播介质访问（比如将各个核的缓存连接至共享缓存或存储器的总线），所有缓存控制器都监听（snoop）这一介质，以确定自己是否拥有总线或交换访问上所请求块的副本。监听协议也可用作多芯片多处理器的一致性协议，有些设计在目录协议的基础上，在芯片间同步使用监听实现！</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>监听协议在使用微处理器（单核）的多处理器和通过总线连接到单个共享存储器的缓存中变得流行起来。总线提供了一种非常方便的广播介质来实现监听协议。在多核体系结构中，所有多核都共享芯片上的某一级缓存。因此，一些设计转而使用目录协议，因为其开销较低。</p>
</div>
</div>
<div class="sect3">
<h4 id="_监听一致性协议"><a class="link" href="#_监听一致性协议">7.2.3. 监听一致性协议</a></h4>
<div class="paragraph">
<p>有两种方法可以满足一致性需求。一种方法是确保处理器在写入某一数据项之前，获取对该数据项的独占访问。这种类型的协议称为写无效协议（wnite invalid protocol)），因为它在执行写操作时会使其他副本无效。这是目前最常用的协议。独占式访问确保在写入某数据项时，不存在该数据项的任何其他可读或可写副本；这一数据项的所有其他级存副本都作废。</p>
</div>
<div class="paragraph">
<p>为了了解这一协议如何确保一致性，我们考虑在处理器执行写操作之后由另一个处理器进行读取：由于写操作需要独占访问。所以进行读取的处理器所保留的所有副本都必须无效（这就是这一协议名称的来历）。缓存无效的处理器在进行读操作时会发生缺失，必须提取此数据的新副本。对于写操作，我们要求执行写操作的处理器拥有独占访问，禁止任何其他处理器同时写入。如果两个处理器尝试同时写入同一数据，其中一个将会在竞争中获胜（稍后会介绍如何确定哪个处理器获胜），从而导致另一处理器的副本无效。另一个处理器要想完成自己的写操作，必须获得此数据的新副本，其中必须包含更新后的取值。因此，这一协议实施了写入串行化。</p>
</div>
<div class="paragraph">
<p>无效协议的一种替代方法是在写入一个数据项时更新该数据项的所有级存副本。这种类型的协议称为写入更新（writeupdate）或写入广播（write broadcast）协议。由于写入更新协议必须将所有写操作都广播到共享缓存行上，所以它要占用相当多的带宽。为此，最近的多处理器几乎都已经选择了实现写无效协议。</p>
</div>
<div class="paragraph">
<p><strong>基本实现技术</strong></p>
</div>
<div class="paragraph">
<p>在多核中实现无效协议的关键在于使用总线或其他广播介质来执行无效操作。在较早的多芯片多处理器中，用于实现一致性的总线是共享存储器访问总线。在单芯片多核处理器中，总线可能是私有缓存（lntel Corei7中的L1和L2）和共享外部缓存(i7中的L3）之间的连接为了执行一项无效操作，处理器只获得总线访问，并在总线上广播要使其无效的地址。所有处理器持续监听该总线，观测这些地址。处理器检查总线上的地址是否在自己的缓存中，如果在，则使缓存中的相应数据无效。</p>
</div>
<div class="paragraph">
<p>在写入一个共享块时，执行写操作的处理器必须获取总线访问权限来广播其无效。如果两个处理器尝试同时写入共享块，当它们争用总线时，其广播无效操作的尝试将被串行化。第一个获得总线访问权限的处理器会使它正在写入的块的所有其他副本无效。如果这些处理器尝试写人同一个块，则由总线强制实现的串行化也将串行化它们的写入。这种机制有一层隐含的意思：在获得总线访问权限之前，无法实际完成共享数据项的写操作。所有一致性机制都需要某种方法来串行化对同一缓存块的访问，具体方式可以是串行化对通信介质的访问，也可以是对另一共享结构访问的串行化。</p>
</div>
<div class="paragraph">
<p>除了使被写人的缓存块的副本无效之外，还需要在发生缓存缺失时定位数据项。在写直达缓存中，可以很轻松地找到一个数据项的最近值，因为所有写入数据都会写回存储器，所以总是可以从存储器中找到数据项的最新值。（对缓冲区的写操作可能会增加一些复杂度，必须将其作为额外的缓存条目进行有效处理。）</p>
</div>
<div class="paragraph">
<p>对于写回缓存，查找最新数据值要困难一些，因为数据项的最新值可能放在私有缓存中，而不是共享缓存或存储器中。所幸，写回缓存可以为缓存缺失和写操作使用相同的监听机制：每个处理器都监听放在共享总线上的所有地址。如果处理器发现自己拥有被请求缓存块的脏副本，它会提供该缓存块以回应读取请求，并中止存储器（或L3）访问。由于必须从另一个处理器的私有缓存（L1或L2）提取缓存块，所以增加了复杂性，这一提取过程花费的时间通常长于从L3进行提取的时间。由于写回缓存对存储带宽的需求较低，所以他们可以支持更多、更快速的处理器。因此，所有多核处理器都在缓存的最外层级别使用写回缓存。</p>
</div>
<div class="paragraph">
<p>普通的缓存标记可用于实现监听过程，每个块的有效位使无效操作的实现非常简单。读缺失（无论是由无效操作导致，还是由其他事件导致）的处理也非常简单，因为它们就是依赖于监听功能的。对于写操作，我们需要知道是否缓存了写入块的其他副本，如果不存在其他缓存副本，那么在写回级存中就不需要将写操作放在总线上。如果不用发送写操作，就既可以缩短写入时间，还可以降低所需带宽。</p>
</div>
<div class="paragraph">
<p>若要跟踪缓存块是否被共享，可以为每个缓存块添加一个状态位，就像有效位和脏位（dirty bit）一样。通过添加一个位来指示该数据块是否被共享，可以判断写操作是否必须生成无效操作。在对处于共享状态的块进行写入时，该缓存在总线上生成无效操作，将这个块标记为独占（exclusive)。这个核不会再发送有关该块的其他无效操作。如果一个缓存块只有唯一刷本、则拥有该唯一副本的核通常称为该缓存块的拥有者。</p>
</div>
<div class="paragraph">
<p>在发送无效操作时，拥有者缓存块的状态由共享改为非共享（或改为独占）。如果另一个处理器稍后请求这一缓存块，必须再次将状态改为共享。由于监听缓存也能看到所有缺失情况，所以它知道另一个处理器什么时候请求了独占缓存块，以及何时应当将状态改为共享。</p>
</div>
<div class="paragraph">
<p>每个总线事务都必须检查缓存地址标记，这些标记可能会干扰处理器缓存访问。减少这种干扰的一种方法就是复制这些标记，并将监听访问引导至这些复制的标记。另一种方法是在共享的L3缓存使用一个目录，这个目录指示给定块是否被共享，哪些核心可能拥有它的副本。利用目录信息，可以将无效操作仅发送给拥有该缓存块副本的缓存。这就要求L3必须总是拥有L1或L2中所有数据项的副本，这一特性称为包含。</p>
</div>
</div>
<div class="sect3">
<h4 id="_基本一致性协议的拓展"><a class="link" href="#_基本一致性协议的拓展">7.2.4. 基本一致性协议的拓展</a></h4>
<div class="paragraph">
<p>前面介绍的一致性协议是一种简单的三状态协议，经常用这些状态的首字母来称呼——MSI(modified,shared,invalid，即已修改、共享、无效）协议。这些扩展是通过添加更多的状态和转换来创建的，这些添加内容对某些行为进行优化，可能会提升性能。下面介绍两种最常见的扩展。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>MESI向基本的MSI协议中添加了“独占”（exclusive）状态，用于表示缓存块仅驻存在一个缓存中，而且是干净的。如果一个块处于独占状态，就可以对其进行写人而不会产生任何无效操作，这优化了一个块先由单个缓存读取再由同一缓存写入的情况。当然，在处于独占状态的块产生读缺失时，必须将这个块改为共享状态，以保持一致性。因为所有后续访问都会被监听，所以有可能保持这一状态的准确性。具体来说，如果另一个处理器发射一个读缺失，则状态会由独占改为共享。添加这一状态的好处是：在由同一个核对处于独占状态的块进行后续写入时，不需要访问总线，也不会生成无效操作，因为处理器知道这个块在这个本地缓存中是独占的；处理器只是将状态改为已修改。添加这一状态非常简单，只需要使用将一致状态编码为独占状态的位，并使用脏位表示这个块已被修改。Intel i7使用了MESI协议的一种变体，称为MESIF，它添加了一个状态（forward），用于表示应当由哪个共享处理器对请求做出响应。这种协议设计用来提高分布式存储器组织结构的性能。</p>
</li>
<li>
<p>MOESI向MESI协议中添加了“拥有”（owned）状态，用于表示相关块由该缓存拥有并且在存储器中已经过时。在MSI和MESI协议中，如果尝试共享处于“已修改”状态的块，会将其状态改为“共享”（在原共享级存和新共享缓存中都会如此），并且必须将这个块写回存储器中。而在MOESI协议中，可以在原缓存中将这个块的状态由“已修改”改为“拥有”，不再将其写到存储器中。（新共享这个块的）其他缓存使这个块保持共享状态；只有原缓存保持“拥有”状态，表示主存储器副本已经过期，指定缓存成为其拥有者。这个块的拥有者必须在发生缺失时提供该块，因为存储器中没有最新内容，如果替换了这个块，则必须将其写回存储器中。AMD Opteron 处理器系列使用了MOESI协议。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_对称共享存储器多处理器与监听协议的局限性"><a class="link" href="#_对称共享存储器多处理器与监听协议的局限性">7.2.5. 对称共享存储器多处理器与监听协议的局限性</a></h4>
<div class="paragraph">
<p>随着多处理器中处理器数量的增加，或每个处理器的存储器需求的增长，系统中的任何集中式资源都可能变成瓶颈。即使只有几个核，单个共享总线也会成为多核系统的瓶颈。因此，多核设计已经转向高带宽、独立内存的互连方案，以允许增加更多的核。多数多核芯片使用了三种不同的方法。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>IBMPower8在一个多核中最多有l2个处理器，它使用8个并行总线连接分布式L3缓存和最多8个独立的存储器通道。</p>
</li>
<li>
<p>Xeon E7使用3个环来连接最多32个处理器、一个分布式L3缓存以及2个或4个存储器通道（取决于配置）。</p>
</li>
<li>
<p>Fajitsu SPARC64 X+使用一个交叉开关将共享的L2缓存连接到最多16个核和多个存储器通道。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>SPARC64 X+是一个具有一致访问时间的对称组织结构。Power8对L3缓存和存储器的访问时间不一致。尽管在一个Power8多核内的存储器地址之间的非争用访问时间差异并不大，但是对于存储器的争用，即使在一个芯片内，访问时间差也会变得非常大。XeonE7可以像访问时间一致一样进行操作；在实践中，软件系统通常对存储器进行组织，使存储器通道与核的一个子集相关联。</p>
</div>
<div class="paragraph">
<p>监听缓存的带宽也会成为一个问题，因为每个缓存必须检查所有缺失，而增加额外的互连带宽只会将问题推给缓存。</p>
</div>
<div class="paragraph">
<p>增加监听带宽的方法有如下几种：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>如前所述，可以复制标记。这使有效的缓存级监听带宽翻了一番。如果假设一半的一致性请求没有命中一个监听请求，并且监听请求的成本只有10个周期（而不是15个周期），第么我们就可以将一个CMR的平均成本降低到12.5个周期。这使得一致性缺失率可以为0.88，或者支持一个额外的处理器（7而不是6）。</p>
</li>
<li>
<p>如果共享多核（通常是L3）上的最外层缓存，则可以分配该缓存，使每个处理器都有一部分存储器，并处理对该部分地址空间的监听。IBM 12核Power8就使用了这种方法，它在采用NUCA设计的同时，按照过处理器的数量有效地扩展了L3缓存上的监听带宽。如果在L3缓存中有一个监听命中，那么我们仍然必须广播到所有的L2缓存，而L2缓存反过来必须监听它们的内容。因为L3缓存充当监听请求的过滤器，所以L3缓存必须具有包含性。</p>
</li>
<li>
<p>我们可以将一个目录放在最外层共享缓存的级别（例如L3）上。L3缓存作为监听请求的过滤器，必须具有包含性。在L3缓存使用一个目录意味着我们不需要监听或广播到所有的L2级存，而只需要监听或广播到目录表明可能有块的副本的那些缓存。正如L3缓存可能是分布式的，相关的目录条目也可能是分布式的。这种方法用于lntel Xeon E7系列，该系列支持8-32个核心。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>下图展示了带有分布式缓存系统（如方案2或方案3中使用的系统）的多核的组织形式。如果想增加更多的多核芯片以形成更大的多处理器，就需要一个片外网络，以及一种扩展一致性机制的方法。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/7.2.5.png" alt="7.2.5">
</div>
</div>
<div class="paragraph">
<p>AMD Opteron展示了监听协议与目录协议之间的另一个折中。存储器被直连到每个多核芯片，最多可以连接4个多核芯片。这个系统为NUMA，因为局部存储器更快一些。Opteron使用点对点连接实现其一致性协议，最多向其他3个芯片进行广播。因为处理器之间的链接未被共享，所以一个处理器要想知道无效操作何时完成，唯一的方法就是显式确认。因此，一致性协议使用广播来查找可能共享的副本，这一点与监听协议类似，但它使用确认来确定操作，这一点与目录协议类似。由于在Opteron实现中，局部存储器仅比远程存储器快一点，所以一些软件把opteron多处理器看作拥有一致的存储器访问。一种解决方案是目录协议，它在发生缺失时不需要向所有缓存进行广播。一些多核设计在多核内目录（Intel Xeon E7），而另一些设计在扩展到多核之外时添加目录。分布式目录消除了对单点串行化所有访问的需要（通常是监听模式中的单点共享总线），任何删除单点串行化的模式都必须处理与分布式目录模式相同的许多挑战。</p>
</div>
</div>
<div class="sect3">
<h4 id="_实现监听缓存一致性"><a class="link" href="#_实现监听缓存一致性">7.2.6. 实现监听缓存一致性</a></h4>
<div class="paragraph">
<p>随着总线带宽需求的增加，设计人员不得不面对一项挑战：在不简化总线来串行化事件的情况下实现监听（或目录模式）。在实际实现监听一致性协议时，最复杂的部分在于：在最近的所有多处理器中，写缺失与更新缺失都不是原子操作。检测写缺失或更新缺失、与其他处理器或存储器通信、为写缺失获取最新值、确保所有无效操作可以正常进行、更新缓存，这些步骤不能在单个时钟周期内完成。</p>
</div>
<div class="paragraph">
<p>在只有一条总线的多核中，如果（在改变缓存状态之前）首先协调连向共享缓存或存储器的总线，并在完成所有操作之前保持总线不被释放，那就可以有效地使上述步骤变成原子操作。处理器怎么才能知道所有无效操作何时完成呢?在早期设计中，当收到所有必要无效操作并在处理时，会使用单根信号线发出信号。收到这一信号之后，生成缺失的处理器就可以释放总线，因为它知道在执行与下一次缺失相关的操作之前，可以完成所有读写行为。只要在执行这些步骤期间独占总线，处理器就能有效地将各个步骤变为原子操作。</p>
</div>
<div class="paragraph">
<p>在没有单一中央总线的系统中，我们必须寻找其他某种方法，将缺失过程中的步骤变为原子操作。具体来说，必须确保两个处理器尝试同时写人同一数据块的操作（这种情景称为竞争）保持严格排序：首先处理一个写操作，然后再开始执行下一个。这两次写操作中的哪一个操作会赢得竞争并不重要，因为只会有一个获胜者，而它的一致性操作将被首先完成。在使用多条总线的多核中，如果每个存储器块只与一条总线关联，则可以消除竞争，从而确保访问同一个块的两次尝试必须由该公共总线序列化。这个特性，以及重启竞争失败者缺失处理的能力，是在无总线情况下实现监听缓存一致性的关键。</p>
</div>
<div class="paragraph">
<p>还可以将监听与目录结合在一起，有些设计在多核处理器内部使用监听、在多个芯片之间使用目录，或者在一个级存级别使用目录、在另一个缓存级别使用监听。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_集中式对称共享存储器多处理器的性能"><a class="link" href="#_集中式对称共享存储器多处理器的性能">7.3. 集中式/对称共享存储器多处理器的性能</a></h3>
<div class="paragraph">
<p>多个处理器共享同一块内存，处理器之间可以很方便的共享资源，并且处理器之间通信比分布式要快。但是处理器访问内存都要占用总线，当处理器数量较多时会因为带宽不足而影响性能。同时也容易出项竞争冒险现象。如果内存损坏，会影响整个系统的工作，稳定性不如分布式共享存储器结构。</p>
</div>
<div class="paragraph">
<p>在使用监听一致性协议的多核处理器中，性能通常受多种因素影响。具体来说，总体缓存性能由两个因素共同决定：一个是由单处理器缓存缺失造成的流量；另一个是通信导致的流量，它会导致无效及后续的缓存缺失。改变处理器数量、缓存大小和块大小能够以不同方式影响缺失率的这两方面，最终影响总体系统性能。</p>
</div>
<div class="paragraph">
<p>对单处理器缺失率可以进行3C分类，即容量（capacity）、强制（compulsory）和冲突（conflict），并深入讨论了应用特性和对缓存设计的可能改进。与此类似，有两种来源会引起因处理器之间的通信而导致的缺失（通常称为一致性缺失)。</p>
</div>
<div class="paragraph">
<p>第一种是所谓的真共享缺失，源自通过缓存一致性机制进行的数据通信。在基于无效的协议中，处理器向共享缓存块的第一次写操作会导致建立该块的所有权无效。此外，当另一个处理器尝试读取这个缓存块中的已修改字时，会发生缺失，并传送结果块。由于这两种缺失都是由处理器之间的数据共享直接导致的，所以都被归类为真共享缺失。</p>
</div>
<div class="paragraph">
<p>第二种称为假共享缺失，源于使用了基于无效的一致性算法，每个级存块只有一个有效位。如果因为写入块中的某个字（不是正被读取的字）而导致一个块无效（而且后续访问会导致缺失）就会发生假共享。如果接收到无效操作的处理器真的正在使用要写入的字，那这个访问就是真正的共享访问，无论块大小如何都会导致缺失。但是，如果正被写入的字和读取的字不同，那就不会因为这一无效操作而传送新值，而只是导致一次额外的级存缺失，所以它是假共享缺失。在假共享缺失的情况下，块被共享，但缓存中的字没有被实际共享，如果块大小是单个字。那就不会发生缺失。</p>
</div>
</div>
<div class="sect2">
<h3 id="_分布式共享存储器和目录一致性"><a class="link" href="#_分布式共享存储器和目录一致性">7.4. 分布式共享存储器和目录一致性</a></h3>
<div class="paragraph">
<p>集中式/对称共享存储器体系结构由于总线带宽等限制，处理器比较少。分布式共享存储器结构则是每个处理器有独立存储器，以允许增加更多核以及处理器。</p>
</div>
<div class="paragraph">
<p>同时为了减少带宽占用，使用了目录一致性协议。每个处理器在写数据时，只对目录进行通信。目录记录了数据的所有者以及一致性状态等信息。目录与存储器一起分配，使得不同的一致性请求访问不同的目录，从而防止竞争冒险且减少了带宽占用。</p>
</div>
<div class="paragraph">
<p>每当发生缓存缺失时，监听协议都需要与所有缓存通信，包括对潜在共享数据的写操作。监听式机制没有任何用于跟踪缓存状态的集中式数据结构，这既是它的一个基本优点（因为可以降低成本），也是可扩展性方面的致命弱点。</p>
</div>
<div class="paragraph">
<p>例如，考虑一个由4个四核多核组成的多处理器，它能够保持每个时钟周期一次数据访问的速率，时钟频率为4GHz。这些应用程序需要4~170GB/s的存储器总线带宽。带有两个DDR4存储器通道的i7支持的最大存储带宽是34GB/s。如果几个i7多核处理器共享同一个存储器系统，存储器系统很容易不堪重负。过去几年中，多核处理器的发展迫使所有设计人员转向某种分布式存储器，以支持各个处理器的带宽要求。</p>
</div>
<div class="paragraph">
<p>可以通过分布式存储器来提高存储带宽和互连带宽。这样会立刻将局部存储器通信与远程存储器通信分离开来，降低对存储器系统和互连网络的带宽要求。除非不再需要一致性协议在每次缓存缺失时进行广播，否则分布式存储器不会带来太大收益。</p>
</div>
<div class="paragraph">
<p>监听一致性协议的替代方法是目录协议（directory protocol）。目录中保存了每个可缓存块的状态。这个目录中的信息包括哪些缓存（或缓存集合）拥有这个块的副本，它是否需要更新，等等。在一个拥有共享最外层缓存（即L3）的多核中，实现目录机制比较容易：只需要为每个L3块保存一个位向量，其大小等于核的数量。这个位向量表示哪些私有L2缓存可能具有L3中某个块的副本，无效操作仅会发送给这些缓存。如果L3是包含性的，那这一方法对于单个多核是非常有效的，lnteli7中就采用了这种机制。</p>
</div>
<div class="paragraph">
<p>在多核中使用单个目录的解决方案是不可扩展的，尽管它避免了广播。这个目录必须是分布式的，并且其分布方式必须能够让一致性协议知道去哪里寻找存储器所有缓存块的目录信息。显而易见的解决方案是将这个目录与存储器一起分配，使不同的一致性请求可以访向不同的目录，就像不同的存储器请求访问不同的存储器一样。如果信息是在外部线存（比如多组的L3）中维护的，那么目录信息可以分布在不同的级存存储体中，从而有效地增加带宽。</p>
</div>
<div class="paragraph">
<p>分布式目录保留了如下特性：块的共享状态总是放在单个已知位置。利用这一性质，再维护一些信息，指出其他照些节点可能缓存这个块，就可以让一致性协议程免进行广播操作。下图显示了在向每个节点添加目录时，分布式存储器多处理器的组织形式。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./src/pic/7.4.png" alt="7.4">
</div>
</div>
<div class="paragraph">
<p>最简单的目录实现方法是将每个存储器块与目录中的一项相关联。在这种实现方式中，信息量与存储器块数（每个块的大小与L2或L3缓存块相同）和节点数的乘积成正比，其中一个节点就是在内部实现一致性的单个多核处理器或一小组处理器。对于处理器少于数百个的多处理器而言（每个处理器可能是多核的），这一开销不会导致问题，因为当块大小比较合理时，目录开销是可以忍受的。对于大型多处理器，需要一些方法来高效地扩展目录结构，不过，只有超级计算机规模的系统才需要操心这一点。</p>
</div>
<div class="sect3">
<h4 id="_目录式缓存一致性协议"><a class="link" href="#_目录式缓存一致性协议">7.4.1. 目录式缓存一致性协议</a></h4>
<div class="paragraph">
<p>目录式缓存一致性协议能有效减少维持缓存一致性的流量，可以扩展到大量处理器的系统中去。缺陷是在有较多处理器情况下目录储存开销较大，且访问内存时因为需要查目录，可能增加访问延迟。</p>
</div>
<div class="paragraph">
<p>当一个处理器请求访问一个内存块时，会首先查询目录以获取状态。</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">操作</th>
<th class="tableblock halign-left valign-top">行为</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">写操作</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">如果其他处理器内存块内有缓存该内存块，那么目录发出无效化消息通知其他处理器使他们的副本无效。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">读操作</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">目录更新共享列表。</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>和监听协议一样，目录协议也必须实现两种主要操作：处理读缺失和处理共享、干净级存块的写操作。（对于当前正被共享的块，其写缺失的处理就是上述两种操作的组合。）为实现这些操作，目录必须跟踪每个缓存块的状态。在简单协议中，状态可能为下列各项之一。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>共享——一个或多个节点缓存了这个块，存储器的值是最新的（所有级存中也是如此）。</p>
</li>
<li>
<p>未缓存——所有节点都没有这个缓存块的副本。</p>
</li>
<li>
<p>已修改——只有一个节点有这个级存块的副本，它已经对这个块进行了写操作，所以存储器副本已经过期。这个处理器称为这个块的拥有者。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>除了跟踪每个潜在共享存储器块的状态之外，我们还必须跟踪哪些节点拥有这个块的副本，因为在进行写操作时需要使这些副本无效。最简单的方法是为每个存储器块保存一个位向量，当这个块被共享时，这个向量的每一位指明相应的处理器芯片（它可能是一个多核）是否拥有这个块的副本。当存储器块处于独占状态时，我们还可以使用这个位向量来跟踪块的拥有者。为了提高效率，还会跟踪各个缓存中每个缓存块的状态。</p>
</div>
<div class="paragraph">
<p>每个缓存中状态机的状态与转换与监听缓存时使用的状态机相同，只不过转换时的操作稍有不同。用于定位一个数据项独占副本并使其无效的过程有所不同，因为它们需要在发出请求的节点与目录之间，以及目录与一个或多个远程节点之间进行通信。在监听式协议中，这两个步骤通过向所有节点进行广播而结合在一起。</p>
</div>
<div class="paragraph">
<p>下表列出了节点之间发送的消息类型。本地节点是发出请求的节点。主节点（home node）是一个地址的存储地址及目录项所在的节点。物理地址空间是静态分布的，所以可以事先知道哪个节点中包含给定物理地址的存储器与目录。例如，地址的高阶位可以提供节点编号，而低阶位提供该节点上存储器内的偏移。本地节点也可能是主节点。当主节点是本地节点时，必须访问该目录，因为副本可能存在于远程节点中。</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 11.1111%;">
<col style="width: 11.1111%;">
<col style="width: 11.1111%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">消息类型</th>
<th class="tableblock halign-left valign-top">来源</th>
<th class="tableblock halign-left valign-top">目标</th>
<th class="tableblock halign-left valign-top">消息内容</th>
<th class="tableblock halign-left valign-top">消息的功能</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">读缺失</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">本地缓存</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">主目录</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">P, A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">节点 P 在地址 A 发生读缺失；请求数据并将 P 设置为共享者</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">写缺失</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">本地缓存</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">主目录</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">P, A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">节点 P 在地址 A 发生写缺失；请求数据并使 P 成为独占拥有者</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">无效</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">本地缓存</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">主目录</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">向所有缓存了地址 A 块的远程缓存发送无效请求</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">无效</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">主目录</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">远程缓存</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">使地址 A 块数据的共享副本无效</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">取数据</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">主目录</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">远程缓存</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">取回地址 A 的块，并发送到它的主目录；把远程缓存中的块状态改为共享</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">取数据/无效</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">主目录</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">远程缓存</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">取回地址 A 的块，并发送到它的主目录；使缓存中的块无效</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">数据值应答</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">主目录</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">本地缓存</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">从主存储器返回数据值</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">数据写回</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">远程缓存</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">主目录</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A, D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">写回地址 A 的数据值</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>远程节点是拥有缓存块副本的节点，该副本可能是独占的（只有一个副本），也可能是共享的。远程节点可能与本地节点或主节点相同。在此类情况下，基本协议不会改变，但处理器之间的消息可能会被处理器内部的消息代替。</p>
</div>
<div class="paragraph">
<p>本节采用存储器一致性的一种简单模型。为了在最大程度上减少消息的类型及协议的复杂性，我们假定这些消息的接受及处理顺序与其发送顺序相同。这一假定在实际中并不成立，并且可能会导致额外的复杂性。在本节，我们利用这一假定来确保在传送新消息之前先处理节点发送的无效操作，就像在讨论监听式协议的实现时所做的假设一样。和在监听情景中一样，我们省略了一些实现一致性协议所必需的细节。具体来说，实现写操作的串行化，以及获知某写入的无效操作已经完成，并不像广播式监听机制中那样简单，而是需要采用明确的确认方法来回应写缺失和无效请求。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_同步基础"><a class="link" href="#_同步基础">7.5. 同步基础</a></h3>
<div class="paragraph">
<p>同步机制通常是以用户级软件例程实现的，这些例程依赖于硬件提供的同步指令。对于较小的多处理器或低争用场景，关键的硬件功能是不可中断的指令或指令序列，它们能以原子方式提取和改变一个值。软件同步机制就是利用这一功能实现的。本节的重点是锁定和解锁同步操作的实现。可以非常轻松地利用锁定和解锁来创建互斥，以及实现更复杂的同步机制。</p>
</div>
<div class="paragraph">
<p>在高争用情景中，同步可能会成为性能瓶颈，因为争用会引人更多延迟，而且在此种多处理器中延迟可能更大。</p>
</div>
<div class="sect3">
<h4 id="_基本硬件原语"><a class="link" href="#_基本硬件原语">7.5.1. 基本硬件原语</a></h4>
<div class="paragraph">
<p>在多处理器中实现同步时，所需要的关键功能是一组能够以原子方式读取和修改存储地址的硬件原语。没有这一功能，构建基本同步原语的成本就会过高，并且会随着处理器数量的增加而增加。基本硬件原语有许多形式，它们都能够以原子形式读取和修改一个位置，还可以判断读取和写入是否是以原子形式执行的。这些硬件原语是用于构建各种用户级同步操作的基本构建块，包括诸如锁和屏障之类的功能。一般情况下，架构师不希望用户利用基本硬件原语，而是希望系统程序员用这些原语来构建同步库，这个过程通常比较复杂。我们先来看一个硬件原语，并说明如何用它来构建某些基本的同步操作。</p>
</div>
<div class="paragraph">
<p>构建同步操作的一个典型操作就是原子交换（atomicexchainge），它会将寄存器中的一个值与存储器中的一个值交换。为了理解如何利用这一操作来构建基本的同步操作，假定我们希望构建一个简单的锁，数值0表示这个锁可以占用，数值1表示这个锁不可用。处理器设置锁的具体做法是将寄存器中的1与跟这个锁对应的存储器地址交换。如果其他某个处理器已经申请了访问权，则这一交换指令将返回1，否则返回0。在后一种情况下，这个值也被改变为1，以防止任意进行竞争的交换指令也返回0。</p>
</div>
<div class="paragraph">
<p>例如，考虑两个试图同时执行交换的处理器：因为只有一个处理器会首先执行交换操作并返回数值0.第二个处理器进行交换时将会返回1，所以不存在竞争问题。使用交换原语来实现同步的关键是这个操作具有原子性：交换是不可分的，两个同时进行的交换将由写人串行化机制进行排序。如果两个处理器都尝试以这种方式对同步变量进行置位，它们不可能认为自己同时对这个变量进行了置位。</p>
</div>
<div class="paragraph">
<p>还有大量其他原子原语可用于实现同步。它们都拥有一个关键待性：读取和更新存储器值的方式可以让我们判断这两种操作是不是以原子形式执行的。在许多较旧的多处理器中存在一种名为测试并置位（test-and-set）的操作，它会测试一个值，如果通过，就对这个值进行置位。比如，我们可以定义一个操作，它会检测0，并将其值设定为1，其使用方式与使用原子交换的方式类似。另一个原子同步原语是提取并递增（fetch-and-increment）：它返回存储地址的值，并以原子方式使其递增。通过用0值来表示同步变量未被声明，我们可以像使用交换一样使用提取并递增。</p>
</div>
<div class="paragraph">
<p>实现单个原子存储器操作会引入一些挑战，因为它需要在单个不可中断的指令中进行存储器读写操作。这一要求增加了一致性实现的复杂性，因为硬件不允许在读取与写人之间插入任何其他操作，而且不能死锁。</p>
</div>
<div class="paragraph">
<p>替代方法是利用一对指令，其中第二条指令返回一个值，从这个值可以判断出这对指令是否像原子指令一样执行。如果任一处理器执行的所有其他指令要么在这对指令之前执行，要么在这对指令之后执行，就可以认为这对指令具有原子性。因此，如果一个指令对具有原子特性，那么所有其他处理器都不能在这个指令对之间改变取值。这是在MIPS处理器和RISC-V中使用的方法。</p>
</div>
<div class="paragraph">
<p>在RISC-V中，这种指令对包含一个名为保留载入（load reserved）的特殊载入指令[也称为链接载入（load linked）或锁定载入（load locked）]和一个名为条件存储（store conditional）的特殊存储指令。保留载入将rsl指示的存储器内容加载到rd中，并在该存储器地址上创建一个保留。条件存储将rs2中的值存储到rs1提供的存储器地址中。如果对同一存储地址的写操作破坏了对该载入的保留，则条件存储失败并将非零写入rd；如果成功，条件存储写入0。如果处理器在两条指令之间进行了上下文切换，那么条件存储总是失败。</p>
</div>
<div class="paragraph">
<p>这些指令是按顺序使用的。因为链接载入返回初始值，而条件存储仅在成功时才返回0，所以以下序列会用x4中的值对x1指定的存储地址实现一次原子交换：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-asm" data-lang="asm">try:
mov	x3, x4	;移动交换值
lr	x2, x1	;保留载入
sc	x3, 0(x1)	;条件存储
bnez	x3, try	;分支存储失败
mov	x4, x2	;将载入值放入x4中</code></pre>
</div>
</div>
<div class="paragraph">
<p>在这个序列的末尾，x4的内容和x1指定的存储地址已经实现了原子交换。每当处理器介入lr和sc指令之间，修改了存储器中的取值，那么sc在x3中返回0，导致此代码序列再次尝试。</p>
</div>
<div class="paragraph">
<p>链接载入/条件存储机制的优势之一就是它能用于构建其他同步原语。例如，下面是原子的“提取并递增”：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-asm" data-lang="asm">try:
lr	x2, x1	;保留载入0(x1)
addi	x3, x2, 1	;递增
sc	x3, 0(x1)	;条件存储
bnez	x3, try	;按条件存储失败</code></pre>
</div>
</div>
<div class="paragraph">
<p>这些指令通常是通过在称为链接寄存器的寄存器中跟踪lr指令指定的地址来实现的。如果发生了中断，或者与链接寄存器中地址匹配的缓存块无效（比如，另一条sc使其无效），那么链接寄存器将被清除。sc指令只是核查它的地址与链接寄存器中的地址是否匹配。如果匹配，sc将成功，否则会失败。因为在再次尝试向链接载入地址进行存储之后，或者在任何异常之后，条件存储会失败，所以在选择向两条指令之间插入的指令时必须非常小心。具体来说，只有寄存器一寄存器指令才是安全的；否则，就有可能造成死锁，即处理器永远无法完成sc指令。此外，链接载入和条件存储之间的指令数应当很少，以尽可能降低无关事件或竞争处理器导致条件存储频繁失败的概率。</p>
</div>
</div>
<div class="sect3">
<h4 id="_使用一致性实现锁"><a class="link" href="#_使用一致性实现锁">7.5.2. 使用一致性实现锁</a></h4>
<div class="paragraph">
<p>在拥有原子操作之后，就可以使用多处理器的一致性机制来实现自旋锁(spin lock)——处理器不断尝试获取的锁，它在循环中自旋，直到成功为止。在两种情况下会用到自旋锁：程序员希望短时间拥有这个锁；程序员希望当这个锁可用时，锁定过程的延迟较低。因为自旋锁会占用处理器，在循环中等待锁被释放，所以在某些情况下不适用。</p>
</div>
<div class="paragraph">
<p>最简单的实现方法是在存储器中保存锁变量，在没有缓存一致性时会使用这种实现方式。处理器可能使用原子操作（比如原子交换）持续尝试获得锁，并测试这一交换过程是否返回了可用锁。为释放锁，处理器只需要在锁中存储数值0即可。下面是锁定地址为x1的自旋锁的代码序列。它将EXCH作为宏，用来表示上一节中的原子交换序列：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-asm" data-lang="asm">addi	x2, R0, #1
lockit:	EXCH	x2, 0(x1)	;原子交换
bnez	x2, lockit	;已经锁定？</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果多处理器支持缓存一致性，就可以使用一致性机制将锁放在缓存中，以保持锁值的一致性。将锁放在级存中有两个好处。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>可以在本地缓存副本上完成“自旋”过程（尝试在一个紧凑循环中测试和获取锁），不需要在每次尝试获取锁时都请求全局存储器访问。</p>
</li>
<li>
<p>第二个好处来自以下观察结果：锁访问往往有良好的局部性；也就是说，上次使用了一个锁的处理器，会在不远的将来再次使用它。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>在此类情况下，锁值可以驻存在这个处理器的缓存中，从而大幅缩短获取锁所需要的时间。</p>
</div>
<div class="paragraph">
<p>要实现第一个好处（在本地缓存副本上自旋，而不需要在每次尝试获取锁时都生成存储器请求），需要对这个简单的自旋过程做一点修改。在上述循环中，每当尝试进行交换时都需要一次写操作。如果多个处理器尝试获取这个锁，会分别生成这一写操作。这些写操作大多会导致写缺失，因为每个处理器都尝试获取处于独占状态的锁变量。</p>
</div>
<div class="paragraph">
<p>因此，应当修改自旋锁过程，使其在自旋过程中读取这个锁的本地副本，直到看到该锁可用为止。然后它尝试通过交换操作来获取这个锁。处理器首先读取锁变量，以检测其状态。处理器不断地读取和检测，直到读取的值表明这个锁已解锁为止。这个处理器随后与所有其他正在进行“自旋等待”的处理器展开竞争，看谁能首先锁定这个变量。所有进程都使用一条交换指令，这条指令读取旧值，并将数值1存储到锁变量中。唯一的获胜者将会看到0.而失败者将会看到由获胜者放在里面的1。（失败者会继续将这个变量设置为锁定值，但这已经无关紧要了。）获胜的处理器在锁定之后执行代码，完成后将0存储到锁定变量中，以释放这个锁，然后再从头开始竞争。</p>
</div>
<div class="paragraph">
<p>让我们看看这个“自旋锁”机制是如何使用级存一致性机制的。下表展示了当多个进程尝试使用原子交换来锁定一个变量时的处理器和总线（或目录）操作。一旦拥有锁的处理器将0存储到领中，所有其他缓存都将无效，必须提取新值以更新它们保存的锁副本。这种缓存首先获取解锁值（0）的副本，并执行交换。在满足其他处理器的缓存缺失之后，它们发现这个变量已经被锁定，所以必须回过头来进行检测和自旋。</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 7.6923%;">
<col style="width: 15.3846%;">
<col style="width: 15.3846%;">
<col style="width: 15.3846%;">
<col style="width: 23.0769%;">
<col style="width: 23.077%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">步骤</th>
<th class="tableblock halign-left valign-top">P0</th>
<th class="tableblock halign-left valign-top">P1</th>
<th class="tableblock halign-left valign-top">P2</th>
<th class="tableblock halign-left valign-top">步骤结束时锁的一致性状态</th>
<th class="tableblock halign-left valign-top">总线/目录操作</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">拥有锁</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">开始自旋，判断锁是否为 0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">开始自旋，判断锁是否为 0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">共享</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">以任意顺序满足 P1 和 P2 的缓存缺失后，锁状态变为共享</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">将锁设为 0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">（接收到无效操作）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">（接收到无效操作）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">独占（P0）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">来自 P0 锁变量的写入无效操作</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">缓存缺失</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">缓存缺失</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">共享</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">总线/目录为 P2 缓存缺失提供服务；从 P0 写回，状态为共享</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">（当总线/目录忙时等待）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">通过锁为 0 检测</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">共享</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">满足 P2 的缓存缺失</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">锁为 0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">执行交换，获得缓存缺失</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">共享</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">满足 P1 的缓存缺失</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">6</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">执行交换，获得缓存缺失</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">完成交换，并将锁设为 0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">独占（P2）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">总线/目录为 P2 缓存缺失提供服务；生成无效操作；锁为独占状态</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">交换完成，返回 1，将锁设置为 1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">进入关键部分</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">独占（P1）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">总线/目录为 P1 缓存缺失提供服务；发送无效操作，并从 P2 生成写回操作</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">8</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">自旋，检测锁是否为 0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">无</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">无</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">无</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_存储器一致性模型"><a class="link" href="#_存储器一致性模型">7.6. 存储器一致性模型</a></h3>
<div class="paragraph">
<p>存储器一致性模型保证了在多处理器对内存的访问的数据一致性，不同模型决定了处理器如何对待内存访问的顺序性，从而影响程序的正确性和性能。</p>
</div>
<div class="paragraph">
<p>缓存一致性保证了多个处理器看到的存储器内容是一致的，但它并没有说明这些存储器内容应当保持何种程度的一致性。当我们问“何种程度的一致性”时，实际是在问一个处理器必须在什么时候看到另一个处理器更新过的值。由于处理器通过共享变量（用于数据值和同步两种目的）进行通信，于是这个问题便简化为：处理器必须以何种顺序观测另一个处理器的数据写操作?由于“观测另一处理器的写操作”的唯一方法就是通过读操作，所以问题现在变为：在不同处理器对不同位置执行读写操作时，必须保持哪些特性?</p>
</div>
<div class="paragraph">
<p>“保持何种程度的一致性”这一问题看起来非常简单，实际上却非常复杂，我们通过一个简单的例子来了解一下。下面是来自处理器P1和P2的两段代码：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-asm" data-lang="asm">P1:		A=0;		P2:		B=0;
		....				....
		A=1;				B=1;
L1:		if(B==0)...			if(A==0)...</code></pre>
</div>
</div>
<div class="paragraph">
<p>假定这些进程运行在不同处理器上，并且位置A和B最初由两个处理器进行缓存，初始值为0。如果写操作总是立刻生效，并且马上就会被其他处理器看到，那么两个IF语句（标有L1和L2）就不可能同时为真，因为能够到达IF语句就说明A或B必然已经被赋值为1。但假定写无效被延迟了.并且处理器可以在延迟期间继续执行。那么，P1和P2在尝试读取数值之前，可能还没有（分别）看到B和A的无效。现在的问题是：是否应当允许这一行为？如果应当允许，在何种条件下允许?</p>
</div>
<div class="paragraph">
<p>存储器一致性的最直观的模型称为顺序一致性模型。顺序一致性（sequential consistency）要求任何程序每次执行的结果都是一样的，就像每个处理器是按顺序执行存储器访问操作的，而且不同处理器之间的访问任意交错在一起。顺序一致性使上述示例中的执行结果不可能出现，因为只有在完成赋值操作之后才能启动IF语句。</p>
</div>
<div class="paragraph">
<p>实现顺序一致性模型的最简单方法是要求处理器推迟完成任意存储器访问，直到该访问操作所导致的全部无效均已完成为止。当然，推迟下一个存储器访问操作，直到前一个访问操作完成为止，这种做法同样有效。别忘了，存储器一致性涉及不同变量之间的操作：两个必须保持顺序的访问操作实际上访问的是不同的存储地址。在我们的例子中，必须延迟对A或B的读取（A==0或B==0），直到上一次写操作完成为止（B=1或A=1）。比如，根据顺序一致性，我们不能简单地将写操作放在写缓冲区中，然后继续执行读操作。</p>
</div>
<div class="paragraph">
<p>尽管顺序一致性模型给出了一种简单的编程范式，但它可能会降低性能，特别是在多处理器的处理器数量很多或者互连延迟很长时。</p>
</div>
<div class="paragraph">
<p>尽管顺序一致性模型有性能方面的不足，但从程序员的角度来看，它拥有简单的优点。挑战在于，要开发一种既便于解释又支持高性能实现方式的编程模型。</p>
</div>
<div class="paragraph">
<p>有一种这样的支持高效实现方式的编程模型，它假定程序是同步的。如果对共享数据的所有访问都由同步操作进行排序，那么这个程序就是同步的。如果满足以下条件。就认为数据访问是由同步操作排序的：在所有可能的执行情景中，一个处理器对某一变量的写操作与另一个处理器对该变量的访问（或者为读取，或者为写入）由一对同步操作隔离开来，其中一个同步操作在第一个处理器执行写操作之后执行，另一个同步操作在第二个处理器执行访问操作之前执行。如果变量可以在未由同步操作排序的情况下更新，则此类情景称为数据竞争（datarace），因为操作的执行结果取决于处理器的相对速度。和硬件设计中的竞争相似，其输出是不可预测的，由此得出了同步程序的另一个名字：无数据竞争（data-race-free）。</p>
</div>
<div class="paragraph">
<p>作为一个简单的例子，我们考虑一个变量由两个不同处理器读取和更新。每个处理器用锁定和解锁操作将读取和更新操作保护起来，这两种操作是为了确保更新操作的互斥和读操作的一致性。显然，每个写操作与另一个处理器的读操作之间现在都由一对同步操作隔离开来：一个是解锁（在写操作之后），一个是锁定（在读操作之前）。当然，如果两个处理器正在写人一个变量，中间没有插入读操作，那么这些写操作也必须由同步操作隔离开。</p>
</div>
<div class="paragraph">
<p>人们普遍认同“大多数程序是同步的”。这一观察结果之所以正确，主要是因为：如果这些访问是非同步的，那么程序的行为就可能是不可预测的，因为哪个处理器赢得数据竞争由执行速度决定，并会影响程序结果。即使有了顺序一致性，也很难理清此类程序的执行逻辑程。</p>
</div>
<div class="paragraph">
<p>序员可以尝试通过构造自已的同步机制来确保顺序，但这种做法需要很强的技巧性，可能会导致充满漏洞的程序，而且在体系结构上可能不受支持，也就是说在以后换代的新多处理器中可能无法工作。因此，几乎所有的程序员都选择使用针对多处理器和同步类型进行了优化的同步库。</p>
</div>
<div class="paragraph">
<p>最后，使用标准同步原语可以确保即使体系结构实现了一种比顺序一致性模型更宽松的一致性模型，同步程序也会像硬件实现了顺序一致性一样正确运行。</p>
</div>
<div class="sect3">
<h4 id="_宽松一致性模型"><a class="link" href="#_宽松一致性模型">7.6.1. 宽松一致性模型</a></h4>
<div class="paragraph">
<p>宽松一致性模型的关键思想是允许乱序执行读写操作，但使用同步操作来确保顺序，因此，同步程序的表现就像处理器具备顺序一致性一样。宽松模型多种多样，可以根据它们放松了哪种读取和写入顺序来进行分类。我们利用一组规则来指定顺序，其形式为X→Y，也就是说必须在完成操作X之后才能执行操作Y。顺序一致性模型需要保持所有4种可能的顺序：R→W，R→R、W→R和W→W。宽松模型由它们放松了的顺序来定义。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>仅放松W→R顺序将会得到一种称为完全存储排序（total store ordering）或处理器一致性（processor consistency）的模型。由于这种模型保持了写操作之间的顺序，所以许多根据顺序一致性运行的程序也能在这一模型下运行，不用添加同步。</p>
</li>
<li>
<p>放松W→R和W→W顺序会得到一种称为部分存储顺序（partial store order）的模型。</p>
</li>
<li>
<p>放松所有4种顺序会得到许多模型、包括弱排序（weak ordering）、PowerPC一致性模型和释放一致性（release consistency，RISC-V一致性模型）。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>通过放松这些顺序，处理器有可能获得显著的性能提升，这也是RISC-V、ARMv8以及C++和C语言标准选择释放一致性模型的原因。</p>
</div>
<div class="paragraph">
<p>释放一致性区分了用于获取对共享变量访问的同步操作(标记为\(S_A\))和那些释放对象以允许其他处理器获取访问的同步操作（标记为\(S_R\)）。释放一致性基于这样的观察：在同步程序中，获取操作必须在使用共享数据之前执行，而释放操作必须在共享数据的任何更新之后、下一个获取操作之前执行。这个属性允许我们通过如下观察稍微放松顺序：在获取操作之前的读取或写操作不需要在获取操作之前完成，并且在释放操作之后的读或写操作不需要等待释放操作。因此，保留的排序只涉及\(S_A\)、和\(S_R\)，如下表所示。</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top" colspan="2">模型类型</th>
<th class="tableblock halign-left valign-top">定义</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">顺序一致性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">要求所有处理器的而操作按照程序中规定的顺序执行，且所有处理器看到的操作顺序一致</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="4"><p class="tableblock">宽松一致性模型</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">完全存储排序或处理器一致性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">仅放松W&#8594;R顺序。保持了写操作之间的顺序</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">部分存储排序</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">放松W&#8594;R和W&#8594;W顺序</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">弱排序</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">放松所有四种顺序</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">释放一致性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">放松所有四种顺序。区分了用于获取对共享变量访问的同步操作（标记为S<sub>A</sub>）和那些释放对象以允许其他处理器获取访问的同步操作（标记为S
<sub>R</sub>）</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>释放一致性提供了一种限制最少的模型，它易于检查，并且能确保同步程序将看到顺序连贯的执行。尽管大多数同步操作是获取或释放操作（获取操作通常读取同步变量并自动更新它，而释放操作通常只是写入），但一些操作既充当获取操作又充当释放操作，并导致排序相当于弱排序。尽管同步操作总是确保之前的写操作已经完成，但我们可能需要确保在没有指定同步操作的情况下完成写操作。在这种情况下，一个显式指令(在RISC-V中称为FENCE)被用来确保该线程中所有之前的指令已经完成，包括所有存储器写人和相关的无效操作。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_多处理器测试基准和性能模型"><a class="link" href="#_多处理器测试基准和性能模型">7.7. 多处理器测试基准和性能模型</a></h3>
<div class="paragraph">
<p>为了避免可能的作弊行为，一个典型的原则是不能修改基准测试程序。源代码和数据集是固定的，并且只有唯一的正确结果。对这些原则的任何违反都会导致测试结果无效。</p>
</div>
<div class="paragraph">
<p>许多多处理器基准测试程序都遵循这些规则。一个共同的例外是允许扩大问题规模，这样可以在有不同数量处理器的系统上运行基准测试程序。也就是说，许多基准测试程序允许弱比例缩放而不是强比例缩放。但即便如此，在比较不同问题规模的测试结果时仍要小心。以下是对不同基准测试程序的具体描述。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Linpack是一组线性代数例程，这些例程执行高斯消元。它允许弱比例缩放，让用户选择任何规模的问题。例如，超级计算机可能会解决维度为每边1000万的密集矩阵。而且，只要保证计算结果正确并对相同规模的问题执行相同数量的浮点运算。Linpack允许用户以几乎任何形式和任何语言重写Linpack。计算Linpack最快的500台计算机每年在www.top500.org发布两次。排名第一的计算机被新闻界视为世界上最快的计算机。鉴于当今能效的重要性，该组织还发布了Gren500列表，根据运行Linpack的每瓦性能对Top500进行排序，公布世界上能效最高的超级计算机。S</p>
</li>
<li>
<p>SPECrate是基于SPEC CPU基准测试（如SPEC CPU 2017）的吞吐量指标。SPECrate并不报告各个程序的性能，而是同时运行该程序的很多副本。因此，它测量的是任务级并行性，因为这些任务之间没有通信。而且可以根据需要运行任意数量的程序副本，这也是一种弱比例缩放的形式。</p>
</li>
<li>
<p>SPLASH和SPLASH2 (Stanford Parallel Applications for Shared Memory)是20世纪90年代斯坦福大学的研究成果，目的是提供类似于SPECCPU的并行基准测试程序。它由核心程序和应用程序组成，许多来自高性能计算领域。尽管该程序提供了两组数据集，但仍需要强比例缩放。</p>
</li>
<li>
<p>NAS(NASA Advanced Supercomputing)并行基准测试是20世纪90年代对多处理器基准测试程序的另一尝试，由5个来源于流体动力学的核心程序构成，允许通过定义几个数据集实现弱比例缩放。像Linpack一样，这些基准测试程序可以被重写，但编程语言只能使用C或Fortran。</p>
</li>
<li>
<p>PARSEC (Princeton Application Repository for Shared MemoryComputer)基准测试程序集由 Pthread（POSIX线程）和OpenMP（Open MultiProcessing）的多线程程序组成。它们主要专注于新兴的计算领域，由9个应用程序和3个核心程序构成。其中8个依赖于数据并行，3个依赖于流水线并行，另一个依赖于非结构化并行。</p>
</li>
<li>
<p>加州大学伯克利分校的研究人员提出了一种方法。他们确定了l3种面向未来应用程序的设计模式。这些设计模式使用框架或核心实现，一些实例包括稀疏矩阵、结构化网格、有限状态自动机、MapReduce和图遍历等。通过将定义保持在高级别层次，他们希望鼓励在系统的任何层次进行创新。因此，速度最快的稀疏矩阵求解器的系统除了使用新型体系结构和编译器之外，还可以使用任何数据结构、算法和编程语言。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>基准测试程序原有约束所造成的负面影响是创新被局限到体系结构和编译器中。更好的数据结构、算法、编程语言等通常不能被使用，因为这些可能产生容易令人误解的结果。这样系统可能因为算法而获胜，而不是因为硬件或编译器。</p>
</div>
<div class="paragraph">
<p>虽然这些准则在计算基础相对稳定时是可以理解的——因为它们是在20世纪90年代提出的，而且是在90年代的前5年——但是，这些准则在编程变革中就不合时宜了。要使变革成功，我们需要鼓励各个层次的创新。</p>
</div>
<div class="paragraph">
<p>MLPef通常运行在并行计算机上，是ML的最新基准程序，尽管并不是主要的并行计算基准程序。MLPerf包括程序、数据集和基本规则。为跟上ML的快速发展，新版本的MLPerf基准测试每三个月更新一次。MLPerf也包括测试运行时的功耗，以对不同规格的计算机进行规格化。基准测试程序的一个新特色是同时提供测试程序的开源和闭源版本。闭源版本用来严格控制提交规则，以确保系统之间的公平比对。开源版本鼓励创新，包括更好的数据结构、算法、编程系统等。开源版本提交只需要使用相同的数据集执行相同的任务。</p>
</div>
<div class="sect3">
<h4 id="_性能模型"><a class="link" href="#_性能模型">7.7.1. 性能模型</a></h4>
<div class="paragraph">
<p>与基准测试程序相关的一个话题是性能模型。正如我们在本章中看到越来越多的体系结构多样性——多线程、SIMD、GPU———如果我们有一个简单的模型来分析不同体系结构设计的性能，将是十分有益的。这个模型不一定是完美的，只要有所见地就行。</p>
</div>
<div class="paragraph">
<p>用于分析cache性能的3C模型是性能模型的一个例子。它不是一个完美的性能模型，因为它忽略了块大小、块分配策略和块替换策略等潜在的重要因素。而且，它还存在一些含糊其辞的地方。例如，一次失效在一种设计中可以归为容量失效，而在同样容量的另一个cache中可以归为冲突失效。然而，3C模型已经流行了25年，因为它提供了对程序行为的深入理解，有助于体系结构设计者和程序员根据对该模型的观察改进他们的创新成果。</p>
</div>
<div class="paragraph">
<p>为了找到并行计算机的这种模型，让我们从小的核心程序开始。尽管这些核心程序的不同数据类型有许多版本，但浮点在几种实现中很常见。因此，在给定的计算机上峰值浮点性能是这类核心程序的速度瓶颈。对于多核芯片，峰值浮点性能是芯片上所有处理器核峰值性能的总和。如果系统中包含多个处理器，那么应该将每个芯片的峰值性能与芯片总数相乘。</p>
</div>
<div class="paragraph">
<p>对存储器系统的需求可以用峰值浮点性能除以每访问一字节所包含浮点操作数的平均值来估算：</p>
</div>
<div class="stemblock">
<div class="content">
\[\frac{浮点操作数/秒}{浮点操作数/字节} = 字节/秒\]
</div>
</div>
<div class="paragraph">
<p>存储器每访问一字节所包含的浮点运算比例称为算术强度(arithmetic intensity)。它的计算可以用程序中浮点运算的总数除以程序执行期间内存传输数据的总字节数。</p>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_集群仓库级计算机wsc"><a class="link" href="#_集群仓库级计算机wsc">8. 集群、仓库级计算机（WSC）</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>高性能计算（HPC）集群与仓库级计算机（WSC）应用领域不同。前者更倾向于线程级并行，主要解决复杂问题。而后者强调请求级并行，同时为多个用户进行服务。</p>
</div>
<div class="paragraph">
<p>仓库级计算机（WSC）是几十亿人每日所用互联网服务的基础，这些服务包括：搜索、社交网络、在线地图、视频共享、网上购物、电子邮件服务，等等。此类互联网服务深受大众喜爱，从而有了创建WSC的必要，以满足公众迅速增长的需求。尽管WSC可能看起来只是一些大型数据中心，但它们的体系结构和运行有很大的不同，这一点稍后我们就会看到。今天的WSC像是一个巨型机器，其成本高达数亿美元，包括机房、配电与制冷基础设施、服务器和网络设备，其中网络设备连接并容纳了50000至100000台服务器。此外，商业云计算的快速增长让每一个拥有信用卡的人都能使用WSC。</p>
</div>
<div class="paragraph">
<p>计算机体系结构很自然地扩展到WSC的设计中。例如，Google公司Luiz Barroso的论文研究的就是计算机体系结构。他认为，架构师在设计过程中实现可扩展性、提高可信性的技巧以及调试硬件的技巧，对于创建和运行WSC有很大的帮助。</p>
</div>
<div class="paragraph">
<p>WSC的巨大规模需要在配电、制冷、监控和运行等各个方面做出创新。WSC是超级计算机的现代后裔，这一点也让Seymour Cray成为当今WSC架构师的教父。他的极限计算机可以处理一些在其他任何地方都无法完成的计算，但非常昂贵，只有少数几家公司负担得起。而WSC的目标是为整个世界提供信息技术，而不再是为科学家和工程师提供高性能计算（HPC）。因此，相较于Cray的超级计算机在过去发挥的作用，WSC在当今社会中扮演了更为重要的角色。</p>
</div>
<div class="paragraph">
<p>毫无疑问，WSC的用户要比高性能计算的用户多出好几个量级，它在IT市场占有的份额也要大得多。无论是按用户数量计算还是按收入计算，Google公司都比Cray Research 公司大1000倍。</p>
</div>
<div class="paragraph">
<p>WSC架构师的许多目标和需求与服务器架构师一致。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>性价比——每一美元能够完成的工作量至关重要，部分原因就是WSC的规模太大了。将一组WSC的成本降低几个百分点就可以节省数百万美元。</p>
</li>
<li>
<p>能效——除了逃逸出去的光子，WSC本质上是封闭的系统，几乎所有能耗都转化为必须被移除的热量。因此，峰值功耗和实际功耗推高了配电与制冷系统两项成本。建造WSC的大部分基础设施成本都花在了电力和制冷上。另外，能效也是环境管理的一个重要组成部分。因此，每焦耳完成的工作量对于wSC和它的服务器来说都至关重要，因为为仓库级计算机建造电力与机械基础设施的成本很高，每月因此产生的水电费也很高。</p>
</li>
<li>
<p>通过冗余提高可信性——互联网服务长时间运行的本质，意味着WSC中的硬件和软件必须至少共同提供99.99%的可用性；也就是说，它每年的宕机时间必须低于1小时。对于WSC和服务器来说，冗余都是提高可信性的关键。服务器架构师经常利用数量更多且价格更高的硬件来实现高可用性，而WSC架构师则利用由网络连接的大量高性价比的服务器，并依赖软件来管理系统的冗余。除了WSC内部的本地冗余之外，一个组织还需要冗余的WSC来应对可能会摧毁整个WSC的事件。事实上，尽管每一个云服务都需要在至少99.99%的时间内可用，但像Amazon、Google或Microsoft这样的纯互联网公司对可信性的要求更高。如果其中一家公司每年有1小时完全离线——也就是99.99%的可用性——那就会成为头版新闻。多个WSC还有利于减少跨地域广泛部署的服务的延迟。</p>
</li>
<li>
<p>网络I/O——服务器架构师必须提供一个出色的网络接口来连接外部世界，WSC架构也必须如此。为保持多个WSC之间的数据一致性，以及与公众交互，需要进行联网。</p>
</li>
<li>
<p>交互式与批处理工作负载——尽管人们期望搜索和社交网络等拥有数十亿用户的服务具有高度交互的工作负载，但WSC像服务器一样，也运行着大量并行批处理程序，用以计算对此类服务有用的元数据。例如，它们可以执行MapReduce作业，将通过爬网返回的页面转换为搜索索引。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>当然，WSC也有一些不同于服务器体系结构的特性。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>足够的并行度——服务器架构师关注的一个问题是，目标市场中的应用程序是否有足够的并行度以充分发挥大量并行硬件的功用，以及为了挖掘这些并行性所使用的通信硬件的成本是否过高。WSC架构师则不关注此类问题。首先，批处理应用程序获益于大量需要独立处理的独立数据集，比如爬取的数十亿个网页。这一处理过程就是数据级并行，这里的数据指的是存储（storage）中的数据，而不是内存（memory）中的数据。第二，交互式互联网服务应用程序（也称为软件即服务，Saas）可从交互式互联网服务数以百万计的独立用户中获益。在SaaS中，读与写很少是相关的，所以SaaS很少需要同步。例如，搜索服务使用的是只读索引，而电子邮件通常需要读写独立的信息。因为许多独立的工作可以很自然地并行进行，几乎不需要通信或同步，所以我们将这种简单的并行称为请求级并行；例如，基于日志的更新过程可以降低吞吐量需求。有时需要放弃存储器中一些与读写数据相关的特性，以提供可扩展到现代WSC大小的存储。无论如何，WSC应用程序别无选择，只能找到能够跨越数百到数千台服务器的算法，因为这是客户所期望的，也是WSC技术所提供的。</p>
</li>
<li>
<p>运营成本计算——服务器架构师通常会忽略服务器的运营成本，假定其相对于购买成本是微不足道的。WSC的寿命更长——机房以及配电和制冷基础设施经常要使用10-15年，所以运营成本也不可小视：在10年中，能源、配电和制冷方面的费用占WSC成本的30%以上。</p>
</li>
<li>
<p>位置成本——要建立WSC，第一步是建立机房。一个问题是在哪儿建机房？房地产经纪人强调位置，但搭建WSC的位置要满足如下要求：有水和便宜的电力，靠近互联网主干光纤，附近的人能够到WsC工作，发生地震、洪水和飓风等环境灾害的风险很低。一个更加显而易见的问题是土地成本，包括WsC扩容所需的足够空间。对于有许多 WSC的公司来说，关注的另一个问题是找到一个靠近当前或未来互联网用户群的地方，以减少互联网延迟。其他因素包括税费、物业费、社会问题（有时人们希望在自己的国家或地区建立设施）、网络成本、网络的可靠性、电力成本、电力来源（例如水电和煤炭）、天气（制冷设备更便宜）、整体互联网连接（澳大利亚在地理位置上接近新加坡，但它们之间的网络链路带宽并不大）。</p>
</li>
<li>
<p>在低利用率下进行高效计算——服务器架构师设计系统的宗旨是在成本预算范围内达到峰值性能，他们仅仅在系统可能超过其机箱的冷却能力时才需要担心功耗问题。WSC服务器很少得到充分利用，部分原因是为了确保低响应时间，部分原因是为了提供进行可靠计算所需的冗余。考虑到运营成本，这些服务器需要在所有利用率级别上高效地计算。</p>
</li>
<li>
<p>规模以及与规模相关的机会/问题——通常，极限计算机是极其昂贵的，因为它们需要定制硬件，而且因为极限计算机的制造数目很低，所以无法有效地分摊定制成本。不过，如果我们一次购买数千台服务器，则可以获得很低的折扣。由于WSC本身就非常庞大，所以即使没有太多WSC.也可以实现规模经济效应。这些规模经济导致了商业云计算的出现，这是因为WSC的单位成本更低，也就是说，一些公司可以向外租借服务器，其利润低于租借者自行租用的成本。100000台服务器的不利之处就是容易发生故障。即使一台服务器的平均无故障时间（MTTF）达到了令人惊叹的25年（200000小时），WSC架构师在进行设计时也要考虑每天有5台服务器发生故障的情况。年磁盘故障率为2%-10%。如果每台服务器有2块硬盘，它们的年故障率为4%，那么对于拥有100000台服务器的WSC时，预计架构师每小时就会看到一块磁盘发生故障。然而，软件故障远远超过硬件故障，因此系统设计必须具有弹性，能够应对由软件故障导致的服务器崩溃，而服务器崩溃比磁盘故障发生得更频繁。由于在这些非常大的设施中有数千台服务器，WSC操作员非常擅长更换磁盘，因此WSC的磁盘故障成本要比小型数据中心低得多。这同样适用于DRAM。如果有更便宜的组件，WSC可以使用可靠性更差的组件。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>WSC的先驱是计算机集群(computer cluster)。集群是一组使用局城网（LAN）和交换机连接在一起的独立计算机。对于不需要密集通信的工作负载，集群计算的成本效益要远高于共享存储器多处理器。（共享存储器多处理器是多核计算机的先驱。）集群在20世纪90年代后期开始流行，先用于科学计算，后来用于互联网服务。关于 WSC 有这样一个观点：它们就是过去数百台服务器组成的集胖向今天数万台服务器所组成的集群的逻辑演化。</p>
</div>
<div class="paragraph">
<p>一个很自然的问题是：WSC是否与高性能计算（HPC）使用的现代集群类似?尽管一些WSC的规模和成本与HPC相近（有些HPC设计拥有100万台处理器，花费数亿美元），但HPC在历史上拥有比WSC更强大的处理器和更低的节点间网络延迟，因为HPC应用的依赖性更强，通信更频繁。其编程环境还强调线程级并行或数据级并行，通常强调完成单项任务的延迟，而不是通过请求级并行完成许多独立任务的带宽。HPC集群往往还拥有长时间运行的作业，它们会使服务器满负荷运行，甚至能持续数周以上，而WSC中服务器的利用率通常在10%~50%，而且每天都会发生变化。与超级计算机环境不同，每周都有数千名开发人员在WSC代码库上工作，并部署重要的软件版本。</p>
</div>
<div class="paragraph">
<p>WSC与传统数据中心相比又怎么样呢?传统数据中心的运营人员通常从组织的许多部门收集机器和第三方软件，并集中为他人运行这些机器和软件。他们的关注点通常是将许多服务整合到较少的机器中，并且这些机器相互隔离，以保护敏感信息。因此，虚拟机在数据中心的重要性日益增加。虚拟机对WSC来说也很重要，但扮演的角色不同。它们用于在不同的客户之间提供隔离，并将硬件资源分割成不同大小的共享部分，以便以不同的价格出租。与WSC不同，传统数据中心往往拥有各种不同的硬件和软件，为一个组织中的不同客户提供服务。WSC程序员则定制第三方软件或者自行开发软件，WSC的硬件一致性要强得多；WSC的目标是让仓库中的硬件/软件就像一台计算机一样，只是上面运行着各种不同的应用程序。传统数据中心的最大成本通常是维护人员的费用，在设计完善的WSC中，服务器硬件是最大的成本，人力成本从最大成本变为几乎可以忽略。传统数据中心也不具备WSC的规模，所以它们无法获得前述的规模经济效益。</p>
</div>
<div class="paragraph">
<p>因此，尽管WSC可能被认为是一个极端的数据中心（因为这些计算机被单独放置在具有特殊配电和制冷基础设施的空间内），但典型的数据中心通常没有WSC所面对的挑战和机遇，无论是体系结构方面还是运营方面都是如此。</p>
</div>
<div class="sect2">
<h3 id="_仓库级计算机的编程模型与工作负载"><a class="link" href="#_仓库级计算机的编程模型与工作负载">8.1. 仓库级计算机的编程模型与工作负载</a></h3>
<div class="paragraph">
<p><strong>编程模型</strong></p>
</div>
<div class="paragraph">
<p>仓库级计算机的编程模型是为处理大规模分布式系统和云计算环境中的任务而设计的。它的核心在于高效地利用由数千甚至数百万台计算节点组成的集群，这些节点通常分布在多个机架中，并通过高速网络互联。编程模型需要在高吞吐量、容错性、分布式数据处理和并行计算之间找到平衡，从而最大化资源利用率，同时满足应用的性能和可靠性需求。</p>
</div>
<div class="paragraph">
<p>仓库级计算机的编程模型通常采用分布式计算框架和抽象层，帮助开发者隐藏复杂的底层硬件细节。典型的编程模型包括MapReduce、Spark、Hadoop等，它们强调将任务分解为小块并行处理，通过分布式文件系统（如HDFS）进行数据存储和管理。程序的编写者只需专注于任务逻辑，而框架会负责调度、资源分配和故障恢复。</p>
</div>
<div class="paragraph">
<p>在这样的模型中，数据分布和任务划分是关键。程序需要设计成能够以并行方式处理大规模的数据集，因此任务通常会划分为多个独立的操作单元（如Map和Reduce阶段）。这些单元在多个节点上同时执行，从而加速计算过程。为了进一步优化性能，编程模型会尽量将计算移动到数据所在的节点，以减少数据传输的开销。</p>
</div>
<div class="paragraph">
<p>容错性是仓库级计算机编程模型的一个重要特性，因为硬件故障在如此大规模的系统中是不可避免的。框架通过数据冗余和任务重试机制来确保任务可以在某个节点失败的情况下继续进行。例如，当一个节点失效时，框架会自动将任务转移到另一个节点，避免整个计算过程中断。</p>
</div>
<div class="paragraph">
<p>此外，仓库级计算机的编程模型还支持高度灵活的调度和资源管理。例如，资源可以根据应用需求动态分配，开发者可以通过设置优先级和资源限制来控制任务的执行。负载均衡机制可以防止某些节点过载，同时提高整体系统的吞吐量。</p>
</div>
<div class="paragraph">
<p>编程模型还强调对多种数据格式和存储方式的支持，例如关系型数据库、键值存储、文档数据库等。为了满足多样化的计算需求，仓库级计算机编程模型通常支持多种语言接口（如Java、Python、Scala），并提供丰富的库和工具以加速开发。</p>
</div>
<div class="paragraph">
<p><strong>主要工作负载及应对方法</strong></p>
</div>
<div class="paragraph">
<p>仓库级计算机（Warehouse-Scale Computers, WSC）的主要工作负载包括搜索引擎、社交媒体、电子商务、大数据分析、机器学习训练和推理、视频流媒体服务等。由于这些工作负载通常涉及到海量数据、高并发请求和复杂计算，仓库级计算机需要通过精心设计的架构和优化技术来高效地应对这些挑战，以满足性能、可靠性和成本的需求。</p>
</div>
<div class="paragraph">
<p>首先，仓库级计算机的核心工作负载之一是搜索引擎服务。搜索引擎需要实时响应用户查询，处理大量的文档索引、排序和检索工作。为了满足这种需求，WSC将搜索索引分布在多个节点上，每个节点处理部分文档集合。这种分布式设计使得查询可以并行处理，显著提高了响应速度。同时，搜索结果排序通常需要复杂的算法计算，WSC通过优化硬件性能和缓存机制，减少了计算延迟。</p>
</div>
<div class="paragraph">
<p>社交媒体平台的工作负载包括用户内容生成、消息传递、实时推荐和大规模图计算。这些负载需要高并发的处理能力和快速的数据一致性保证。WSC通过分布式存储系统和分片技术，将数据分散在多个节点上，以提高吞吐量和降低延迟。同时，社交媒体中的推荐系统依赖实时用户数据分析，WSC通常采用流式计算框架（如Apache Kafka、Flink）来支持低延迟的实时数据处理。</p>
</div>
<div class="paragraph">
<p>电子商务平台的工作负载涉及库存管理、交易处理、支付系统以及推荐引擎。为了处理高峰流量和瞬时的大量交易请求，WSC利用负载均衡技术，将请求均匀分配到不同服务器上。此外，电子商务平台需要极高的数据一致性和事务可靠性，因此WSC常采用分布式事务处理协议（如两阶段提交）以及高可用的数据库系统来确保交易数据的正确性。</p>
</div>
<div class="paragraph">
<p>大数据分析和机器学习任务是WSC的另一类重要工作负载。这些任务需要处理海量数据，包括数据预处理、特征提取、模型训练和评估等。WSC通常采用分布式计算框架（如Hadoop、Spark）来划分和并行化计算任务，以充分利用集群资源。对于机器学习模型训练，WSC通过专用硬件（如GPU、TPU）和高效的分布式训练算法（如数据并行、模型并行）来加速计算过程，同时利用参数服务器等架构实现多节点之间的通信和同步。</p>
</div>
<div class="paragraph">
<p>视频流媒体服务的工作负载主要是视频的存储、转码和传输。为了高效处理海量的视频请求，WSC通常采用内容分发网络（CDN）将热门视频内容缓存在离用户更近的边缘节点，从而降低主数据中心的负载和传输延迟。此外，视频转码是一项计算密集型任务，WSC利用专用硬件加速器和并行计算技术来提升转码效率。</p>
</div>
<div class="paragraph">
<p>为应对这些工作负载，仓库级计算机需要结合多种优化方法。一方面，在硬件层面，WSC通过使用高性能处理器（包括CPU、GPU和加速器）、大容量内存和高速网络互联来提升性能。另一方面，在软件层面，WSC采用高效的分布式存储系统（如HDFS、Bigtable）和计算框架（如MapReduce、Spark）来优化数据处理。此外，为了实现高可用性和容错性，WSC依赖于数据冗余、任务重试和负载均衡等机制，确保即使在硬件故障或高峰流量下系统也能稳定运行。</p>
</div>
</div>
<div class="sect2">
<h3 id="_仓库级计算机的计算机体系结构"><a class="link" href="#_仓库级计算机的计算机体系结构">8.2. 仓库级计算机的计算机体系结构</a></h3>
<div class="paragraph">
<p>WSC的网络是将50000-100000台服务器连接在一起的结缔组织。类似于存储器层次结构，WSC使用一种层次化的网络结。理想情况下，这种合并后的网络将提供相当于为100000台服务器定制的高端交换机的性能，而每端口的成本只相当于为50台服务器设计的普通交换机。</p>
</div>
<div class="paragraph">
<p>承载服务器的结构是机架。虽然每个WSC的机架宽度不同（有些是经典的19英寸宽，其他的是这个宽度的两到三倍），但高度往往都不超过6-7英尺，以方便工作人员进行维修和保养。这样的机架大概可容纳40-80台服务器。由于在机架顶部连接网络电缆通常很方便，这种交换机通常称为机架（ToR）交换机。(有些WSC有带多个ToR交换机的机架。）通常，机架内的带宽比机架之间的带宽高得多，所以如果发送机和接收机在同一个机架内，软件将发送机和接收机放在哪里就不那么重要了。从软件的角度来看，这种灵活性是很理想的。</p>
</div>
<div class="paragraph">
<p>这些交换机通常提供4-16个上行链路，它们用来连接位于网络层次结构中的下一层交换机。因此，机架之间的带宽是机架内带宽的\(1/6～1/24(8/48～2/48)\)。这—比值称为收敛比（orersubscripion)。然而，当收敛比很高时，程序员必须知道将发送机和接收机放在不同机架时将导致的性能后果。这会增大软件调度负担，也是专门为数据中心设计网络交换机的另一个理由。</p>
</div>
<div class="paragraph">
<p>连接机架阵列的交换机比ToR交换机贵得多。产生这种成本的一个原因是更高的连通性，另一个原因是通过交换机的带宽必须更大，以减少收敛比问题。Barroso等人[2013]报告说，如果一个交换机的二分带宽（bisection bandwidth，基本上是最坏情况下的内部带宽）是机架式交换机的10倍，那么其成本大约是ToR交换机的100倍。其中一个原因是n端口交换机的带宽成本会增长倍。</p>
</div>
<div class="sect3">
<h4 id="_存储"><a class="link" href="#_存储">8.2.1. 存储</a></h4>
<div class="paragraph">
<p>WSC的存储体系以分布式存储系统为核心，这种架构通过将数据分散存储在多个物理服务器上，提供了良好的扩展性和容错能力。在分布式存储中，数据通常以分片（shard）的形式存储，每个分片会被复制到多个节点上以实现数据冗余，从而提高系统的可靠性。即使某些存储节点发生故障，系统也可以通过访问冗余副本来保证数据的可用性。分布式文件系统（如HDFS）和分布式数据库（如Google Spanner、Bigtable）是实现这一目标的典型例子。HDFS提供了对海量非结构化数据的存储支持，而Bigtable则擅长处理结构化数据，同时支持高吞吐量的随机读写操作。</p>
</div>
<div class="paragraph">
<p>其次，存储体系中的层次化存储设计也是WSC的关键特征。为了高效管理不同类型的数据和优化访问性能，WSC通常结合使用多种存储介质。快速但昂贵的存储介质（如DRAM和NVMe SSD）主要用于缓存和热数据存储，提供低延迟的数据访问；而廉价且容量大的存储介质（如HDD和磁带）则用于存储冷数据和归档数据。通过这种层次化设计，WSC在性能和成本之间实现了良好的平衡。例如，分布式缓存系统（如Memcached或Redis）利用DRAM缓存频繁访问的数据，降低了后端存储系统的压力，而冷数据可以被异步迁移到HDD或离线存储设备中。</p>
</div>
<div class="paragraph">
<p>数据一致性是WSC存储体系中必须解决的关键问题。由于数据分布在多个节点之间，分布式存储系统需要通过一致性协议（如Paxos或Raft）来确保数据副本的一致性。对于强一致性需求的应用（如金融交易系统），系统会采用同步复制机制，在写操作完成后立即更新所有副本。而对于某些可以容忍弱一致性的场景（如社交媒体新闻流），系统可能选择异步复制以减少延迟。此外，存储系统还支持事务性操作，提供原子性和隔离性，以确保复杂操作的正确性。</p>
</div>
<div class="paragraph">
<p>数据分布和访问模式优化是存储体系设计中的另一个重要方面。WSC需要通过智能的数据分布策略和索引机制来高效管理大规模数据。常见的做法是根据数据的访问频率、地理位置或内容特征来分布数据。例如，为了减少用户访问延迟，热门数据通常被复制到距离用户最近的节点或区域。同时，分布式哈希表（DHT）等索引技术被用来快速定位数据，提高查询效率。</p>
</div>
<div class="paragraph">
<p>为了满足现代应用对存储性能的高要求，WSC还依赖于硬件层面的优化。在许多情况下，WSC会配备高性能的网络存储设备（如NVMe SSD）和高速网络互联（如RDMA或NVLink）来加速数据传输。此外，一些先进的WSC甚至会使用专用的硬件加速器（如FPGA或ASIC）来优化特定存储操作（如压缩、解压缩和加密）。</p>
</div>
<div class="paragraph">
<p>最后，存储系统的可管理性和可扩展性也是WSC设计的重要目标。WSC通常采用分布式元数据管理来协调存储节点的操作，并通过自动化的负载均衡和故障恢复机制来减少人工干预。随着存储需求的增长，WSC可以通过简单地增加存储节点或升级硬件来扩展系统容量，而不需要对现有系统进行大规模的重构。</p>
</div>
</div>
<div class="sect3">
<h4 id="_wsc存储器层次结构"><a class="link" href="#_wsc存储器层次结构">8.2.2. WSC存储器层次结构</a></h4>
<div class="paragraph">
<p>在存储器层次结构的顶层，WSC通常利用高速缓存来加速对频繁访问数据的处理。这一层次的高速缓存包括处理器内置的L1、L2和L3缓存以及分布式缓存系统（如Memcached或Redis）。处理器内的高速缓存负责加速计算节点的本地数据访问，而分布式缓存则通过内存级存储实现整个集群范围内的数据共享。分布式缓存系统通常使用DRAM作为存储介质，具备极低的访问延迟，适用于存储热点数据或中间计算结果，从而减少对后端存储系统的压力。对于WSC的许多在线服务应用（如搜索引擎和社交媒体），分布式缓存系统起到了至关重要的作用。</p>
</div>
<div class="paragraph">
<p>在高速缓存之下，主存储器（DRAM）是存储层次结构的重要组成部分。主存储器为计算节点提供了较大的存储容量，用于支持运行中的应用程序和处理任务所需的数据。然而，DRAM的成本较高且功耗较大，因此其容量通常受限于实际预算。为优化主存储器的使用效率，WSC会采用内存分片和内存分级管理策略，将不同节点的内存资源虚拟化为一个统一的内存池，从而实现跨节点的高效资源共享。此外，近年来随着非易失性存储器（如3D XPoint）的兴起，一些WSC开始将非易失性存储器作为主存储器的一部分或其扩展，用以在降低成本的同时提高存储密度。</p>
</div>
<div class="paragraph">
<p>主存储器之下是分布式存储系统，这是WSC存储层次结构的核心部分。这一层次的存储系统通过分布式文件系统（如HDFS）或分布式数据库（如Google Spanner和Bigtable）实现海量数据的可靠存储和高效管理。分布式存储系统通常将数据分片，并将每个分片的多个副本存储在不同的物理节点上，从而提供高可靠性和容错能力。分布式存储系统支持的数据类型广泛，包括非结构化数据（如日志文件和多媒体内容）和结构化数据（如事务记录）。此外，分布式存储系统还支持动态负载均衡、分布式事务和一致性协议（如Paxos或Raft），以保证数据的可用性和一致性。</p>
</div>
<div class="paragraph">
<p>存储层次结构的底层是离线存储设备，用于存储冷数据和归档数据。这些设备包括大容量的HDD和磁带库，其特点是成本低但访问延迟较高。离线存储主要用于存储不经常访问的数据，例如历史日志、备份数据和归档文件。当需要访问冷数据时，系统可以将其从离线存储设备迁移到上层存储设备中，以支持进一步的处理或分析。通过这种分层存储策略，WSC能够在性能和成本之间取得平衡，同时确保满足不同数据访问模式的需求。</p>
</div>
<div class="paragraph">
<p>WSC存储器层次结构的设计还充分考虑了数据在不同层次之间的流动性。为了提高数据访问效率，WSC通常会采用多种数据迁移和缓存策略。例如，系统会将热点数据从底层存储设备预取到上层的高速缓存或主存储器中，以减少高延迟设备的访问频率。此外，分层存储还通过数据压缩、去重和智能分配技术优化了存储资源的利用率，从而进一步降低存储成本。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_云计算效用计算的回报"><a class="link" href="#_云计算效用计算的回报">8.3. 云计算：效用计算的回报</a></h3>
<div class="paragraph">
<p>由于用户数目不断增大，受用户需求的推动，Amazon、Google和Microsoft等互联网公司用商用组件构建了日益庞大的仓库级计算机，这使得麦卡锡的预测最终成为现实，但由于分时服务的流行，这一预测并非如他所想象的那样。这种需求导致了系统软件的革新，以支持这种规模的操作，这些系统软件包括BigTable、Colossus、Dynamo、GFS和MapReduce。尽管存在组件故障和安全攻击，它还要求改进运行技术，使所提供的服务至少在99.99%的时间内可用。这些技术的示例包括故障转移、防火墙、虚拟机和防御分布式拒绝服务攻击。有了提供扩展能力的软件和专业知识，再加上日益增长的客户需求证明了投资的合理性，拥有50000到100000台服务器的WSC变得很常见。</p>
</div>
<div class="paragraph">
<p>随着规模的增大，规模经济的好处也日益凸显。2006年的一项研究对比了WSC和仅有1000台服务器的数据中心，根据这一研究，Hamilton[2010]报告了WSC的以下优势。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>存储成本缩减为数据中心的17.7%——WSC的磁盘存储费用为每年4.6美元/GB，而数据中心则为26美元/GB。</p>
</li>
<li>
<p>管理成本缩减为数据中心的14.0%——WSC的服务器与管理员之比超过1000，而数据中心仅为140。</p>
</li>
<li>
<p>联网成本缩减为数据中心的13.7%——WSC的互联网带宽成本为每月l3美元/Mbps，而数据中心为95美元。不难想到，在协商带宽价格时，订购1000Mbps的单位Mbps价格肯定可以远低于订购10Mbps的价格。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>规模经济也体现在采购过程中。大规模的采购可以使WSC中几乎所有东西获得很低的折扣价格。</p>
</div>
<div class="paragraph">
<p>规模经济同样适用于运营成本。许多数据中心的PUE为2.0，大型公司可以雇用机械工程师和电力工程师对WSC进行改进，使其PUE更低，降至1.1到1.2。</p>
</div>
<div class="paragraph">
<p>为了可靠性和降低延迟（特别是对于国际市场），互联网服务需要分布到多个WSC上。由于这一原因，所有大型公司都采用多个WSC。各个公司在世界各地创建多个小型数据中心的成本要远高于在公司总部创建单个数据中心。</p>
</div>
<div class="paragraph">
<p>最后，数据中心中服务器的利用时间往往只有总时间的10%-20%。将WSC推向公众使用之后，不同客户之间的不相关峰值可以将平均利用率提高到50%以上。</p>
</div>
<div class="paragraph">
<p>因此，WSC中的几种组件可以使WSC的规模经济提升5~7倍，而wSC整体又可以使其规模经济额外提升1.5-2倍。</p>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_领域专用体系结构"><a class="link" href="#_领域专用体系结构">9. 领域专用体系结构</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>针对特定领域定制处理器，加速某些应用程序以实现更好的性能与性价比</p>
</div>
<div class="paragraph">
<p>登纳德缩放比例定律的终结远早于摩尔定律。因此，晶体管开关越多，意味着功耗越高。能量预算并没有增加，而且我们已经将单个低效处理器替换为多个高效核。因此，我们已经囊中乏计，无法再继续大幅提升通用体系结构的性价比和能效了。因为能量预算是有限的（原因在于芯片的电迁移、机械和热限制），所以要想提升性能（每秒内执行更多的操作），就需要减少单次操作所消耗的能量。</p>
</div>
<div class="paragraph">
<p>按照一个算术运算指令的开销来计算，对现有处理器核进行微小的调整，可能会得到10%的提升，但如果希望在保持可编程性的同时得到指数级的提升，就需要将每条指令的算术运算操作的数量由1增加到数百。为实现这一级别的效率，就需要对计算机体系结构进行巨大的改变，由通用核变为领域专用体系结构(domain-specific architecture,DSA)。</p>
</div>
<div class="paragraph">
<p>于是，就像在过去10年里，迫不得已由单处理器转向多处理器一样，架构师们现在研究DSA也是因为对过往技术的绝望。现在的新常态是，一台计算机将包含标准处理器和领域专用处理器，其中标准处理器用来运行诸如操作系统之类的传统大型程序，领域专用处理器则仅执行非常有限的一些任务，但其执行效果极好。因此，与过去的同构多核芯片相比，这些计算机的异构性会高得多。</p>
</div>
<div class="paragraph">
<p>过去几十年利用摩尔定律进行的体系结构方面的创新（缓存、乱序执行等）也许并不能很好地与某些领域相匹配（特别是就能量利用而言），因此，可以重新利用这部分资源使芯片更符合领域需求。例如，缓存对于通用体系结构来说是非常出色的，但对于DSA来说就不一定了；有些应用程序的访存模式很容易预测，有些大数据集（比如视频）几乎没有数据重用，对于这些情况，多级缓存技术就显得大材小用了。因此，DSA的前景既包括提升硅的利用率，也包括提升能效，而在今天，后者通常更重要。</p>
</div>
<div class="paragraph">
<p>架构师很可能不会为了一个大型的C++程序（比如SPEC2017基准测试中的某个编译器）开发一个DSA。领城专用算法大多是针对较大系统中的小型计算密集型内核设计的，比如目标识别或语音理解。DSA应当专注于某一个任务子集，而不是准备运行整个程序。此外，改变基准测试的代码不再是违规；对DSA来说，这是一种非常有效的加速方法。于是，对DSA感兴趣的架构师想有所建树的话，必须现在就开始学习相关应用领域及算法。</p>
</div>
<div class="paragraph">
<p>除了拓展专业知识，领域专用架构师面对的另一个挑战是找到一个合适的目标领域，其需求大到有必要在一个SOC上为其分配专门的资源，甚至是专门研发一种定制芯片。定制芯片及其配套软件的非重复性工程（nonrecuring engincering,NRE）成本要分摊到生产的所有芯片上，因此，如果你只需要1000个芯片，那么成本将非常高。</p>
</div>
<div class="paragraph">
<p>对于小体量的应用程序，一种应对方法是使用可重配置的芯片，比如FPGA，这是因为它们的NRE成本低于定制芯片，而且几种不同的应用可以重复利用同一个可重配置的硬件，从而分摊其成本。然而，由于这种硬件的效率低于定制芯片，所以由FPGA得到的收益有限。</p>
</div>
<div class="paragraph">
<p>DSA的另一个挑战是软件移植。人们熟悉的编程环境（比如C++编程语言和编译器）很少能在 DSA上直接使用。</p>
</div>
<div class="sect2">
<h3 id="_dsa指导原则"><a class="link" href="#_dsa指导原则">9.1. DSA指导原则</a></h3>
<div class="paragraph">
<p>下面介绍DSA设计的5条基本原则，后文所说的4种DSA设计就是以这5条原则为指导的。遵循这5条基本原则不仅可以提高面积效率和能效，还有两个好处。第一，它们可以简化设计，从而降低 DSA的NRE成本。第二，对于DSA中常见的面向用户的应用程序来说，相较于传统处理器采用的时变性能优化方法，遵循这些基本原则的加速器可以更好地满足第99百分位响应时间期限。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>使用专用存储器将数据移动距离缩至最短。通用微处理器中的多级缓存使用了大量的硅面积和能量，试图以最佳方式为程序移动数据。例如，一个两路组相联缓存使用的能量是与之等价的软件控制便笺式存储器的2.5倍。当然。DSA的编译器编写者和程序员对其领域有着深刻的理解，所以不需要硬件来为他们移动数据。而是利用专门为该领域内的特定功能所定制的软件控制存储器来减少数据移动。</p>
</li>
<li>
<p>将通过减少微体系结构高级优化措施所节省的资源，投入到更多的算术运算单元或更大的存储器中。架构师们将摩尔定律带来的好处转化为针对CPU和GPU的资源密集型优化（乱序执行、多线程、多重处理、预取、地址接合，等等）。鉴于架构师对这些领域中的程序执行有深刻的理解，这些资源最好投入到更多的处理单元或者更大的片上存储上。</p>
</li>
<li>
<p>使用与该领域相匹配的最简并行形式。DSA的目标领城几乎总是有内在的并行性。所以一个DSA的关键决策就是如何充分利用其并行性，以及如何向软件展现这一特性。要围绕该领域固有的并行粒度来设计DSA，并在编程模型中简单地展现这一并行性。例如，就数据级并行而言，如果SIMD在该领域就够用了，那么对程序员和编译器编写者来说，它当然要比MIMD更容易。同样，如果VLIW可以表达该领域的指令级并行，那么与乱序执行相比，其设计规模可以更小，能效可以更高。</p>
</li>
<li>
<p>缩小数据规模，减少数据类型，使之能满足该领域最低需求即可。许多领域中的应用程序通常都是受存储器限制的，所以可以利用更小位宽的数据类型来提高有效存储带宽和片上存储利用率。更短小、更简单的数据还允许你在同样的芯片面积上放置更多的算术运算单元。</p>
</li>
<li>
<p>使用一种领域专用编程语言将代码移植到 DSA。DSA的一个经典难题是让应用程序在你的新体系结构上运行。一个长期存在的谬误是，假定你的新计算机非常有吸引力，以至于程序员们为了你的硬件而重写自己的代码。所幸，在架构师被迫将注意力转移到DSA之前，领域专用编程语言就已经流行起来。用于视觉处理的Halide和用于DNN的TensorFlow[Ragan-Kelley等，2013；Abadi等，2016]都是这方面的例子。这些语言大幅提高了向DSA移植应用程序的可行性。如前所述，在某些领域，应用程序中只有一些涉及大量计算的部分需要在DSA上运行，这也简化了代码移植。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>下表说明了这四种DSA是如何遵守这些指导原则的。</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">指导原则</th>
<th class="tableblock halign-left valign-top">TPU</th>
<th class="tableblock halign-left valign-top">Catapult</th>
<th class="tableblock halign-left valign-top">Crest</th>
<th class="tableblock halign-left valign-top">Pixel Visual Core</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">设计目标</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">数据中心 ASIC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">数据中心 FPGA</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">数据中心 ASIC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PMD ASIC/SOC IP</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1. 专用存储器</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">24 MiB 统一缓冲区，4 MiB 累加器</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">可变</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">无</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">每个核：128 KiB 行缓冲区，64 KiB P.E. 存储器</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2. 更大的算术运算单元</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">65,536 个乘法累加器</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">可变</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">无</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">每个核：256 个乘法累加器（512 个 ALU）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">3. 简单的并行机制</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">单线程，SIMD，顺序</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">SIMD, MISD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">无</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">MPMD, SIMD, VLIW</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">4. 更大的数据规模</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8 位、16 位整数</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8 位、16 位整数，32 位浮点数</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">21 位浮点数</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8 位、16 位、32 位整数</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">5. 领域专用语言</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TensorFlow</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Verilog</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TensorFlow</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Halide/TensorFlow</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_示例领域深度神经网络"><a class="link" href="#_示例领域深度神经网络">9.2. 示例领域：深度神经网络</a></h3>
<div class="paragraph">
<p>深度神经网络（Deep Neural Network, DNN）是人工神经网络的一种扩展形式，通过增加网络的层数和复杂度以实现对复杂数据特征的自动提取和学习。它是深度学习的核心技术，广泛应用于语音识别、图像处理、自然语言处理和推荐系统等领域。</p>
</div>
<div class="paragraph">
<p>深度神经网络由多层神经元组成，包括输入层、隐藏层和输出层。输入层负责接收原始数据，隐藏层通过逐层抽象和计算提取数据的高阶特征，输出层则生成预测结果或分类标签。隐藏层是DNN的核心，它由多个非线性激活函数、权重矩阵和偏置组成，通过优化训练获得表示能力。</p>
</div>
<div class="paragraph">
<p>DNN的特点是其深度结构和强大的特征学习能力。相比于传统的浅层网络，深度神经网络能够在隐藏层中捕获数据的复杂模式和高维特征，减少对手工设计特征的依赖。同时，通过使用反向传播算法，DNN能够有效地优化权重和偏置参数，从而提升模型性能。</p>
</div>
<div class="paragraph">
<p>DNN的训练过程通常需要大量标注数据和计算资源。通过前向传播计算网络输出，再通过反向传播计算误差和梯度，更新权重。优化器（如SGD或Adam）用于加速训练过程。为了解决深层网络容易出现的梯度消失或梯度爆炸问题，通常采用规范化技术（如批量归一化）和特殊激活函数（如ReLU）。</p>
</div>
<div class="paragraph">
<p>深度神经网络的成功得益于三大关键因素：大规模数据、强大的计算能力（如GPU、TPU）以及高效的训练算法。虽然DNN具有很高的表达能力，但其也面临着一些挑战，如模型过于复杂可能导致过拟合、训练时间较长、对高质量数据的依赖等。</p>
</div>
<div class="sect3">
<h4 id="_dnn的神经元"><a class="link" href="#_dnn的神经元">9.2.1. DNN的神经元</a></h4>
<div class="paragraph">
<p>深度神经网络（DNN）中的神经元是其基本构建单元，模拟生物神经元的行为，用于接收输入信号、执行计算并产生输出。每个神经元通过简单的数学运算将输入映射为输出，进而通过多层的连接构建起整个网络的计算能力。</p>
</div>
<div class="paragraph">
<p>一个神经元的主要组成部分包括输入、权重、偏置、激活函数和输出：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>输入：神经元从前一层的神经元接收输入数据，这些输入可能是原始数据特征或前一层的计算结果。每个输入与相应的权重配对。</p>
</li>
<li>
<p>权重：权重是神经元学习的核心参数，用于衡量输入的相对重要性。在训练过程中，通过优化算法（如梯度下降）调整权重以最小化预测误差。</p>
</li>
<li>
<p>偏置：偏置是一个额外的参数，与输入无关，能够调整激活函数的输出范围，确保网络对不同输入数据具有更好的拟合能力。</p>
</li>
<li>
<p>加权和计算：神经元对所有输入进行加权求和，并加入偏置，计算公式为：</p>
<div class="stemblock">
<div class="content">
\[z = \sum_{i=1}^n w_i x_i + b

，其中x_i是第i个输入，w_i是对应的权重，b是偏置。\]
</div>
</div>
</li>
<li>
<p>激活函数：激活函数对加权和结果 \(z\) 进行非线性变换，产生神经元的输出。常见的激活函数包括：</p>
<div class="ulist">
<ul>
<li>
<p>ReLU（修正线性单元）：\(\text{ReLU}(z) = \max(0, z)\)</p>
</li>
<li>
<p>Sigmoid：\(\sigma(z) = \frac{1}{1 + e^{-z}}\)</p>
</li>
<li>
<p>Tanh：\(\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}\)</p>
<div class="literalblock">
<div class="content">
<pre>激活函数的非线性特性使得神经网络能够表示复杂的非线性关系，提高网络的表达能力。</pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>输出：激活函数的结果作为神经元的输出，传递到下一层神经元。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>在DNN中，大量神经元通过层与层之间的连接形成复杂的网络结构。每一层的神经元共同处理上一层的输出，并将计算结果传递给下一层，从而逐步提取数据的特征。神经元的数量和激活函数的选择对网络性能有显著影响。</p>
</div>
<div class="paragraph">
<p>通过反向传播算法，神经元的权重和偏置会根据损失函数的梯度逐步调整，从而使网络能够学习到输入数据的特征模式并完成预测或分类任务。神经元的设计与优化是DNN训练和推理性能的关键。</p>
</div>
</div>
<div class="sect3">
<h4 id="_训练与推理"><a class="link" href="#_训练与推理">9.2.2. 训练与推理</a></h4>
<div class="paragraph">
<p>深度神经网络（DNN）的训练与推理是其实现功能的两个核心过程，分别对应于模型的学习阶段和实际应用阶段。以下是对这两个过程的详细介绍：</p>
</div>
<div class="paragraph">
<p>DNN的训练
训练是DNN学习数据特征并优化模型参数的过程，主要包括以下几个关键步骤：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>前向传播：在训练过程中，输入数据通过神经网络逐层传递，依次经过每一层的加权求和、偏置加和、激活函数处理，最后生成输出（预测值）。这一过程称为前向传播，用于计算模型的输出和与目标值之间的误差。</p>
</li>
<li>
<p>计算损失函数：损失函数用于衡量模型预测值与真实值之间的差距。例如，分类任务中常用交叉熵损失函数，回归任务中常用均方误差（MSE）。损失函数的值越小，说明模型的预测性能越好。</p>
</li>
<li>
<p>反向传播：反向传播通过链式法则计算损失函数对模型中所有可训练参数（权重和偏置）的梯度。从输出层开始，逐层向输入层回溯，通过求导计算每一层参数对损失的影响。反向传播是训练阶段的重要步骤，它将误差信号传播到整个网络以指导参数的调整。</p>
</li>
<li>
<p>参数更新：在获得梯度后，利用优化算法（如随机梯度下降SGD、Adam、RMSProp等）更新权重和偏置。优化算法根据学习率调整参数，使得模型的损失逐渐减小，网络逐渐逼近全局或局部最优解。</p>
</li>
<li>
<p>迭代训练：上述过程会在多个训练样本上反复进行，通常分为多个epoch（一个epoch表示整个训练集被网络完整训练一次）。通过多次迭代，模型逐步学习数据特征并提高性能。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>训练过程的目标是通过反复优化使网络的权重和偏置达到能够有效捕捉数据分布和特征的状态，从而使网络能够泛化到未见过的测试数据。</p>
</div>
<div class="paragraph">
<p>DNN的推理
推理是DNN在训练完成后应用于实际任务的过程，主要用于对新数据进行预测。推理过程相对简单，与训练阶段的前向传播类似，但不涉及梯度计算和参数更新。其主要步骤包括：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>输入数据预处理：在推理阶段，将实际输入数据按照训练时相同的方式进行预处理，例如归一化、标准化或图像缩放，以确保数据分布一致。</p>
</li>
<li>
<p>前向传播计算：输入数据经过神经网络逐层传递，网络的权重和偏置保持不变，最终输出预测结果。</p>
</li>
<li>
<p>输出结果：根据网络输出的值，得到分类标签、回归值或其他形式的预测结果。例如，在分类任务中，输出层可能提供每个类别的概率值，然后选取概率最高的类别作为预测结果。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>推理过程的效率取决于网络的复杂性（如层数、参数量）和硬件性能。在实际应用中，推理阶段通常运行在高效的硬件（如GPU、TPU或专用加速器）上，以满足实时性需求。</p>
</div>
</div>
<div class="sect3">
<h4 id="_多层感知机"><a class="link" href="#_多层感知机">9.2.3. 多层感知机</a></h4>
<div class="paragraph">
<p>多层感知机（MLP，Multilayer Perceptron）是深度神经网络（DNN）的基础结构之一，也是最早发展起来的一种前馈神经网络。它由输入层、一个或多个隐藏层以及输出层组成，各层神经元之间全连接，但层内没有连接。MLP主要用于解决非线性问题，是深度学习中广泛使用的模型。以下是多层感知机的详细介绍：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>基本结构</p>
<div class="paragraph">
<p>多层感知机由多个相互堆叠的全连接层构成，每一层的输出作为下一层的输入。它包含以下几部分：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>输入层：输入层的神经元个数由输入数据的特征维度决定，例如输入是一个向量，则输入层神经元个数等于向量的维度。</p>
</li>
<li>
<p>隐藏层：隐藏层是多层感知机的核心部分，可以有一个或多个隐藏层。每一层神经元通过加权求和（权重和偏置）处理输入数据，并通过激活函数引入非线性。隐藏层的数量和每层的神经元个数是模型设计的超参数，需要根据任务复杂度和数据特性进行调整。</p>
</li>
<li>
<p>输出层：输出层的神经元个数取决于具体的任务。例如，在分类问题中，输出层神经元的数量等于类别数；在回归问题中，输出层通常只有一个神经元。输出层的激活函数通常与任务类型相关，例如分类任务常用softmax或sigmoid函数，而回归任务常用线性激活函数。</p>
</li>
</ul>
</div>
</li>
<li>
<p>工作原理</p>
<div class="paragraph">
<p>多层感知机通过前向传播和反向传播实现输入到输出的映射，并通过训练调整参数以最小化预测误差。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>前向传播：输入数据从输入层开始，逐层通过隐藏层计算，直到输出层生成结果。每个神经元的输出是输入的加权和加上偏置，再通过激活函数引入非线性。</p>
</li>
<li>
<p>反向传播：通过损失函数计算输出结果与真实值之间的误差，然后利用梯度下降算法（如SGD、Adam）通过链式法则计算误差对每一层参数的梯度，逐层更新权重和偏置以减少误差。</p>
</li>
</ul>
</div>
</li>
<li>
<p>激活函数的作用</p>
<div class="paragraph">
<p>隐藏层中的激活函数是多层感知机引入非线性的关键，它使得模型能够拟合复杂的非线性关系。如果没有激活函数，MLP只能表示线性映射，无法解决复杂的实际问题。常用的激活函数包括：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Sigmoid：将输出压缩到 (0, 1) 范围内，适用于概率预测，但在深层网络中可能导致梯度消失问题。</p>
</li>
<li>
<p>ReLU（Rectified Linear Unit）：将负值输出为0，正值保持不变，解决了梯度消失问题，是现代深度学习中最常用的激活函数之一。</p>
</li>
<li>
<p>Tanh：将输出压缩到 (-1, 1) 范围内，收敛速度比Sigmoid更快，但仍可能存在梯度消失问题。</p>
</li>
</ul>
</div>
</li>
<li>
<p>MLP的特点</p>
<div class="ulist">
<ul>
<li>
<p>全连接结构：多层感知机中的每一层神经元与下一层神经元全连接，使其具有较强的特征表达能力。</p>
</li>
<li>
<p>非线性映射：通过激活函数，MLP能够学习输入和输出之间的复杂非线性关系。</p>
</li>
<li>
<p>参数数量多：由于每层神经元全连接，MLP的参数量较多，容易导致计算开销大和过拟合问题。</p>
</li>
</ul>
</div>
</li>
<li>
<p>应用场景</p>
<div class="paragraph">
<p>多层感知机是DNN最基本的形式，适用于多种任务，包括：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>分类：用于图像、文本或其他形式数据的分类任务，例如手写数字识别。</p>
</li>
<li>
<p>回归：在预测连续值的任务中（如房价预测），MLP也能表现出色。</p>
</li>
<li>
<p>特征学习：可以用作其他复杂网络的基础层，通过学习数据的高维特征表示。</p>
</li>
</ul>
</div>
</li>
<li>
<p>局限性</p>
<div class="paragraph">
<p>尽管多层感知机是DNN的重要组成部分，但它也存在一些局限性：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>不适合处理高维数据：例如图像数据，直接使用MLP会导致参数量过大，因此更适合卷积神经网络（CNN）。</p>
</li>
<li>
<p>全连接导致计算冗余：所有神经元之间的连接可能会造成资源浪费和冗余计算。</p>
</li>
<li>
<p>对时序数据支持不足：在处理时间序列数据时，MLP无法捕获时间上的依赖关系，因此通常使用循环神经网络（RNN）或Transformer模型。</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_批数据"><a class="link" href="#_批数据">9.2.4. 批数据</a></h4>
<div class="paragraph">
<p>批数据是指在深度神经网络训练和推理过程中，将一组输入数据同时送入网络进行计算的方法。它通过批量处理多个样本来有效利用硬件的并行计算能力，提升训练效率，稳定梯度更新，并改善模型性能。在训练过程中，批数据的核心思想是将训练数据划分为多个小批次，每次使用一个批次的数据进行前向传播和反向传播。批数据方法是小批量梯度下降的重要实现方式，每个批次的数据量称为批大小，通常为2的幂，如32、64、128等，便于硬件高效计算。通过批量梯度下降，每个批次的数据用于计算损失函数和梯度，再用于更新模型参数。</p>
</div>
<div class="paragraph">
<p>批数据在深度神经网络中的作用主要体现在几个方面。它能够充分利用硬件（如GPU或TPU）的并行计算能力，加速矩阵运算（例如前向传播和反向传播中的加权求和和激活函数计算），显著提高计算效率。同时，相较于单样本更新的随机梯度下降，使用批数据能够减小梯度更新的随机性，使梯度估计更加平稳，有助于更快收敛。批数据还能减少内存开销，与全量梯度下降需要一次加载所有样本不同，批处理方法通过小批量迭代计算降低了对内存的需求。此外，批数据也能一定程度上避免过拟合，因为每次训练只用部分数据，模型不会完全依赖整个训练数据集。</p>
</div>
<div class="paragraph">
<p>批大小是批数据的关键参数，直接影响训练过程的效率和效果。小批大小（如16或32）更新频繁，计算更加精细，但可能会引入更多噪声，导致收敛速度变慢甚至不稳定，适合小型数据集或硬件资源有限的情况。大批大小（如256或更大）能提高计算效率，梯度估计更加准确，但可能导致模型陷入局部最优，适合大型数据集和资源充足的硬件场景。极端情况下，当批大小为1时，相当于随机梯度下降；当批大小等于数据集大小时，则为全量梯度下降。</p>
</div>
<div class="paragraph">
<p>在训练过程中，批数据的处理主要包括数据集划分、前向传播、损失计算、反向传播和参数更新。整个数据集被划分为若干批次，每个批次依次输入模型进行计算，得到预测结果并计算损失值，再通过反向传播计算梯度，用优化算法更新模型参数。批数据不仅在训练阶段具有重要作用，在推理阶段也能显著提升计算效率。在推理过程中，批处理的样本数根据硬件能力和任务需求选择合适的大小，例如在GPU上利用批数据可以最大化硬件利用率，减少推理时间；而对于实时性要求较高的任务，可能需要逐个样本推理。</p>
</div>
<div class="paragraph">
<p>总体而言，批数据是深度神经网络训练和推理中的重要概念，通过划分小批量样本实现了计算效率和训练效果的平衡。适当选择批大小能够最大化硬件资源利用率，同时优化模型的性能和稳定性，在深度学习的实际应用中发挥着重要作用。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_google的张量处理单元一种数据中心推理加速器"><a class="link" href="#_google的张量处理单元一种数据中心推理加速器">9.3. Google的张量处理单元——一种数据中心推理加速器</a></h3>
<div class="sect3">
<h4 id="_tpu的概念"><a class="link" href="#_tpu的概念">9.3.1. TPU的概念</a></h4>
<div class="paragraph">
<p>TPU（Tensor Processing Unit）是一种专为加速深度学习任务而设计的专用硬件加速器，由谷歌（Google）开发。它是一个面向人工智能和机器学习，特别是深度神经网络模型计算的专用集成电路（ASIC）。TPU的设计初衷是满足高性能计算需求，优化深度学习中大规模矩阵运算（如张量运算），以提高效率并降低能耗。相比于传统的CPU和GPU，TPU专注于为机器学习框架（如TensorFlow）提供高效支持。</p>
</div>
<div class="paragraph">
<p>TPU的特点主要体现在以下几个方面：首先，TPU以矩阵运算为核心，集成了大量专门用于矩阵乘法和累加的硬件单元，能够极大地提升张量运算的速度，是深度学习模型计算的核心。其次，TPU采用低精度计算单元（如8位整数或16位浮点数），从而在计算效率和内存带宽之间达到平衡，满足深度学习对大规模数据处理的需求，同时降低功耗。TPU的硬件架构简单，去除了许多通用处理器中的复杂控制逻辑和缓存系统，从而进一步提升了性能，并显著降低了硬件设计的成本和复杂度。此外，TPU还支持强大的并行计算能力，通过内置大量计算单元实现大规模并行运算，能够高效处理深度神经网络的训练和推理任务。</p>
</div>
<div class="paragraph">
<p>TPU的用途集中在深度学习任务中，广泛应用于训练和推理阶段。训练阶段中，TPU能够大幅度加速深度学习模型的优化过程，特别是在需要处理海量数据和复杂网络结构的场景下表现尤为突出，例如自然语言处理（NLP）、计算机视觉、语音识别和推荐系统等领域。推理阶段中，TPU可以在低延迟和高效率的前提下部署模型，用于实时任务或大规模数据处理，如搜索引擎优化、自动翻译、语音助手和视频推荐等应用。此外，TPU作为谷歌云服务的重要组成部分，还为开发者提供了广泛的云计算支持，使用户可以通过谷歌云平台高效运行机器学习任务，降低硬件门槛。</p>
</div>
</div>
<div class="sect3">
<h4 id="_tpu体系结构"><a class="link" href="#_tpu体系结构">9.3.2. TPU体系结构</a></h4>
<div class="paragraph">
<p>TPU（Tensor Processing Unit）的体系结构是一种专为深度学习设计的高效硬件架构，它通过简化的控制逻辑、高度并行化的计算单元和优化的数据流设计，为深度神经网络（DNN）计算提供了高性能支持。TPU的架构紧密围绕深度学习的核心需求，特别是矩阵运算（如张量计算），并在计算密集型任务中表现出色。</p>
</div>
<div class="paragraph">
<p>TPU的核心组件是其矩阵乘法单元（Matrix Multiply Unit，MXU），这是一种专门用于处理矩阵乘法的硬件单元。在第一代TPU中，MXU是一个支持 256×256 大小矩阵运算的单元，它能够高效执行大规模矩阵乘法和累加操作（如卷积运算），这是深度学习模型训练和推理的核心操作。通过高度优化的MXU，TPU实现了大规模并行计算，显著提升了深度学习的性能。</p>
</div>
<div class="paragraph">
<p>TPU架构中使用了低精度计算单元，例如8位整数（INT8）或16位浮点数（bfloat16），以减少计算复杂度和内存带宽需求，同时仍然满足神经网络模型的计算精度需求。这种低精度运算能够在不显著影响模型性能的情况下，大幅度提升计算速度和能效。</p>
</div>
<div class="paragraph">
<p>在数据存储方面，TPU引入了专用的高带宽存储器（如SRAM），称为“统一缓冲区”（Unified Buffer）。这个存储器用于缓存模型参数和中间数据，从而最大限度地减少与外部内存之间的数据传输开销。TPU还配备了片上内存（On-Chip Memory），用于支持高效的数据复用，并进一步优化数据流。通过这种设计，TPU能够以更高的效率处理深度学习的海量数据需求。</p>
</div>
<div class="paragraph">
<p>TPU的指令集相对简单，去除了传统处理器中的复杂控制逻辑。它采用了一种数据流驱动的计算模式，极大地减少了指令调度和控制的复杂性。这种架构设计能够更好地支持深度学习任务中规则化和高度并行的计算模式。</p>
</div>
<div class="paragraph">
<p>在输入输出（I/O）方面，TPU通过高速互连网络与其他硬件模块进行通信，以实现多个TPU之间的协同工作。这种设计特别适合分布式深度学习任务，例如需要多节点并行计算的大规模模型训练。</p>
</div>
<div class="paragraph">
<p>TPU的体系结构还具有模块化设计，便于扩展以支持更复杂的深度学习任务。谷歌在后续的TPU版本（如TPU v2和v3）中引入了更多的计算核心、更大的内存带宽以及液冷系统，以满足更高性能的需求。这些版本还支持分布式计算架构，可以将多个TPU组装为一个“TPU Pod”，从而实现超大规模的深度学习训练。</p>
</div>
</div>
<div class="sect3">
<h4 id="_tpu指令集体系结构"><a class="link" href="#_tpu指令集体系结构">9.3.3. TPU指令集体系结构</a></h4>
<div class="paragraph">
<p>TPU指令集围绕矩阵运算展开，其核心是支持大规模的矩阵乘法与累加（Matrix Multiply-Accumulate, MAC）。矩阵乘法是神经网络中的基础操作，例如卷积层、全连接层等都依赖矩阵乘法进行计算。TPU指令集直接为这些操作提供了硬件支持，通过特定的指令来触发矩阵计算单元（MXU）的运算。这种专用指令避免了传统处理器中复杂的指令解码过程，极大提高了执行效率。</p>
</div>
<div class="paragraph">
<p>指令集支持低精度数据类型，例如8位整数（INT8）或16位浮点数（bfloat16）。低精度运算是深度学习领域常见的优化手段，用于减少计算开销和存储带宽，同时保证计算精度满足实际需求。TPU指令集为低精度数据提供了原生支持，从硬件层面上提升了性能与能效比。</p>
</div>
<div class="paragraph">
<p>TPU的指令集采用简化控制逻辑，其设计目标是优化数据流计算，而不是传统处理器那样强调复杂的控制流操作。它通过专用指令控制数据从片外内存到片上存储的传输，以及数据在片上计算单元之间的流动。这种设计符合深度学习任务中数据流计算的特点，显著减少了控制开销。</p>
</div>
<div class="paragraph">
<p>TPU指令集中的加载与存储指令（Load/Store Instructions）主要用于控制数据的读写操作。TPU片上有统一缓冲区（Unified Buffer）作为高带宽存储，用于缓存神经网络的权重参数和中间计算结果。指令集可以高效管理数据在统一缓冲区和外部存储之间的传输，确保计算单元能够快速获得所需数据。</p>
</div>
<div class="paragraph">
<p>TPU指令集还包含用于数据预处理与激活函数的指令。例如，指令集中可能会提供用于计算ReLU、Sigmoid、Softmax等常见激活函数的支持，这些操作可以直接在硬件中高效执行，而不需要像传统处理器那样依赖软件实现。</p>
</div>
<div class="paragraph">
<p>为了支持高并行计算，TPU指令集采用向量化或SIMD（Single Instruction, Multiple Data）方式。一条指令可以同时作用于多个数据元素，从而实现大规模并行计算。这种设计非常适合深度学习中大批量数据的处理需求，能够显著提高计算吞吐量。</p>
</div>
<div class="paragraph">
<p>TPU指令集的编程接口通常是通过高层次的深度学习框架（如TensorFlow）进行访问的。开发者无需直接编写低级别的指令，而是通过框架中的高阶API描述神经网络模型，框架会自动将这些高层描述转换为TPU的指令集操作。这种设计极大降低了开发者的使用门槛，同时保证了硬件资源的高效利用。</p>
</div>
</div>
<div class="sect3">
<h4 id="_tpu微体系结构"><a class="link" href="#_tpu微体系结构">9.3.4. TPU微体系结构</a></h4>
<div class="paragraph">
<p>TPU微体系结构的核心组件是矩阵乘法单元（MXU，Matrix Multiply Unit），它专门用于高效执行神经网络中的矩阵乘法操作。MXU是一个高度并行的计算单元，能够同时处理大量的乘法累加操作（Multiply-Accumulate, MAC）。在典型的TPU设计中，MXU可以执行以千为单位的MAC操作，从而显著加速神经网络中的卷积计算和全连接层操作。MXU的定制设计使其能够高效利用芯片面积和能量，同时保证低延迟和高吞吐量。</p>
</div>
<div class="paragraph">
<p>为了支持深度学习模型的参数和中间结果存储，TPU微体系结构包含一个统一缓冲区（Unified Buffer, UB）。统一缓冲区是一个高带宽、低延迟的片上存储，用于缓存权重、激活值和其他中间数据。它与MXU紧密集成，减少了对外部存储的依赖，从而降低了数据传输的延迟和能耗。统一缓冲区的大小经过精心设计，可以容纳神经网络计算中经常访问的数据，避免频繁的数据加载。</p>
</div>
<div class="paragraph">
<p>TPU微体系结构采用了流水线化设计，将数据流计算划分为多个阶段。每个阶段负责一个特定的任务，例如数据加载、权重解码、矩阵计算和结果写回。流水线设计的优势在于能够同时处理多个任务，从而提高计算单元的利用率和整体吞吐量。此外，流水线还可以缓解数据传输瓶颈，使计算与内存访问的效率更加均衡。</p>
</div>
<div class="paragraph">
<p>TPU微体系结构使用专用的数据加载和存储单元（Load/Store Units, LSU），负责将数据从片外内存加载到片上统一缓冲区，或者将计算结果写回片外内存。这些单元优化了数据的传输路径和带宽利用率，支持高效的流式计算。通过硬件预取和数据排布优化，LSU可以减少存储访问的延迟，并为计算单元提供持续的高带宽数据流。</p>
</div>
<div class="paragraph">
<p>TPU微体系结构还集成了激活函数和数据预处理单元，用于执行神经网络中的非线性操作（如ReLU、Sigmoid、Softmax）和数据变换（如归一化、量化等）。这些操作通常是神经网络模型中的重要组成部分，TPU通过硬件加速器为它们提供了高效支持，从而避免了通用处理器中依赖软件实现的开销。</p>
</div>
<div class="paragraph">
<p>为了支持深度学习任务中的并行性，TPU微体系结构采用大规模并行计算的策略。通过在硬件层面支持SIMD（Single Instruction, Multiple Data）和张量操作，TPU能够同时处理多个数据元素，极大地提升了计算效率。此外，TPU的设计还允许多个核心协同工作，以实现更高的性能和扩展性。</p>
</div>
<div class="paragraph">
<p>TPU的微体系结构针对深度学习中的低精度计算进行了优化，例如支持bfloat16（16位浮点数）和INT8（8位整数）数据类型。低精度计算可以显著降低数据存储需求和计算开销，同时满足深度学习应用对精度的要求。TPU通过专用硬件实现对低精度运算的支持，进一步提升了计算的能效比。</p>
</div>
<div class="paragraph">
<p>最后，TPU微体系结构通过专门的硬件控制单元（如调度器和执行单元）实现了对指令流和数据流的高效管理。这些控制单元负责调度计算任务、协调数据传输和管理流水线操作，确保各个硬件模块之间的高效协同工作。</p>
</div>
</div>
<div class="sect3">
<h4 id="_tpu实现"><a class="link" href="#_tpu实现">9.3.5. TPU实现</a></h4>
<div class="paragraph">
<p>TPU的核心实现原理基于矩阵乘法加速。在深度学习中，大量的计算来自于神经网络层的矩阵乘法操作（如全连接层和卷积层的计算）。TPU专门为这些操作设计了一个大规模的矩阵运算单元（Matrix Multiply Unit, MXU），它能够以极高的并行性和效率同时处理数千个乘法累加运算（MAC，Multiply-Accumulate）。这种硬件的高度定制化使得TPU在矩阵运算上的性能远超通用处理器和GPU。</p>
</div>
<div class="paragraph">
<p>为了实现高效的数据访问和存储，TPU采用了片上存储（On-Chip Memory）和数据流架构（Dataflow Architecture）的组合。TPU的片上存储主要包括统一缓冲区（Unified Buffer），它被用来存储神经网络的权重、输入激活值和中间结果。由于片上存储比片外存储具有更低的访问延迟和更高的带宽，TPU尽可能将经常使用的数据保存在片上缓冲区中，从而减少了片外内存的访问需求。数据流架构通过硬件设计直接管理数据在芯片内部的传输路径，避免了不必要的数据搬移，从而进一步提高了效率。</p>
</div>
<div class="paragraph">
<p>TPU的实现还通过流水线化设计（Pipelining）来优化数据流和计算流程。TPU将神经网络计算过程分解为多个流水线阶段，每个阶段专注于一个特定的子任务，例如数据加载、权重解码、矩阵运算和结果写回。流水线设计允许多个计算任务同时在不同的阶段中进行，极大地提高了芯片的资源利用率和吞吐量。</p>
</div>
<div class="paragraph">
<p>在数据表示和计算方面，TPU采用了低精度数据类型优化的原理。与传统的32位浮点运算相比，TPU支持更低精度的计算数据格式，例如bfloat16（16位浮点数）和INT8（8位整数）。这些数据类型能够显著减少计算和存储的资源消耗，同时保持神经网络模型的计算精度。TPU通过硬件支持低精度运算，进一步提升了单位功耗的计算性能（即能效）。</p>
</div>
<div class="paragraph">
<p>TPU的另一个实现关键是指令流和数据流的高效控制。在传统处理器中，指令流的执行通常需要复杂的控制逻辑，而TPU通过硬件设计简化了控制逻辑，重点优化了数据流。TPU的硬件调度器直接管理数据的加载、存储和运算任务，确保每个硬件单元始终处于高效工作状态。这种优化减少了指令调度和任务切换的开销。</p>
</div>
<div class="paragraph">
<p>为了支持规模化计算，TPU通过硬件架构实现了大规模并行处理。在硬件层面，TPU设计了大量的并行计算单元，这些单元能够同时处理多个神经网络层的计算任务。在系统级别，TPU还支持多芯片协作，通过多个TPU设备组成计算集群，共同完成大型深度学习模型的训练和推理任务。</p>
</div>
<div class="paragraph">
<p>TPU的实现还特别注重能效比优化。相比于通用处理器和GPU，TPU通过减少不必要的硬件功能（如分支预测、复杂的缓存层次）以及高度专用化的设计，将更多的芯片资源用于深度学习计算本身，从而显著提高了单位能耗下的计算性能。</p>
</div>
<div class="paragraph">
<p>最后，TPU的实现原理还依赖于软硬件协同设计。谷歌开发了专门的编译器和框架（如TensorFlow），用于优化神经网络模型在TPU上的运行。这些工具能够将高层的神经网络模型转换为TPU指令，并为硬件执行生成高效的任务调度和数据流图，使TPU硬件的计算潜力得到最大化的发挥。</p>
</div>
</div>
<div class="sect3">
<h4 id="_tpu软件"><a class="link" href="#_tpu软件">9.3.6. TPU软件</a></h4>
<div class="paragraph">
<p>TPU最常用的软件是TensorFlow，它是谷歌开发的一种广泛使用的开源深度学习框架。TensorFlow为TPU提供了深度优化的运行支持，开发者可以通过编写TensorFlow代码无缝地在TPU上运行模型。TensorFlow的TPU支持通过专门的API（如tf.distribute.TPUStrategy）提供分布式训练能力，使用户能够轻松将单机模型扩展到多TPU节点的训练。此外，TensorFlow还包含许多针对TPU的优化功能，例如自动分配计算任务、调整数据流和优化内存管理，使得模型的执行能够充分利用TPU的硬件性能。</p>
</div>
<div class="paragraph">
<p>为了简化TPU的使用，谷歌还开发了TPU运行时（TPU Runtime），这是一个为TPU设计的底层运行环境。TPU运行时负责管理硬件资源，执行低级硬件指令，以及在TPU硬件和高层编程框架之间提供接口。它确保TensorFlow或其他框架生成的任务能够高效地映射到TPU硬件上，并负责优化任务调度和数据传输。</p>
</div>
<div class="paragraph">
<p>针对大规模的模型训练和推理任务，谷歌还提供了Cloud TPU，这是一种基于TPU的云服务。Cloud TPU集成了谷歌云平台（Google Cloud Platform, GCP）的功能，用户可以通过GCP访问TPU资源，并通过TensorFlow或JAX运行深度学习模型。Cloud TPU支持自动化的集群管理和任务分发，使得开发者能够快速部署和扩展大规模的深度学习训练任务。</p>
</div>
<div class="paragraph">
<p>JAX是另一个支持TPU的高性能计算库，它主要用于科学计算和深度学习模型的开发。JAX以其灵活的自动微分和硬件加速能力著称，开发者可以使用JAX轻松实现复杂的数学模型和神经网络架构。在TPU上，JAX通过其后端支持快速矩阵运算和分布式计算，适合需要高度自定义和优化的深度学习任务。</p>
</div>
<div class="paragraph">
<p>除了TensorFlow和JAX，谷歌还推出了PyTorch/XLA，这是一个为TPU设计的PyTorch扩展。PyTorch/XLA使得开发者可以使用PyTorch框架在TPU上运行模型，同时享受PyTorch的灵活性和动态计算图的特性。PyTorch/XLA将PyTorch代码自动转换为TPU硬件指令，并对模型训练过程进行优化，例如数据分片、梯度计算和模型参数更新。</p>
</div>
<div class="paragraph">
<p>在工具链方面，谷歌提供了TPU性能分析工具（TPU Profiler），这是一个用于调试和优化TPU程序的性能监控工具。TPU Profiler可以帮助开发者识别性能瓶颈，例如模型的计算、通信或内存使用中的问题，并提供建议以改进模型性能。</p>
</div>
<div class="paragraph">
<p>此外，为了帮助开发者快速构建和部署深度学习模型，谷歌提供了TensorFlow Model Garden，这是一个集合了许多预训练深度学习模型的库。这些模型经过优化，可以直接运行在TPU上，适合需要快速部署或进行迁移学习的开发者。</p>
</div>
<div class="paragraph">
<p>最后，为了实现不同模型和数据集的快速训练，谷歌还开发了TPUEstimator和TPU训练循环（TPU Training Loop）。TPUEstimator是一种高级API，它简化了模型定义、训练和评估过程，而TPU训练循环提供了更底层的灵活性，允许开发者精确控制训练步骤、梯度计算和参数更新。</p>
</div>
</div>
<div class="sect3">
<h4 id="_改进tpu"><a class="link" href="#_改进tpu">9.3.7. 改进TPU</a></h4>
<div class="paragraph">
<p>TPU（Tensor Processing Unit）作为谷歌为深度学习工作负载设计的专用硬件，不断在架构、性能、效率和适用性等方面进行改进，以满足深度学习领域快速发展的需求。目前TPU的改进方向主要集中在以下几个方面：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>性能提升仍然是TPU改进的核心目标。随着深度学习模型规模的指数级增长（例如GPT系列和更大规模的Transformer模型），TPU需要支持更高的计算能力和吞吐量。未来的TPU改进方向之一是进一步优化矩阵乘法加速器（Matrix Multiply Unit, MMU）的设计，以提升每秒浮点操作次数（FLOPS）。同时，通过更高效的硬件流水线和指令调度机制，减少计算中可能的资源空闲和延迟，从而实现更高效的计算性能。</p>
</li>
<li>
<p>在存储和内存方面，TPU的改进方向集中于提高片上内存（on-chip memory）的容量和带宽。当前深度学习模型对内存的需求越来越高，大量的模型参数和中间激活值需要快速访问。TPU通过增加SRAM容量、改进内存架构和提升片外存储（如HBM高带宽内存）的访问效率，来满足大规模模型的内存需求。此外，为了应对分布式训练中模型和数据并行的需求，TPU还在优化内存共享和数据缓存技术，以进一步减少数据访问延迟和通信开销。</p>
</li>
<li>
<p>能效优化是TPU的重要改进方向之一。随着数据中心规模的扩大和深度学习工作负载的增长，降低能耗成为关键问题。TPU通过优化硬件设计、降低计算单元的功耗、改进动态电源管理（Dynamic Power Management）技术，以及采用更先进的制程工艺（如5nm、3nm技术），在提供更高计算性能的同时显著降低能耗。未来TPU还将结合定制化低功耗电路设计和高效的散热技术来进一步提升能效比。</p>
</li>
<li>
<p>针对深度学习模型多样化需求的硬件支持是TPU的重要改进方向之一。现代深度学习模型不仅包括传统的卷积神经网络（CNN）和全连接网络，还涉及Transformer、图神经网络（GNN）等复杂结构。为了适应这些模型的需求，TPU需要提供更加灵活的硬件支持，例如改进可编程性、支持更多类型的计算模式（如稀疏矩阵计算和动态计算图执行）以及更高效的非矩阵操作（如条件分支和非线性激活函数）。</p>
</li>
<li>
<p>TPU在系统级设计中正在不断优化分布式计算性能，以更好地支持超大规模的训练任务。当前的TPU已经可以通过网络将多个TPU芯片组成一个集群（如TPU Pod），支持数千个TPU核心同时工作。未来，TPU将改进芯片间的互连带宽和延迟，采用更高效的通信协议（如RDMA），并优化全局同步机制，以降低集群规模增加带来的通信开销。特别是在支持混合精度计算和梯度压缩技术方面，TPU将进一步优化，以适应更高效的分布式深度学习训练。</p>
</li>
<li>
<p>TPU在软件生态系统的改进方向上也在持续投入。为支持更广泛的开发者群体，TPU将进一步优化编程接口（如TensorFlow、JAX、PyTorch/XLA等）和自动化工具链，使其使用更加便捷。自动混合精度训练、模型并行策略优化以及分布式训练自动化等功能的改进，将帮助开发者更轻松地利用TPU的计算能力。</p>
</li>
<li>
<p>TPU还将改进对推理任务的支持。目前TPU主要被用于训练阶段的高计算需求，但推理任务由于对延迟和吞吐量的不同需求，也成为TPU改进的重点之一。未来TPU将在低延迟推理和边缘设备部署方面进行优化，例如设计针对推理的定制加速器，以及支持模型剪枝、量化和稀疏计算等推理优化技术。</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_microsoft_catapult一种灵活的数据中心加速器"><a class="link" href="#_microsoft_catapult一种灵活的数据中心加速器">9.4. Microsoft Catapult——一种灵活的数据中心加速器</a></h3>
<div class="sect3">
<h4 id="_catapult实现与体系结构"><a class="link" href="#_catapult实现与体系结构">9.4.1. Catapult实现与体系结构</a></h4>
<div class="paragraph">
<p>Microsoft Catapult 是微软为提高其数据中心计算性能和效率而设计的一种硬件加速平台。Catapult 项目采用 FPGA（现场可编程门阵列）作为加速硬件，通过灵活的硬件设计与定制化优化，为多种任务（尤其是搜索引擎、机器学习等计算密集型应用）提供加速能力。</p>
</div>
<div class="paragraph">
<p>Catapult 的实现基于将 FPGA 集成到数据中心的每个服务器中，通过 FPGA 和 CPU 的协同工作，为高性能计算任务提供硬件加速。Catapult 的设计目标是灵活性和高效性，它不仅能够在不同的任务需求下动态配置硬件资源，还能显著降低数据中心的整体功耗。</p>
</div>
<div class="paragraph">
<p>在体系结构方面，Catapult 的核心由以下几个部分组成：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>FPGA 节点设计：Catapult 在每台服务器中嵌入一块 FPGA，作为与 CPU 协作的硬件加速器。这些 FPGA 通过高速接口（如 PCIe）与主机 CPU 连接，并通过标准协议实现数据交换。在设计中，FPGA 执行计算密集型任务，例如搜索排序算法、深度学习推理或数据流处理，而 CPU 负责控制逻辑和任务调度。</p>
</li>
<li>
<p>分布式 FPGA 网络：Catapult 通过高带宽网络将多个 FPGA 节点连接成一个分布式加速系统。该网络支持 FPGA 间的低延迟通信，使得数据中心的 FPGA 加速器能够协同工作。这种设计特别适用于需要并行处理的大规模任务，例如搜索引擎结果排序或大规模机器学习模型的推理计算。</p>
</li>
<li>
<p>模块化设计：Catapult 的 FPGA 配置为模块化结构，每个模块执行特定功能（例如特定算法或数据流处理）。这种模块化设计使得系统能够根据不同任务需求动态加载不同的 FPGA 配置文件（bitstream），从而提高灵活性和资源利用率。</p>
</li>
<li>
<p>流水线并行计算：Catapult 的 FPGA 被设计为支持流水线并行计算。这种计算模式将任务划分为多个阶段，每个阶段由 FPGA 的特定硬件资源处理，从而实现更高的吞吐量和更低的延迟。这种设计非常适合搜索排序或大规模数据流处理等任务。</p>
</li>
<li>
<p>硬件与软件协同优化：Catapult 在设计中重视硬件和软件的协同优化。微软为 FPGA 开发了定制化的软件栈，包括硬件描述语言（HDL）开发工具链和支持任务调度的高层编程接口。开发者可以通过这些工具方便地在 FPGA 上部署算法，从而降低开发复杂性。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Catapult 的实现原理是通过 FPGA 的可编程特性，为特定任务设计高效的硬件加速器。与传统的 GPU 或 ASIC 加速器不同，FPGA 的优势在于其灵活性和低延迟特性。Catapult 的体系结构充分利用了 FPGA 的这些特点，将其与数据中心的服务器整合，从而实现了硬件资源的统一调度与高效利用。</p>
</div>
<div class="paragraph">
<p>Catapult 的一个关键应用是 Bing 搜索引擎的加速。通过 FPGA，微软实现了排序算法的硬件加速，大幅度提高了搜索结果的处理速度。此外，Catapult 还被用作深度学习推理的加速器，用于优化计算密集型神经网络任务。</p>
</div>
</div>
<div class="sect3">
<h4 id="_catapult软件"><a class="link" href="#_catapult软件">9.4.2. Catapult软件</a></h4>
<div class="paragraph">
<p>Microsoft Catapult 的成功不仅依赖于其硬件设计，还依赖于其开发的软件栈和相关工具，这些软件为开发者提供了高效的硬件配置、任务管理和应用部署能力，充分释放了 FPGA 硬件的潜能。以下是 Catapult 平台的重要软件及其作用的详细介绍。</p>
</div>
<div class="paragraph">
<p>Catapult 软件栈涵盖从底层硬件抽象到高层应用接口的一整套工具。它的设计目标是简化 FPGA 的编程流程，提高开发效率，并使其能够与数据中心的现有工作流和服务无缝集成。Catapult 的软件系统主要包括以下几个重要部分：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>硬件描述与配置工具</p>
<div class="paragraph">
<p>Catapult 使用标准的硬件描述语言（如 Verilog 和 VHDL）来设计 FPGA 的硬件逻辑电路。同时，微软开发了定制化的工具链，以便简化 FPGA 的硬件描述和编译流程。这些工具能够将高层的任务描述转化为 FPGA 的硬件配置文件（bitstream），并快速部署到 Catapult 平台中的 FPGA 节点上。</p>
</div>
</li>
<li>
<p>高层次综合工具（HLS, High-Level Synthesis）</p>
<div class="paragraph">
<p>为了降低 FPGA 开发的复杂性，Catapult 支持高层次综合工具，使开发者可以使用高层次编程语言（如 C 或 C++）来描述任务逻辑。HLS 工具会将这些描述自动转换为底层的硬件逻辑，从而生成适用于 FPGA 的硬件电路。这大大降低了开发门槛，使得非硬件领域的开发者也能够高效利用 FPGA 的计算能力。</p>
</div>
</li>
<li>
<p>FPGA 任务调度与资源管理软件</p>
<div class="paragraph">
<p>Catapult 平台包含任务调度和资源管理软件，用于管理 FPGA 与服务器 CPU 的协同工作。这些软件负责在不同任务间分配硬件资源，并动态调整 FPGA 的配置以适应任务需求。例如，在 Bing 搜索引擎加速任务中，任务调度器可以根据查询流量动态加载不同的排序算法，从而提高服务效率。</p>
</div>
</li>
<li>
<p>分布式系统支持工具</p>
<div class="paragraph">
<p>Catapult 平台的 FPGA 加速器通过高速网络连接形成分布式计算系统。为了管理这些 FPGA 节点之间的通信，微软开发了分布式系统支持工具。这些工具能够在多个 FPGA 节点间协调任务分配，优化通信路径，并实现低延迟的数据交换。这种分布式支持对需要高并行性和高吞吐量的应用（如机器学习推理）至关重要。</p>
</div>
</li>
<li>
<p>Catapult 驱动程序与运行时库</p>
<div class="paragraph">
<p>Catapult 的驱动程序和运行时库负责连接 FPGA 和主机 CPU，并提供与应用程序交互的接口。开发者可以通过标准化的 API（如微软提供的 DNN 模型推理 API）调用 FPGA 的加速功能，而无需直接处理底层硬件逻辑。这种抽象化设计简化了开发流程，同时保证了应用的可移植性。</p>
</div>
</li>
<li>
<p>机器学习支持工具</p>
<div class="paragraph">
<p>在机器学习领域，Catapult 平台提供了针对深度学习推理的优化工具。这些工具支持常见的深度学习框架（如 TensorFlow 和 PyTorch），并提供与 FPGA 加速紧密集成的库和优化算子。例如，Catapult 提供了硬件优化版本的矩阵乘法和卷积操作，以显著提升推理速度。</p>
</div>
</li>
<li>
<p>开发与调试工具链</p>
<div class="paragraph">
<p>Catapult 的开发工具链包含硬件调试、性能分析和故障诊断工具。这些工具能够帮助开发者检测 FPGA 配置中的错误，分析硬件加速性能瓶颈，并对其进行优化。例如，微软为 Catapult 平台开发了图形化调试界面，使开发者可以直观地监控硬件运行状态。</p>
</div>
</li>
<li>
<p>FPGA 动态重新配置支持</p>
<div class="paragraph">
<p>Catapult 的软件栈支持 FPGA 的动态部分重配置（Partial Reconfiguration），即在不中断 FPGA 其他部分任务运行的情况下，重新加载某些模块的硬件配置。这种特性使得 Catapult 平台能够灵活应对不同的任务需求，提高了硬件资源的利用效率。</p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_catapult上的cnn"><a class="link" href="#_catapult上的cnn">9.4.3. Catapult上的CNN</a></h4>
<div class="paragraph">
<p>Microsoft Catapult 平台上的 CNN（卷积神经网络）实现，充分利用了 FPGA（现场可编程门阵列）硬件的灵活性和高效并行性，为深度学习推理任务（如图像分类、目标检测等）提供了强大的加速能力。</p>
</div>
<div class="paragraph">
<p>在 Catapult 上运行 CNN 的核心思想是利用 FPGA 的并行计算特性加速 CNN 的关键运算，尤其是卷积运算和全连接层运算。这些操作占据了 CNN 绝大部分的计算开销，同时也具有高度的计算密集性和数据重复利用性。Catapult 针对这些特点，通过硬件优化和高效的软件栈支持，显著提高了 CNN 的推理性能。</p>
</div>
<div class="paragraph">
<p>Catapult 平台上 CNN 的主要特性和实现方法如下：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>卷积层加速</p>
<div class="paragraph">
<p>卷积层是 CNN 的核心计算模块，涉及大量的矩阵-张量乘法操作。Catapult 平台在 FPGA 上实现了专门的卷积硬件模块，这些模块利用数据的高局部性和重复性，将卷积操作映射为并行的乘加运算单元。通过流水线技术和硬件级优化，卷积模块可以同时处理多个输入通道和输出通道的数据流，从而极大地提升计算效率。</p>
</div>
</li>
<li>
<p>稀疏性和低精度优化</p>
<div class="paragraph">
<p>在 CNN 推理过程中，可以通过剪枝、量化等技术减少模型参数的稀疏性和数据的位宽需求。Catapult 平台支持 8 位甚至更低精度的整数计算，以及对稀疏矩阵的优化处理。通过这些优化，Catapult 在不显著损失精度的前提下减少了计算量和存储带宽需求，同时更好地利用了 FPGA 的硬件资源。</p>
</div>
</li>
<li>
<p>特定层的硬件优化</p>
<div class="paragraph">
<p>除了卷积层外，Catapult 平台还针对全连接层、池化层和激活函数实现了硬件优化。全连接层的计算被映射为高效的矩阵乘法，并利用 FPGA 的片上存储器来减少访存开销。池化操作（如最大池化或平均池化）被设计为独立的硬件单元，与卷积层流水线连接以最大化吞吐量。激活函数（如 ReLU 或 sigmoid）则通过查找表和硬件算子快速实现。</p>
</div>
</li>
<li>
<p>深度学习框架的集成支持</p>
<div class="paragraph">
<p>Catapult 平台与主流深度学习框架（如 TensorFlow 和 PyTorch）深度集成，开发者可以直接通过这些框架生成 CNN 模型，并利用 Catapult 的工具链将模型转换为适用于 FPGA 的硬件配置文件。这种高层次的抽象简化了开发过程，使得开发者无需直接接触 FPGA 的底层硬件逻辑。</p>
</div>
</li>
<li>
<p>分布式 CNN 推理支持</p>
<div class="paragraph">
<p>Catapult 平台通过其分布式计算能力支持大型 CNN 模型的分片推理。当单个 FPGA 无法容纳整个 CNN 模型时，Catapult 能够将模型划分为多个部分并分配到不同的 FPGA 节点上运行。通过高速互连网络，Catapult 能够高效地在节点之间传输中间数据，保持推理过程的低延迟和高吞吐量。</p>
</div>
</li>
<li>
<p>动态重新配置 CNN 模型</p>
<div class="paragraph">
<p>Catapult 的 FPGA 硬件支持动态部分重配置（Partial Reconfiguration），允许在不中断硬件运行的情况下加载新的 CNN 模型配置。这种特性使得 Catapult 平台能够灵活应对不同的 CNN 模型需求，如不同任务间的切换或模型参数的在线调整。</p>
</div>
</li>
<li>
<p>典型应用</p>
<div class="paragraph">
<p>在图像处理领域，Catapult 上的 CNN 被广泛用于图像分类、目标检测和语义分割等任务。例如，微软的 Bing 搜索引擎使用 Catapult 平台加速图片的特征提取和分类。此外，在视频处理和流媒体分析等任务中，Catapult 平台也通过 CNN 模型实现了高效的实时处理。</p>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>通过以上优化，Microsoft Catapult 平台不仅大幅提升了 CNN 模型的推理性能，还提供了高效的开发环境和分布式支持，满足了数据中心中对低延迟、高吞吐量和灵活性的需求。在 AI 加速领域，Catapult 平台的 CNN 实现成为一种高效且具有成本效益的解决方案。</p>
</div>
</div>
<div class="sect3">
<h4 id="_catapult上的搜索加速"><a class="link" href="#_catapult上的搜索加速">9.4.4. Catapult上的搜索加速</a></h4>
<div class="paragraph">
<p>Microsoft Catapult 是微软的一项基于 FPGA 的加速平台，最初被设计用于 Bing 搜索引擎的加速任务。通过将搜索引擎的关键计算任务卸载到 FPGA 上，Catapult 平台大幅提升了搜索引擎的性能、效率和响应速度。</p>
</div>
<div class="paragraph">
<p>Catapult 平台上的搜索加速主要体现在以下几个方面：</p>
</div>
<div class="paragraph">
<p>首先，Catapult 平台通过 FPGA 的并行处理能力加速了搜索引擎中的关键任务，如查询解析、文档评分、排序以及推荐等。在传统 CPU 中，这些任务需要消耗大量计算资源并具有较高的延迟。而通过 FPGA 的硬件流水线和高并行度特性，Catapult 平台能够快速处理大规模的搜索任务，从而显著降低延迟并提高吞吐量。</p>
</div>
<div class="paragraph">
<p>其次，Catapult 平台专门优化了 Bing 搜索引擎的文档评分过程。在搜索任务中，用户输入的查询需要与数十亿文档进行匹配，并计算相关性得分以返回最相关的结果。文档评分过程通常涉及复杂的向量操作、字符串匹配和特征提取等计算。Catapult 使用 FPGA 加速了这些运算，通过硬件级的优化实现高效的矩阵-向量乘法、稀疏向量操作和哈希匹配等功能，从而大幅提升了文档评分的速度。</p>
</div>
<div class="paragraph">
<p>此外，Catapult 平台还支持大规模分布式搜索加速架构。在 Bing 的数据中心中，数千个 FPGA 组成一个高性能的加速网络，每个 FPGA 节点负责处理搜索任务的一部分。这种架构允许任务在不同节点之间高效分配和并行执行，并通过高速互联网络实现节点间的数据通信，从而实现搜索任务的低延迟和高吞吐量。</p>
</div>
<div class="paragraph">
<p>在搜索排序任务中，Catapult 平台也起到了至关重要的作用。在搜索引擎中，排序算法根据查询结果的相关性对文档进行优先级排序。Catapult 平台使用 FPGA 加速了排序过程中的特征计算和评分函数评估，并利用硬件流水线进一步优化排序的执行效率。这种硬件加速确保了用户能够以更快的速度获得更准确的搜索结果。</p>
</div>
<div class="paragraph">
<p>Catapult 平台还支持深度学习模型在搜索引擎中的部署。近年来，深度学习模型在搜索相关性评估、自然语言处理和推荐系统中得到了广泛应用。Catapult 利用 FPGA 的灵活性和高并行性，为这些深度学习模型提供了硬件加速支持。通过优化的硬件配置，Catapult 平台能够加速深度学习模型的推理过程，例如在查询理解和上下文匹配任务中显著提升性能。</p>
</div>
<div class="paragraph">
<p>最后，Catapult 平台的设计不仅提升了 Bing 搜索的性能，还降低了整体能耗和硬件成本。相比使用更多的 CPU 或 GPU 资源，FPGA 提供了更高的性能功耗比，同时可以通过硬件复用支持多种搜索任务的加速需求。Catapult 平台的灵活性还使其能够适应搜索引擎的不断发展，例如支持新算法、新模型和更复杂的任务。</p>
</div>
<div class="paragraph">
<p>综上所述，Microsoft Catapult 平台在搜索加速中的应用充分利用了 FPGA 的硬件优势，通过大规模并行处理、硬件流水线优化和深度学习模型支持，大幅提升了搜索引擎的性能和响应效率。同时，其分布式架构和灵活性使其成为 Bing 搜索引擎的重要支撑技术，也是现代数据中心搜索加速的典范之一。</p>
</div>
</div>
<div class="sect3">
<h4 id="_catapult_ver_1_的部署"><a class="link" href="#_catapult_ver_1_的部署">9.4.5. Catapult Ver 1 的部署</a></h4>
<div class="paragraph">
<p>Catapult Ver 1 的部署始于 Microsoft Bing 数据中心。为了应对搜索引擎对计算性能的巨大需求以及降低搜索延迟的挑战，微软决定通过 FPGA 提供硬件加速。与传统 CPU 或 GPU 不同，FPGA 提供了灵活的硬件配置能力和低延迟的并行处理特性，非常适合搜索引擎中的关键任务加速。</p>
</div>
<div class="paragraph">
<p>Catapult Ver 1 的部署主要体现在以下几个方面：</p>
</div>
<div class="paragraph">
<p>首先是硬件部署。在 Catapult Ver 1 中，每台服务器中都集成了一个专门的 FPGA 加速卡。这些 FPGA 加速卡通过 PCIe 总线与主机 CPU 相连，形成了一个计算协同的架构。每个 FPGA 配备有独立的片上内存，用于处理本地数据，同时支持通过网络与其他 FPGA 节点进行通信。在 Bing 数据中心的部署过程中，微软为数千台服务器安装了这些 FPGA 加速卡，使其能够支持大规模的分布式计算任务。</p>
</div>
<div class="paragraph">
<p>其次是软件堆栈部署。Catapult Ver 1 的软件栈被设计为一个分层结构，包括驱动程序、运行时环境和应用程序接口（API）。这些软件层使得主机 CPU 和 FPGA 之间能够高效协同工作。在实际部署中，微软开发了一套专门的 FPGA 配置工具，用于将搜索引擎的关键任务逻辑编译成 FPGA 的硬件描述语言（HDL），并加载到 FPGA 中运行。这种硬件逻辑优化后的 FPGA 能够以较低的能耗完成搜索任务中的复杂计算。</p>
</div>
<div class="paragraph">
<p>网络部署是 Catapult Ver 1 中的另一大亮点。微软通过高性能网络将部署在服务器中的 FPGA 节点连接起来，形成一个可扩展的分布式加速网络。在这个网络中，FPGA 节点之间可以直接通信，实现了搜索任务的并行处理。通过这种分布式架构，Catapult Ver 1 能够支持 Bing 数据中心中的全局负载均衡和任务分配，从而进一步提升了系统的效率。</p>
</div>
<div class="paragraph">
<p>Catapult Ver 1 的部署还涉及到具体的搜索引擎加速任务。在 Bing 搜索中，查询处理涉及大量计算密集型任务，例如查询解析、文档评分和排序等。微软将这些任务的核心逻辑迁移到 FPGA 中运行，而非完全依赖于传统的 CPU 计算。这种硬件加速方式有效降低了搜索查询的响应时间，同时提升了搜索结果的相关性和准确性。</p>
</div>
<div class="paragraph">
<p>此外，Catapult Ver 1 的部署过程还注重成本和效率的平衡。与大规模升级服务器 CPU 不同，部署 FPGA 加速卡为微软节约了大量成本。FPGA 的低功耗和高性能功耗比使得数据中心能够在提高性能的同时保持能源消耗的稳定。在 Catapult Ver 1 项目的后期部署中，微软的数据中心还通过动态调整 FPGA 配置来满足不同工作负载的需求，这进一步增强了部署的灵活性。</p>
</div>
</div>
<div class="sect3">
<h4 id="_catapult_ver_2"><a class="link" href="#_catapult_ver_2">9.4.6. Catapult Ver 2</a></h4>
<div class="paragraph">
<p>Microsoft Catapult Ver 2 是微软在第一代 FPGA 加速平台 Catapult Ver 1 的基础上开发的升级版本，旨在进一步优化数据中心的硬件加速能力，并扩展应用领域。Catapult Ver 2 的设计目标是不仅支持 Bing 搜索引擎的加速，还能够为其他计算密集型任务（例如深度学习推理、网络功能虚拟化等）提供通用硬件加速。这一版本在体系结构、功能支持和部署模式上都进行了显著的改进。</p>
</div>
<div class="paragraph">
<p>Catapult Ver 2 的体系结构以 灵活性和扩展性 为核心特性。与 Ver 1 相比，Ver 2 将 FPGA 节点的连接方式从单独通过 PCIe 接口与主机 CPU 相连，扩展为一个更加复杂的分布式架构。这种改进使得 FPGA 不仅可以加速本地服务器的任务，还能够通过网络协作完成大规模的分布式任务处理。Catapult Ver 2 中，FPGA 加速卡通过高速网络接口连接在一起，形成了一个可扩展的计算加速池，进一步提升了系统的整体吞吐量。</p>
</div>
<div class="paragraph">
<p>在硬件配置上，Catapult Ver 2 引入了更强大的 FPGA 芯片，同时在加速卡上集成了更多的片上存储器和更高带宽的接口。这种硬件升级使得 FPGA 能够以更高的性能运行复杂的计算任务，例如深度学习模型的推理和训练。Catapult Ver 2 的硬件设计还加入了对 高精度计算 和 低精度运算 的支持，从而为不同类型的任务提供优化选项。</p>
</div>
<div class="paragraph">
<p>在软件层面，Catapult Ver 2 提供了一套更加完善的软件堆栈，支持多种工作负载和开发环境。这一版本的 Catapult 软件堆栈包括驱动程序、运行时库和开发工具链，开发者可以利用标准的编程语言（例如 C++ 和高层次综合工具）编写加速代码。微软还为 Catapult Ver 2 引入了深度学习框架支持，例如与 CNTK 和 TensorFlow 的无缝集成，使得用户能够轻松部署神经网络模型到 FPGA 上运行。此外，Catapult Ver 2 的软件支持动态重配置，允许开发者根据工作负载的需求动态更改 FPGA 的功能逻辑，从而实现资源利用的最大化。</p>
</div>
<div class="paragraph">
<p>Catapult Ver 2 的部署不仅延续了 Ver 1 在 Bing 搜索中的应用，还大幅扩展到其他领域。例如，微软开始在其 Azure 云服务中使用 Catapult Ver 2 提供加速功能，用于支持虚拟机的网络流量管理、视频转码和分布式数据库查询加速。这些新增的应用场景要求 FPGA 的灵活性和吞吐能力更高，而 Ver 2 的改进设计正好满足了这些需求。</p>
</div>
<div class="paragraph">
<p>一个关键的改进是，Catapult Ver 2 在网络拓扑上采用了近端加速器和全局共享资源池的混合架构。通过将部分 FPGA 加速卡设置为共享资源池中的节点，Catapult Ver 2 实现了更高的计算资源复用率和任务分配效率。这种设计特别适合需要并行处理的任务，例如搜索引擎的大规模查询解析和排序计算，以及深度学习推理中的批量推理处理。</p>
</div>
<div class="paragraph">
<p>此外，Catapult Ver 2 针对低延迟任务优化了通信机制。FPGA 加速器之间通过高速网络直接交换数据，而无需通过主机 CPU 中转。这种直接通信机制大幅降低了延迟，同时减少了主机 CPU 的负担，提高了整体系统的响应速度。</p>
</div>
<div class="paragraph">
<p>Catapult Ver 2 的一个重要应用是 深度学习推理加速。与传统的 GPU 加速相比，FPGA 在执行特定任务（例如低精度矩阵乘法）时具有更高的能效比。微软利用 Catapult Ver 2 提供的高效硬件加速功能，在 Azure 数据中心中运行深度学习模型推理，并显著降低了功耗和运营成本。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_intel_crest一种用于训练的数据中心加速器"><a class="link" href="#_intel_crest一种用于训练的数据中心加速器">9.5. Intel Crest——一种用于训练的数据中心加速器</a></h3>
<div class="paragraph">
<p>Intel Crest 是 Intel 公司推出的一种数据中心专用加速器 (Data Center ASIC)，旨在为特定的数据密集型计算任务提供高效的硬件加速。Crest 主要应用于云计算和数据中心的高性能计算场景，特别是在数据分析、机器学习推理以及高吞吐量任务中表现突出。</p>
</div>
<div class="paragraph">
<p>Crest 的设计目标是为数据中心工作负载提供更高的性能、能效比和计算密度，与传统的 CPU 或 GPU 相比，针对性更强，更适合某些固定的计算模式。作为 ASIC (Application-Specific Integrated Circuit) 硬件加速器，Crest 专为高效处理特定计算任务设计，具有比通用硬件（如 CPU 或 GPU）更低的功耗、更高的性能和更好的延迟表现。</p>
</div>
<div class="sect3">
<h4 id="_crest_的特点"><a class="link" href="#_crest_的特点">9.5.1. Crest 的特点</a></h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>高性能定制设计</p>
<div class="paragraph">
<p>Crest 是专用的 ASIC 加速器，因此其设计完全针对数据中心中常见的特定工作负载进行了优化。它能够以更高的吞吐量和更低的功耗执行计算密集型任务，例如深度学习推理、视频处理或大规模数据分析。</p>
</div>
</li>
<li>
<p>灵活性与可扩展性</p>
<div class="paragraph">
<p>Crest 被设计为数据中心架构的一个组成部分，支持多种并行计算模型（例如 SIMD 和 MIMD）。虽然 ASIC 硬件通常比 FPGA 更固定，但 Crest 针对不同工作负载仍具有一定的灵活性，能够适应多种任务需求。</p>
</div>
</li>
<li>
<p>片上存储器与高带宽</p>
<div class="paragraph">
<p>Crest 采用了片上存储器（on-chip memory）的设计，为处理单元提供了高速数据访问路径，减少了与外部存储器通信的延迟，同时增加了数据访问带宽。这种设计特别适合需要高内存带宽的工作负载，如矩阵运算和图形处理。</p>
</div>
</li>
<li>
<p>低功耗高能效</p>
<div class="paragraph">
<p>作为 ASIC 的一部分，Crest 的能效远高于通用硬件（例如 GPU），因为其硬件逻辑专门为特定任务设计，省去了大量通用硬件中必需的多余功能。这种高效设计使 Crest 在数据中心部署中具有显著的功耗优势。</p>
</div>
</li>
<li>
<p>多种数据格式支持</p>
<div class="paragraph">
<p>Crest 能够处理包括浮点数和定点数在内的多种数据格式。这种支持让它在深度学习推理任务中表现出色，因为低精度运算（如 8 位、16 位整数计算）在现代 AI 推理任务中非常常见。</p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_crest_的用途"><a class="link" href="#_crest_的用途">9.5.2. Crest 的用途</a></h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>深度学习推理加速</p>
<div class="paragraph">
<p>Crest 在深度学习推理中表现突出。它能够高效地处理神经网络的前向传播，尤其是在处理卷积神经网络 (CNN) 等计算密集型模型时，通过高效的矩阵运算加速推理过程。</p>
</div>
</li>
<li>
<p>视频处理与编码</p>
<div class="paragraph">
<p>视频流的实时处理是数据中心的常见任务。Crest 可以通过高带宽和高并行性支持视频流的实时解码、编码和转码，为在线视频平台提供支持。</p>
</div>
</li>
<li>
<p>大规模数据分析</p>
<div class="paragraph">
<p>数据中心中经常需要执行大规模数据分析工作负载，例如排序、过滤和聚合等操作。Crest 的高吞吐量设计使其在处理这些任务时具有显著的性能优势。</p>
</div>
</li>
<li>
<p>图形数据与科学计算</p>
<div class="paragraph">
<p>Crest 还可以应用于图形数据处理和科学计算，特别是在需要进行复杂数学运算或矩阵操作的工作负载中。</p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_crest_的部署场景"><a class="link" href="#_crest_的部署场景">9.5.3. Crest 的部署场景</a></h4>
<div class="paragraph">
<p>Intel Crest 主要部署在数据中心环境中，用于加速大规模工作负载。它可以与传统 CPU 协同工作，将计算密集型任务卸载到 Crest，以减轻 CPU 的负担。与 GPU 或 FPGA 相比，Crest 提供了更高效的能耗比和更优化的性能，特别适合固定功能需求的任务。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_pixel_visual_core一种个人移动设备图像处理单元"><a class="link" href="#_pixel_visual_core一种个人移动设备图像处理单元">9.6. Pixel Visual Core——一种个人移动设备图像处理单元</a></h3>
<div class="paragraph">
<p>Pixel Visual Core（PVC）是谷歌公司为其智能手机系列（例如 Pixel 手机）设计的一种专用图像处理单元（Image Processing Unit，IPU）。PVC 的开发旨在提升图像处理的性能，同时降低功耗，以支持复杂的计算摄影任务和实时图像处理。PVC 是一种高度优化的硬件加速器，能够实现高效的图像处理操作，包括 HDR（高动态范围）图像生成、降噪、白平衡调整以及其他先进的图像处理功能。</p>
</div>
<div class="paragraph">
<p>PVC 集成了多个硬件加速器和自定义的处理核心，专门优化计算摄影和机器学习任务。它能够以硬件为基础实现诸如 HDR+ 和夜视模式等复杂功能，这些功能原本需要消耗大量 CPU 和 GPU 资源。在谷歌 Pixel 系列手机中，PVC 的引入显著增强了拍照体验，使用户能够在极短时间内获得高质量的图像，并在低光环境下实现细节丰富的画面。</p>
</div>
<div class="paragraph">
<p>PVC 的体系结构设计强调并行计算能力。它包含多个专用处理核心，能够并行处理图像的不同区域，从而极大地提高了数据吞吐量。此外，PVC 支持广泛的图像处理算法，并且通过硬件优化实现了更高效的能耗比，与依赖 CPU 和 GPU 的传统图像处理方法相比，它在降低功耗的同时大幅提高了处理速度。</p>
</div>
<div class="paragraph">
<p>PVC 的一个显著特点是其灵活性和可编程性，它支持包括 TensorFlow Lite 在内的机器学习框架，使得开发者可以针对 PVC 开发定制化的图像处理算法。这一特性不仅支持先进的计算摄影功能，还为后续的软件升级和新功能实现提供了支持。</p>
</div>
<div class="paragraph">
<p>Pixel Visual Core 的用途广泛，除了拍照功能的提升，它还被用于增强视频录制、实时滤镜和增强现实（AR）应用的性能。例如，在拍照时，PVC 可以实时分析和处理多帧图像，从而生成更清晰、色彩更准确的 HDR+ 照片。在视频录制中，它能够实时应用降噪和动态范围扩展，显著提升画面质量。同时，由于其支持机器学习算法，PVC 在语义分割、人脸识别等计算密集型任务中也有广泛应用。</p>
</div>
<div class="sect3">
<h4 id="_pixel_visual_core_体系结构的理念"><a class="link" href="#_pixel_visual_core_体系结构的理念">9.6.1. Pixel Visual Core 体系结构的理念</a></h4>
<div class="paragraph">
<p>Pixel Visual Core（PVC）的体系结构设计理念基于高性能、低功耗和专用性优化的原则，专注于满足计算摄影和实时图像处理的需求，同时为机器学习任务提供强大的硬件支持。其设计理念体现了以下核心思想：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>PVC 的体系结构设计强调并行计算能力。现代计算摄影和图像处理通常需要处理大规模的图像数据，传统的串行处理方法无法满足实时性能要求。PVC 的设计理念是通过高度并行化的硬件结构，将图像分割为多个小块，分发到不同的计算单元并行处理，从而实现大幅度的性能提升。其硬件设计包含多个专用核心，这些核心可以同时运行，以快速完成复杂的图像计算任务。</p>
</li>
<li>
<p>PVC 的设计注重能效比优化。在移动设备中，功耗限制是一个关键问题，尤其是在处理高计算量的任务（例如 HDR+、降噪和白平衡）时。PVC 的架构通过硬件加速和专用指令集减少了对通用 CPU 和 GPU 的依赖，降低了整体功耗，同时提升了执行速度。这种设计使得 PVC 能够在低功耗的同时支持复杂的计算任务，延长设备的续航时间。</p>
</li>
<li>
<p>PVC 强调硬件的灵活性和可编程性。虽然 PVC 是一个专用硬件，但其体系结构支持广泛的算法和机器学习框架，例如 TensorFlow Lite。这种设计允许开发者为 PVC 编写特定的软件算法，使其能够快速适应新兴的图像处理需求，例如更高效的 HDR、语义分割或 AR 应用。PVC 的灵活性使其不仅限于静态图像处理，还可以扩展到视频处理和实时 AI 推理。</p>
</li>
<li>
<p>PVC 的架构理念还包含模块化和集成性。它并不是完全独立的硬件，而是深度集成在设备的 SoC（系统级芯片）中，能够与 CPU、GPU 和内存系统高效协同工作。这种集成性减少了数据传输的延迟和带宽消耗，使得 PVC 可以高效地与其他硬件单元交互，支持实时任务处理。</p>
</li>
<li>
<p>PVC 的设计体现了专用性和通用性的平衡。作为一个专用图像处理单元，PVC 针对计算摄影和 AI 任务进行了高度优化，但其设计并不局限于特定的算法或任务，而是为未来的计算需求预留了足够的扩展空间。这种设计理念确保了 PVC 能够应对图像处理领域不断变化的需求，同时为设备提供前沿的图像处理能力。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_pixel_visual_core_光晕"><a class="link" href="#_pixel_visual_core_光晕">9.6.2. Pixel Visual Core 光晕</a></h4>
<div class="paragraph">
<p>当模块计算滑动窗口到达一个二维数据的边缘部分时，3 × 3, 5 × 5, 7 × 7模板分别要从边缘外取1、2、3个像素（模板维度的一半减一）。这给出了两种选择。Pixel Visual Core要么无法充分利用边界附近元素对应的硬件资源（因为它们只传递输入值），要么使用去掉了ALU的简化版PE对二维PE稍做扩展。因为标准 PE与简化版 PE的大小相差约2.2倍，所以 Pixel VisualCore选择了后者。这个扩充区域称为光晕（halo）。</p>
</div>
</div>
<div class="sect3">
<h4 id="_pixel_visual_core_的处理器"><a class="link" href="#_pixel_visual_core_的处理器">9.6.3. Pixel Visual Core 的处理器</a></h4>
<div class="paragraph">
<p>7.7.5 Pixel Visual Core的处理器l6×l6个PE和每个维度上的4个光晕通道，合在一起称为PE阵列（PEarray）或向量阵列(vector array)，它是Pixel VisualCore的主要计算单元。它还有一个加载一存储单元，称为片生成器(sheet generator，SHG)。SHG是指对大小为1 × l到256 × 256的像素块进行的存储器访问，这样的像素块被称为片（sheet）。这种访问发生在下采样时，典型值为16 × 16或20 × 20。</p>
</div>
<div class="paragraph">
<p>Pixel Visual Core的实现可以拥有任意偶数个核，具体取决于可用资源。因此，它需要一个网络将这些核连接在一起，所以每个核还有一个接口连到片上网络（network on chip，NOC）。但是，Pixel Visual Core的典型NOC实现不会是一个昂贵的交叉开关，因为这需要数据通过很长的距离，而这样做的成本非常高。利用此应用程序的流水线本质，NOC通常只需要与相邻的核通信。它被实现为一种二维网格，由软件管理核的电源门控。</p>
</div>
<div class="paragraph">
<p>最后，Pixel Visual Core 还包含一个标量处理器，称为标量通道（scalar lane,SCL）。它与向量通道相同，只是增加了一些处理跳转、分支和中断的指令，控制到向量阵列的指令流，并为片生成器调度所有加载和存储操作。它还有一个很小的指令存储器。注意，Pixel Visual Core使用一个控制标量单元和向量单元的单一指令流，类似于一个CPU核为其标量和SIMD单元使用单一指令流。</p>
</div>
<div class="paragraph">
<p>除了核之外，还有一个DMA引擎用于在DRAM和行缓冲区之间传送数据，同时高效地在图像存储布局格式（即压缩/解压缩）之间进行转换。与顺序DRAM访问一样，这些DMA引擎也执行与向量类似的DRAM集中读操作，以及顺序和步幅读写。</p>
</div>
</div>
<div class="sect3">
<h4 id="_pixel_visual_core_指令集体系结构"><a class="link" href="#_pixel_visual_core_指令集体系结构">9.6.4. Pixel Visual Core 指令集体系结构</a></h4>
<div class="paragraph">
<p>与GPU类似，Pixel Visual Core采用一种两步编译过程。第一步是将程序由原语言（例如，Halide）编译为vISA指令。Pixel Visual Core vISA（virtual instruction set architecture,虚拟指令集体系结构）受到了RISC-V指令集的启发，但它采用了一种图像专用的存储模型，并对指令集进行了扩展以进行图像处理，特别是图像的二维概念。在vISA中，一个核的二维阵列是无限的，寄存器的数量是无限的，存储器大小也没有限制。vISA指令包含了不直接访问DRAM的纯函数，极大地简化了将其映射到硬件的操作。</p>
</div>
<div class="paragraph">
<p>第二步是将vISA程序编译为pISA（物理指令集体系结构）程序。以vISA为编译器的目标，处理器可以与之前的程序保持软件兼容，同时还能接受对pISA指令集的修改，所以vISA扮演的角色类似于PTX在GPU中扮演的角色。由vISA降至pISA分为两步：编译以及与早期绑定参数的映射，向代码中添加后期绑定参数。必须绑定的参数包括STP大小、光晕大小、STP的数量、行缓冲区的映射，将内核映射到处理器，以及寄存器和局部存储器分配。</p>
</div>
<div class="paragraph">
<p>pISA是一个超长指令字（VLIV）指令集，拥有宽度为119位的指令。第一个字段的长度为43位，用于标量通道；第二个字段的长度为38位，指定由二维PE阵列执行的计算：第三个字段的长度为12位，指定由二维PE阵列执行的存储器访问；最后两个字段是用于计算或寻址的立即数。所有VLIV字段的操作是我们所期望的：二进制补码整数算术运算、饱和整数算术运算、逻辑运算、移位、数据传输，以及一些特殊运算，比如除法选代和计算前导零的个数等。标量通道在二维PE阵列中支持这些运算的一个超集，另外还增加了用于控制流和片生成器控制的指令。上面提到的1位谓词寄存器支持向寄存器的条件移动（例如，若C，则A=B）。</p>
</div>
<div class="paragraph">
<p>尽管pISA VLIW指令非常宽，但Halide内核很短，经常仅有200-600条指令。作为一个IPU，它只需要执行一个应用程序中计算密集的部分，而将其他功能交给CPU和GPO因此，Pixel Visunl Core的指令存储器仅保存2048条pISA指令（28.5KiB）。</p>
</div>
<div class="paragraph">
<p>标量通道发出访问行缓冲区的片生成器指令。与Pixel Visual Core中的其他存储器访问不同，其延迟可能超过1个时钟周期，所以它们有一个类似于DMA的接口。使用这个通道需首先在特殊功能寄存器中设定地址和传送大小。</p>
</div>
</div>
<div class="sect3">
<h4 id="_pixel_visual_core_pe"><a class="link" href="#_pixel_visual_core_pe">9.6.5. Pixel Visual Core PE</a></h4>
<div class="paragraph">
<p>体系结构设计中的一个决策就是设定光晕的大小。Pixel Visual Core使用16 × 16个PE，并增加了一个拥有2个额外单元的光晕，所以它可以直接支持5 × 5模板。注意，PE阵列越大，支持给定模型大小所需要的光晕相对开销越小。</p>
</div>
<div class="paragraph">
<p>对于Pixel Visual Core，光晕 PE的较小尺寸和16 × l6的阵列规模意味着光晕只需要多占用20%的面积。对于一个5 × 5的模板，Pixel Visual Core每个时钟周期可以计算约1.8倍（\(s6^2/12^2\)）的结果；对于3×3模板，此比值约为1.3(\(16^2/14^2\))。</p>
</div>
<div class="paragraph">
<p>PE的算术运算单元的设计受乘累加（MAC）运算的驱动，这种运算是模板计算的基元运算。Pisel Visual Core 原生MAC的乘法宽度为16位，但它们能够以32位宽度进行计算。MAC的流水化设计会不必要地耗用能量，这是因为要对所增加的流水线寄存器进行读写操作。因此，来加硬件的耗时就决定了时钟周期。之前提到的其他一些运算是传统的逻辑与算术运算，还有算术运算的饱和版本及一些专用指令。PE有两个16位ALU，它们可以在单个时钟周期内以各种方式运行。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>独立，生成两个16位结果：A op C, C op D</p>
</li>
<li>
<p>融合，仅生成一个16位结果：A op (C op D)</p>
</li>
<li>
<p>联合，生成一个32位结果：A:C op B:D</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_二维行缓冲区及其控制器"><a class="link" href="#_二维行缓冲区及其控制器">9.6.6. 二维行缓冲区及其控制器</a></h4>
<div class="paragraph">
<p>因为DRAM 访问耗用如此之多的能量，所以要对Pixel Visual Core存储系统进行精心设计，使DRAM访问的次数降至最低。这里的关键创新是二维行缓冲区。</p>
</div>
<div class="paragraph">
<p>逻辑上，内核运行在独立的核上，它们连接在一个DAG中，输入来自传感器或DRAM，编出送至DRAM。行缓冲区在内核之间保存要计算的图像的一部分。</p>
</div>
<div class="paragraph">
<p>二维行级冲区必须支持如下4项功能。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>它必须支持各种大小的二维模板计算，而这些大小在设计时是未知的。</p>
</li>
<li>
<p>由于光晕的原因，对于Pixel Visual Core中的16x16 PE阵列，STP将希望从行缓冲区中读取20×20的像素块，向行缓冲区写人16×16的像素块。</p>
</li>
<li>
<p>因为DAG是可编程的，所以我们需要可以由软件在任意两个核之间分配的行缓冲区。</p>
</li>
<li>
<p>几个核可能需要从同一个行缓冲区读取数据。因此，一个行级冲区应当支持多个消费者，尽管它只需要一个生产者。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Piel Visual Core中的行缓冲区实际上是一个多读取者的二维FIFO抽象，建立在大量SRAM之上：每个实例中为128KiB。它包含了仅使用一次的临时“图像”，对于这些图像，一个小型专用本地FIFO的效率要远高于对远距离存储器中的数据进行缓存。</p>
</div>
<div class="paragraph">
<p>由于读取的是20 × 20的像素块，而写入的是16 × 16的像素块，所以为了适应这一大小失配，FIFO中的基本分配单元为4×4的像素组。每个模板处理器有一个行缓冲区池(lincbuferpool，LBP），它们可能拥有8个逻辑行缓冲区（LB），再加上一个用于I/ODMA的LBP。LBP有三级抽象。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>在顶端，LBP控制器支持将8个LB作为逻辑实例。每个LB有一个FIFO生产者，最多有8个FIFO消费者。</p>
</li>
<li>
<p>控制器跟踪每个FIFO的头指针和尾指针。注意，LBP内部行缓冲区的大小灵活可变，由控制器决定。</p>
</li>
<li>
<p>底部是多个物理存储体，用于提供所需的带宽。Pixel Visual Core拥有8个物理存储体，每个存储体有一个128位的接口，容量为l6KiB。LBP的控制器富有挑战性，因为它必须满足STP和L/ODMA的带宽要求，还要将它们的所有读写操作调度给物理SRAM存储体。LBP控制器是Pixel Visoal Core最复杂的部分之一。</p>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2025-01-17 09:00:13 +0800
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains("stemblock")) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>